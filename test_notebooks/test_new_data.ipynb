{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import ROOT\n",
    "import numpy as np\n",
    "import root_numpy as rnp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "detfile = \"utilities/km3net_jul13_90m.detx\"\n",
    "nuefile = \"utilities/km3_v4_nuecc_1.evt.JTE.aa.root\"\n",
    "numufile = \"utilities/km3_v4_numucc_1_B.evt.aa.root\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from load_trees import load_trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ch_id_numu, dom_id_numu, trig_numu, times_numu = load_trees(numufile)\n",
    "ch_id_nue, dom_id_nue, trig_nue, times_nue = load_trees(nuefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lattice_doms_znewk import lattice_doms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lattice, l_doms = lattice_doms(detfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### totally crazy and inefficient way to define the array of lattice indices (but it works XD )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indices = []\n",
    "for i, (x,y,z) in enumerate(lattice):\n",
    "    for j,(xd,yd,zd) in enumerate(l_doms):\n",
    "        if (x,y,z)==(xd,yd,zd):\n",
    "            #print(i)\n",
    "            indices.append((i, j))\n",
    "indices = np.asarray(indices)\n",
    "doms_map = np.sort(indices, axis=1)[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i=[]\n",
    "j=[]\n",
    "k=[]\n",
    "for ii,x in enumerate(range(-300,1100,90)):\n",
    "    for jj,y in enumerate(np.arange(-550,550, 45*np.sqrt(3))):\n",
    "        for kk,z in enumerate(range(98,712,36)):\n",
    "            i.append(ii)\n",
    "            j.append(jj)\n",
    "            k.append(kk)\n",
    "        x-= 45\n",
    "l_i = np.asarray(i)\n",
    "l_j = np.asarray(j)\n",
    "l_k = np.asarray(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arr = []\n",
    "for i,j,k in zip(l_i,l_j,l_k):\n",
    "    arr.append((i,j,k))\n",
    "lol = np.asarray(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ret = np.zeros((16,15,18))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from timeslices import tslices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49997887.0, 49993098.0, 50000747.0, 50004225.0, 49993098.0, 50004225.0)\n"
     ]
    }
   ],
   "source": [
    "tslice = tslices(times_numu, times_nue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numu_events = dom_id_numu.shape[0]\n",
    "n_timeslices = tslice.shape[0] - 1\n",
    "#X = np.zeros((numu_events,n_timeslices, ret.shape))\n",
    "X_numu = np.zeros((numu_events,n_timeslices, ret.shape[0],ret.shape[1],ret.shape[2]))\n",
    "for evt in range(numu_events):\n",
    "    triggered_dom_ids = (dom_id_numu[evt][trig_numu[evt] == True]) - 1\n",
    "    times_event_hits = times_numu[evt]\n",
    "    for ts, tsl in enumerate(zip(tslice[:-1], tslice[1:])):\n",
    "            low, high = tsl\n",
    "            hits = np.where((times_event_hits >= low) & (times_event_hits < high))[0]\n",
    "            if not len(hits):\n",
    "                continue\n",
    "            #print(low,high, hits)\n",
    "            dom_hit_in_slice = triggered_dom_ids[hits]\n",
    "            l_dom_hit_in_slice = doms_map[dom_hit_in_slice]\n",
    "            l_ret = lol[l_dom_hit_in_slice]\n",
    "            for dom_indx in l_ret:\n",
    "                #print(evt, ts, dom_indx[0],dom_indx[1],dom_indx[2])\n",
    "                X_numu[evt, ts, dom_indx[0],dom_indx[1],dom_indx[2]] +=1\n",
    "            #print(\"dom_hit_in_slice: \",dom_hit_in_slice)\n",
    "            #print(\"l_dom_hit_in_slice: \",l_dom_hit_in_slice)\n",
    "            #print(evt, ts, l_ret)\n",
    "            #print(l_dom_hit_in_slice)# , dom_hit_in_slice)\n",
    "            \n",
    "            #X[evt, ts, l_ret[0],l_ret[1],l_ret[2]] +=1\n",
    "            #print(X[evt, ts, l_ret])\n",
    "Y_numu = np.ones(dom_id_numu.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1541, 75, 16, 15, 18)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_numu.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_numu_sw_12 = np.swapaxes(X_numu, 1,2)\n",
    "X_numu_sw_23 = np.swapaxes(X_numu_sw_12, 2,3)\n",
    "X_numu_sw_34 = np.swapaxes(X_numu_sw_23, 3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nue_events = dom_id_nue.shape[0]\n",
    "n_timeslices = tslice.shape[0] - 1\n",
    "X_nue = np.zeros((nue_events,n_timeslices, ret.shape[0],ret.shape[1],ret.shape[2]))\n",
    "for evt in range(nue_events):\n",
    "    triggered_dom_ids = (dom_id_nue[evt][trig_nue[evt] == True]) - 1\n",
    "    times_event_hits = times_nue[evt]\n",
    "    for ts, tsl in enumerate(zip(tslice[:-1], tslice[1:])):\n",
    "            low, high = tsl\n",
    "            hits = np.where((times_event_hits >= low) & (times_event_hits < high))[0]\n",
    "            if not len(hits):\n",
    "                continue\n",
    "            #print(low,high, hits)\n",
    "            dom_hit_in_slice = triggered_dom_ids[hits]\n",
    "            l_dom_hit_in_slice = doms_map[dom_hit_in_slice]\n",
    "            l_ret = lol[l_dom_hit_in_slice]\n",
    "            for dom_indx in l_ret:\n",
    "                #print(evt, ts, dom_indx[0],dom_indx[1],dom_indx[2])\n",
    "                X_nue[evt, ts, dom_indx[0],dom_indx[1],dom_indx[2]] +=1\n",
    "            #print(\"dom_hit_in_slice: \",dom_hit_in_slice)\n",
    "            #print(\"l_dom_hit_in_slice: \",l_dom_hit_in_slice)\n",
    "            #print(evt, ts, l_ret)\n",
    "            #print(l_dom_hit_in_slice)# , dom_hit_in_slice)\n",
    "            \n",
    "            #X[evt, ts, l_ret[0],l_ret[1],l_ret[2]] +=1\n",
    "            #print(X[evt, ts, l_ret])\n",
    "Y_nue = np.zeros(dom_id_nue.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_nue_sw_12 = np.swapaxes(X_nue, 1,2)\n",
    "X_nue_sw_23 = np.swapaxes(X_nue_sw_12, 2,3)\n",
    "X_nue_sw_34 = np.swapaxes(X_nue_sw_23, 3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_numu = X_numu_sw_34\n",
    "X_nue = X_nue_sw_34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('X_numu: ', (1541, 75, 16, 15, 18), 'X_nue: ', (1183, 75, 16, 15, 18), 'Y_numu: ', (1541,), 'Y_nue: ', (1183,))\n"
     ]
    }
   ],
   "source": [
    "print('X_numu: ', X_numu.shape, 'X_nue: ', X_nue.shape, 'Y_numu: ', Y_numu.shape, 'Y_nue: ', Y_nue.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.vstack((X_numu, X_nue))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'channels_first'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.backend.image_data_format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers.convolutional import Conv3D, MaxPooling3D, ZeroPadding3D\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.losses import categorical_crossentropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### concatenate Y to use data with StratifiedKFold (train-test split), otherwise concatenate later, after converting Y to categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y = np.concatenate((Y_numu, Y_nue))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=7)\n",
    "best_validation_acc = 0.0\n",
    "best_model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2043, 75, 16, 15, 18)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input_shape for \"channels_first\" image_data_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_channel = X_train.shape[1]\n",
    "conv_dim_1 = X_train.shape[2]\n",
    "conv_dim_2 = X_train.shape[3]\n",
    "conv_dim_3 = X_train.shape[4]\n",
    "inputshape = (img_channel, conv_dim_1, conv_dim_2, conv_dim_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input shape for \" image_data_format\" = \"channels_last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_channel = X_train.shape[4]\n",
    "conv_dim_1 = X_train.shape[1]\n",
    "conv_dim_2 = X_train.shape[2]\n",
    "conv_dim_3 = X_train.shape[3]\n",
    "inputshape = (conv_dim_1, conv_dim_2, conv_dim_3, img_channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cnn_model():\n",
    "    early_stop = EarlyStopping(monitor='val_acc', patience=4, verbose=1)\n",
    "    model = Sequential()\n",
    "    model.add(Conv3D(128, kernel_size=(3, 3, 3), activation='relu', input_shape=inputshape))\n",
    "    model.add(Conv3D(64, (3, 3, 3), activation='relu'))\n",
    "    model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "    #model.add(Dropout(0.1))\n",
    "    model.add(Conv3D(32, (3, 3, 3), activation='relu'))\n",
    "    #model.add(Dropout(0.25))\n",
    "    model.add(Conv3D(32, (3, 3, 3), activation='relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(loss=categorical_crossentropy,\n",
    "                  optimizer=keras.optimizers.Adadelta(),\n",
    "                  metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cnn_model2():\n",
    "    early_stop = EarlyStopping(monitor='val_acc', patience=4, verbose=1)\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv3D(64, kernel_size=(3, 3, 3), activation='relu', input_shape=inputshape))\n",
    "    model.add(Conv3D(128, (3, 3, 3), activation='relu'))\n",
    "    model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Conv3D(256, (3, 3, 3), activation='relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv3D(512, (3, 3, 3), activation='relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(loss=categorical_crossentropy,\n",
    "                  optimizer=keras.optimizers.Adadelta(),\n",
    "                  metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cnn_model2():\n",
    "    early_stop = EarlyStopping(monitor='val_acc', patience=4, verbose=1)\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv3D(64, kernel_size=(3, 3, 3), activation='relu', input_shape=inputshape))\n",
    "    model.add(Conv3D(128, (3, 3, 3), activation='relu'))\n",
    "    model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "    #model.add(Dropout(0.1))\n",
    "    model.add(Conv3D(256, (3, 3, 3), activation='relu'))\n",
    "    #model.add(Dropout(0.25))\n",
    "    model.add(Conv3D(512, (3, 3, 3), activation='relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(loss=categorical_crossentropy,\n",
    "                  optimizer=keras.optimizers.Adadelta(),\n",
    "                  metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cnn_model3():\n",
    "    early_stop = EarlyStopping(monitor='val_acc', patience=4, verbose=1)\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(ZeroPadding3D((1,1,1), input_shape=inputshape))\n",
    "    model.add(Conv3D(64, kernel_size=(3, 3, 3), activation='relu'))#, input_shape=inputshape))\n",
    "    model.add(Conv3D(128, (3, 3, 3), activation='relu'))\n",
    "    model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "    #model.add(Dropout(0.1))\n",
    "    model.add(Conv3D(256, (3, 3, 3), activation='relu'))\n",
    "    #model.add(Dropout(0.25))\n",
    "    model.add(Conv3D(256, (3, 3, 3), activation='relu'))\n",
    "    model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "    model.add(Conv3D(256, (3, 3, 3), activation='relu'))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(loss=categorical_crossentropy,\n",
    "                  optimizer=keras.optimizers.Adadelta(),\n",
    "                  metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cnn_model_sigmoid():\n",
    "    early_stop = EarlyStopping(monitor='val_acc', patience=4, verbose=1)\n",
    "    model = Sequential()\n",
    "    model.add(Conv3D(128, kernel_size=(3, 3, 3), activation='relu', input_shape=inputshape))\n",
    "    model.add(Conv3D(64, (3, 3, 3), activation='relu'))\n",
    "    model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "    #model.add(Dropout(0.1))\n",
    "    model.add(Conv3D(32, (3, 3, 3), activation='relu'))\n",
    "    #model.add(Dropout(0.25))\n",
    "    model.add(Conv3D(32, (3, 3, 3), activation='relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(num_classes, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss=categorical_crossentropy,\n",
    "                  optimizer=keras.optimizers.Adadelta(),\n",
    "                  metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "create_nn_model = cnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "create_nn_model = cnn_model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "create_nn_model = cnn_model3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "create_nn_model = cnn_model_sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_94 (Conv3D)           (None, 128, 14, 13, 16)   259328    \n",
      "_________________________________________________________________\n",
      "conv3d_95 (Conv3D)           (None, 64, 12, 11, 14)    221248    \n",
      "_________________________________________________________________\n",
      "max_pooling3d_25 (MaxPooling (None, 64, 6, 5, 7)       0         \n",
      "_________________________________________________________________\n",
      "conv3d_96 (Conv3D)           (None, 32, 4, 3, 5)       55328     \n",
      "_________________________________________________________________\n",
      "conv3d_97 (Conv3D)           (None, 32, 2, 1, 3)       27680     \n",
      "_________________________________________________________________\n",
      "flatten_23 (Flatten)         (None, 192)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 2)                 386       \n",
      "=================================================================\n",
      "Total params: 563,970\n",
      "Trainable params: 563,970\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1750 samples, validate on 293 samples\n",
      "Epoch 1/20\n",
      "1750/1750 [==============================] - 21s - loss: 0.6940 - acc: 0.5674 - val_loss: 0.6829 - val_acc: 0.5904\n",
      "Epoch 2/20\n",
      "1750/1750 [==============================] - 21s - loss: 0.6660 - acc: 0.6154 - val_loss: 0.6641 - val_acc: 0.5802\n",
      "Epoch 3/20\n",
      "1750/1750 [==============================] - 21s - loss: 0.6134 - acc: 0.6474 - val_loss: 0.6576 - val_acc: 0.5904\n",
      "Epoch 4/20\n",
      "1750/1750 [==============================] - 21s - loss: 0.5659 - acc: 0.6931 - val_loss: 0.5841 - val_acc: 0.7304\n",
      "Epoch 5/20\n",
      "1750/1750 [==============================] - 22s - loss: 0.4811 - acc: 0.7754 - val_loss: 0.4970 - val_acc: 0.7884\n",
      "Epoch 6/20\n",
      "1750/1750 [==============================] - 22s - loss: 0.4069 - acc: 0.8263 - val_loss: 0.4284 - val_acc: 0.8430\n",
      "Epoch 7/20\n",
      "1750/1750 [==============================] - 22s - loss: 0.3512 - acc: 0.8543 - val_loss: 0.4157 - val_acc: 0.8225\n",
      "Epoch 8/20\n",
      "1750/1750 [==============================] - 22s - loss: 0.3055 - acc: 0.8703 - val_loss: 0.3859 - val_acc: 0.8567\n",
      "Epoch 9/20\n",
      "1750/1750 [==============================] - 22s - loss: 0.2846 - acc: 0.8743 - val_loss: 0.3905 - val_acc: 0.8669\n",
      "Epoch 10/20\n",
      "1750/1750 [==============================] - 22s - loss: 0.2592 - acc: 0.8960 - val_loss: 0.3992 - val_acc: 0.8703\n",
      "Epoch 11/20\n",
      "1750/1750 [==============================] - 23s - loss: 0.2244 - acc: 0.9074 - val_loss: 0.4005 - val_acc: 0.8567\n",
      "Epoch 12/20\n",
      "1750/1750 [==============================] - 23s - loss: 0.2077 - acc: 0.9171 - val_loss: 0.4465 - val_acc: 0.8737\n",
      "Epoch 13/20\n",
      "1750/1750 [==============================] - 23s - loss: 0.1879 - acc: 0.9303 - val_loss: 0.4375 - val_acc: 0.8805\n",
      "Epoch 14/20\n",
      "1750/1750 [==============================] - 23s - loss: 0.1693 - acc: 0.9343 - val_loss: 0.4771 - val_acc: 0.8874\n",
      "Epoch 15/20\n",
      "1750/1750 [==============================] - 23s - loss: 0.1741 - acc: 0.9394 - val_loss: 0.4479 - val_acc: 0.8874\n",
      "Epoch 16/20\n",
      "1750/1750 [==============================] - 23s - loss: 0.1446 - acc: 0.9440 - val_loss: 0.5256 - val_acc: 0.8601\n",
      "Epoch 17/20\n",
      "1750/1750 [==============================] - 23s - loss: 0.1462 - acc: 0.9411 - val_loss: 0.5442 - val_acc: 0.8635\n",
      "Epoch 18/20\n",
      "1750/1750 [==============================] - 23s - loss: 0.1254 - acc: 0.9549 - val_loss: 0.5255 - val_acc: 0.8771\n",
      "Epoch 19/20\n",
      "1750/1750 [==============================] - 23s - loss: 0.1188 - acc: 0.9543 - val_loss: 0.5857 - val_acc: 0.8771\n",
      "Epoch 20/20\n",
      "1750/1750 [==============================] - 23s - loss: 0.1123 - acc: 0.9577 - val_loss: 0.5686 - val_acc: 0.8874\n",
      "2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_98 (Conv3D)           (None, 128, 14, 13, 16)   259328    \n",
      "_________________________________________________________________\n",
      "conv3d_99 (Conv3D)           (None, 64, 12, 11, 14)    221248    \n",
      "_________________________________________________________________\n",
      "max_pooling3d_26 (MaxPooling (None, 64, 6, 5, 7)       0         \n",
      "_________________________________________________________________\n",
      "conv3d_100 (Conv3D)          (None, 32, 4, 3, 5)       55328     \n",
      "_________________________________________________________________\n",
      "conv3d_101 (Conv3D)          (None, 32, 2, 1, 3)       27680     \n",
      "_________________________________________________________________\n",
      "flatten_24 (Flatten)         (None, 192)               0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 2)                 386       \n",
      "=================================================================\n",
      "Total params: 563,970\n",
      "Trainable params: 563,970\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1750 samples, validate on 293 samples\n",
      "Epoch 1/20\n",
      "1750/1750 [==============================] - 24s - loss: 0.6954 - acc: 0.5669 - val_loss: 0.7036 - val_acc: 0.5734\n",
      "Epoch 2/20\n",
      "1750/1750 [==============================] - 23s - loss: 0.6412 - acc: 0.6194 - val_loss: 0.6683 - val_acc: 0.6246\n",
      "Epoch 3/20\n",
      "1750/1750 [==============================] - 23s - loss: 0.5937 - acc: 0.6823 - val_loss: 0.6338 - val_acc: 0.6314\n",
      "Epoch 4/20\n",
      "1750/1750 [==============================] - 23s - loss: 0.5028 - acc: 0.7526 - val_loss: 0.6496 - val_acc: 0.6621\n",
      "Epoch 5/20\n",
      "1750/1750 [==============================] - 23s - loss: 0.4418 - acc: 0.8149 - val_loss: 0.5403 - val_acc: 0.7543\n",
      "Epoch 6/20\n",
      "1750/1750 [==============================] - 23s - loss: 0.3782 - acc: 0.8446 - val_loss: 0.5304 - val_acc: 0.7850\n",
      "Epoch 7/20\n",
      "1750/1750 [==============================] - 23s - loss: 0.3382 - acc: 0.8611 - val_loss: 0.4678 - val_acc: 0.8328\n",
      "Epoch 8/20\n",
      "1750/1750 [==============================] - 24s - loss: 0.3038 - acc: 0.8789 - val_loss: 0.5173 - val_acc: 0.8123\n",
      "Epoch 9/20\n",
      "1750/1750 [==============================] - 24s - loss: 0.2726 - acc: 0.8909 - val_loss: 0.4634 - val_acc: 0.8328\n",
      "Epoch 10/20\n",
      "1750/1750 [==============================] - 24s - loss: 0.2526 - acc: 0.8989 - val_loss: 0.5574 - val_acc: 0.8020\n",
      "Epoch 11/20\n",
      "1750/1750 [==============================] - 24s - loss: 0.2322 - acc: 0.9091 - val_loss: 0.4626 - val_acc: 0.8294\n",
      "Epoch 12/20\n",
      "1750/1750 [==============================] - 24s - loss: 0.2226 - acc: 0.9126 - val_loss: 0.4469 - val_acc: 0.8498\n",
      "Epoch 13/20\n",
      "1750/1750 [==============================] - 24s - loss: 0.1814 - acc: 0.9251 - val_loss: 0.4658 - val_acc: 0.8464\n",
      "Epoch 14/20\n",
      "1750/1750 [==============================] - 24s - loss: 0.1757 - acc: 0.9314 - val_loss: 0.5169 - val_acc: 0.8328\n",
      "Epoch 15/20\n",
      "1750/1750 [==============================] - 24s - loss: 0.1506 - acc: 0.9423 - val_loss: 0.4962 - val_acc: 0.8396\n",
      "Epoch 16/20\n",
      "1750/1750 [==============================] - 24s - loss: 0.1403 - acc: 0.9497 - val_loss: 0.5377 - val_acc: 0.8362\n",
      "Epoch 17/20\n",
      "1750/1750 [==============================] - 24s - loss: 0.1272 - acc: 0.9549 - val_loss: 0.5367 - val_acc: 0.8498\n",
      "Epoch 18/20\n",
      "1750/1750 [==============================] - 24s - loss: 0.1301 - acc: 0.9514 - val_loss: 0.5240 - val_acc: 0.8532\n",
      "Epoch 19/20\n",
      "1750/1750 [==============================] - 24s - loss: 0.1116 - acc: 0.9594 - val_loss: 0.5474 - val_acc: 0.8532\n",
      "Epoch 20/20\n",
      "1750/1750 [==============================] - 24s - loss: 0.1067 - acc: 0.9640 - val_loss: 0.5744 - val_acc: 0.8498\n",
      "3\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_102 (Conv3D)          (None, 128, 14, 13, 16)   259328    \n",
      "_________________________________________________________________\n",
      "conv3d_103 (Conv3D)          (None, 64, 12, 11, 14)    221248    \n",
      "_________________________________________________________________\n",
      "max_pooling3d_27 (MaxPooling (None, 64, 6, 5, 7)       0         \n",
      "_________________________________________________________________\n",
      "conv3d_104 (Conv3D)          (None, 32, 4, 3, 5)       55328     \n",
      "_________________________________________________________________\n",
      "conv3d_105 (Conv3D)          (None, 32, 2, 1, 3)       27680     \n",
      "_________________________________________________________________\n",
      "flatten_25 (Flatten)         (None, 192)               0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 2)                 386       \n",
      "=================================================================\n",
      "Total params: 563,970\n",
      "Trainable params: 563,970\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1751 samples, validate on 292 samples\n",
      "Epoch 1/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.6979 - acc: 0.5580 - val_loss: 0.6947 - val_acc: 0.5377\n",
      "Epoch 2/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.6326 - acc: 0.6311 - val_loss: 0.7312 - val_acc: 0.5959\n",
      "Epoch 3/20\n",
      "1751/1751 [==============================] - 23s - loss: 0.5832 - acc: 0.6745 - val_loss: 0.5908 - val_acc: 0.6541\n",
      "Epoch 4/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.5124 - acc: 0.7424 - val_loss: 0.5934 - val_acc: 0.7534\n",
      "Epoch 5/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.4490 - acc: 0.8093 - val_loss: 0.5260 - val_acc: 0.8493\n",
      "Epoch 6/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.3958 - acc: 0.8447 - val_loss: 0.4862 - val_acc: 0.8390\n",
      "Epoch 7/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.3525 - acc: 0.8795 - val_loss: 0.4917 - val_acc: 0.8219\n",
      "Epoch 8/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.3222 - acc: 0.8744 - val_loss: 0.5021 - val_acc: 0.8185\n",
      "Epoch 9/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.2897 - acc: 0.8892 - val_loss: 0.4061 - val_acc: 0.8253\n",
      "Epoch 10/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.2583 - acc: 0.8966 - val_loss: 0.4224 - val_acc: 0.8493\n",
      "Epoch 11/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.2278 - acc: 0.9109 - val_loss: 0.4934 - val_acc: 0.8253\n",
      "Epoch 12/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.2251 - acc: 0.9092 - val_loss: 0.4191 - val_acc: 0.8630\n",
      "Epoch 13/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.1971 - acc: 0.9246 - val_loss: 0.4183 - val_acc: 0.8527\n",
      "Epoch 14/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.2004 - acc: 0.9172 - val_loss: 0.4185 - val_acc: 0.8562\n",
      "Epoch 15/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.1741 - acc: 0.9332 - val_loss: 0.4037 - val_acc: 0.8630\n",
      "Epoch 16/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.1556 - acc: 0.9383 - val_loss: 0.4573 - val_acc: 0.8493\n",
      "Epoch 17/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.1486 - acc: 0.9417 - val_loss: 0.4193 - val_acc: 0.8699\n",
      "Epoch 18/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.1384 - acc: 0.9492 - val_loss: 0.4348 - val_acc: 0.8596\n",
      "Epoch 19/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.1431 - acc: 0.9497 - val_loss: 0.4337 - val_acc: 0.8664\n",
      "Epoch 20/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.1175 - acc: 0.9566 - val_loss: 0.4308 - val_acc: 0.8699\n",
      "4\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_106 (Conv3D)          (None, 128, 14, 13, 16)   259328    \n",
      "_________________________________________________________________\n",
      "conv3d_107 (Conv3D)          (None, 64, 12, 11, 14)    221248    \n",
      "_________________________________________________________________\n",
      "max_pooling3d_28 (MaxPooling (None, 64, 6, 5, 7)       0         \n",
      "_________________________________________________________________\n",
      "conv3d_108 (Conv3D)          (None, 32, 4, 3, 5)       55328     \n",
      "_________________________________________________________________\n",
      "conv3d_109 (Conv3D)          (None, 32, 2, 1, 3)       27680     \n",
      "_________________________________________________________________\n",
      "flatten_26 (Flatten)         (None, 192)               0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 2)                 386       \n",
      "=================================================================\n",
      "Total params: 563,970\n",
      "Trainable params: 563,970\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1751 samples, validate on 292 samples\n",
      "Epoch 1/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.6948 - acc: 0.5397 - val_loss: 0.6940 - val_acc: 0.5753\n",
      "Epoch 2/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.6540 - acc: 0.6156 - val_loss: 0.6791 - val_acc: 0.5993\n",
      "Epoch 3/20\n",
      " 832/1751 [=============>................] - ETA: 12s - loss: 0.6517 - acc: 0.6022"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-70ecf263e373>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     history = model.fit(Xtrain, Ytrain, batch_size=64,\n\u001b[1;32m     15\u001b[0m                         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                         validation_data = (Xvalidation, Yvalidation))\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mvalidation_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvalidation_acc\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbest_validation_acc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cdesio/.local/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    861\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/home/cdesio/.local/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1428\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1429\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1430\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1432\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cdesio/.local/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m   1077\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1079\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1080\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cdesio/.local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2266\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2267\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2268\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2269\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cdesio/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cdesio/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 997\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    998\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cdesio/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1132\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/cdesio/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1137\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cdesio/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#cnn first attempt - new dataset + tf with 'channels_first'\n",
    "best_validation_acc = 0.0\n",
    "best_model = None\n",
    "num_classes = 2\n",
    "for i, (train_index, validation_index) in enumerate(skf.split(X_train, Y_train)):\n",
    "    print(i+1)\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", validation_index)\n",
    "    Xtrain, Xvalidation = X_train[train_index], X_train[validation_index]\n",
    "    ytrain, yvalidation = Y_train[train_index], Y_train[validation_index]\n",
    "    model = create_nn_model()\n",
    "    Ytrain = np_utils.to_categorical(ytrain)\n",
    "    Yvalidation = np_utils.to_categorical(yvalidation)\n",
    "    \n",
    "    history = model.fit(Xtrain, Ytrain, batch_size=64,\n",
    "                        epochs=20, verbose=1,\n",
    "                        validation_data = (Xvalidation, Yvalidation))\n",
    "    validation_acc = history.history['val_acc']\n",
    "    if validation_acc > best_validation_acc:\n",
    "        best_validation_acc = validation_acc\n",
    "        best_model = model\n",
    "Ytrain = np_utils.to_categorical(ytrain)\n",
    "best_model.fit(Xtrain, Ytrain, batch_size=64, epochs=20)  # replicate conf.\n",
    "\n",
    "predictions = best_model.predict(X_test)\n",
    "cls_predictions = np.argmax(predictions, axis=1)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(Y_test, cls_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure()\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.grid()\n",
    "plt.legend(['Training', 'Validation'])\n",
    "\n",
    "plt.figure()\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.grid()\n",
    "plt.legend(['Training', 'Validation'], loc='lower right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the previous cnn was created putting an increasing number of () in each layer.\n",
    "(previously, it was decreasing), then dropout was added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_33 (Conv3D)           (None, 128, 14, 13, 16)   259328    \n",
      "_________________________________________________________________\n",
      "conv3d_34 (Conv3D)           (None, 64, 12, 11, 14)    221248    \n",
      "_________________________________________________________________\n",
      "max_pooling3d_9 (MaxPooling3 (None, 64, 6, 5, 7)       0         \n",
      "_________________________________________________________________\n",
      "conv3d_35 (Conv3D)           (None, 32, 4, 3, 5)       55328     \n",
      "_________________________________________________________________\n",
      "conv3d_36 (Conv3D)           (None, 32, 2, 1, 3)       27680     \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 192)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 2)                 386       \n",
      "=================================================================\n",
      "Total params: 563,970\n",
      "Trainable params: 563,970\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1750 samples, validate on 293 samples\n",
      "Epoch 1/20\n",
      "1750/1750 [==============================] - 28s - loss: 0.6888 - acc: 0.5623 - val_loss: 0.6786 - val_acc: 0.5700\n",
      "Epoch 2/20\n",
      "1750/1750 [==============================] - 29s - loss: 0.6513 - acc: 0.6229 - val_loss: 0.6418 - val_acc: 0.5973\n",
      "Epoch 3/20\n",
      "1750/1750 [==============================] - 29s - loss: 0.5871 - acc: 0.6680 - val_loss: 0.6096 - val_acc: 0.6792\n",
      "Epoch 4/20\n",
      "1750/1750 [==============================] - 29s - loss: 0.5210 - acc: 0.7400 - val_loss: 0.5296 - val_acc: 0.7235\n",
      "Epoch 5/20\n",
      "1750/1750 [==============================] - 29s - loss: 0.4520 - acc: 0.8057 - val_loss: 0.4756 - val_acc: 0.8328\n",
      "Epoch 6/20\n",
      "1750/1750 [==============================] - 29s - loss: 0.3897 - acc: 0.8389 - val_loss: 0.4303 - val_acc: 0.8191\n",
      "Epoch 7/20\n",
      "1750/1750 [==============================] - 29s - loss: 0.3354 - acc: 0.8600 - val_loss: 0.3908 - val_acc: 0.8635\n",
      "Epoch 8/20\n",
      "1750/1750 [==============================] - 29s - loss: 0.3236 - acc: 0.8634 - val_loss: 0.3933 - val_acc: 0.8532\n",
      "Epoch 9/20\n",
      "1750/1750 [==============================] - 29s - loss: 0.2798 - acc: 0.8886 - val_loss: 0.3774 - val_acc: 0.8771\n",
      "Epoch 10/20\n",
      "1750/1750 [==============================] - 29s - loss: 0.2549 - acc: 0.8983 - val_loss: 0.4393 - val_acc: 0.8601\n",
      "Epoch 11/20\n",
      "1750/1750 [==============================] - 29s - loss: 0.2326 - acc: 0.9109 - val_loss: 0.3863 - val_acc: 0.8908\n",
      "Epoch 12/20\n",
      "1750/1750 [==============================] - 29s - loss: 0.2316 - acc: 0.9080 - val_loss: 0.3784 - val_acc: 0.8908\n",
      "Epoch 13/20\n",
      "1750/1750 [==============================] - 29s - loss: 0.1920 - acc: 0.9269 - val_loss: 0.4140 - val_acc: 0.8805\n",
      "Epoch 14/20\n",
      "1750/1750 [==============================] - 29s - loss: 0.1857 - acc: 0.9286 - val_loss: 0.3906 - val_acc: 0.8771\n",
      "Epoch 15/20\n",
      "1750/1750 [==============================] - 29s - loss: 0.1601 - acc: 0.9434 - val_loss: 0.4190 - val_acc: 0.8942\n",
      "Epoch 16/20\n",
      "1750/1750 [==============================] - 29s - loss: 0.1564 - acc: 0.9429 - val_loss: 0.4300 - val_acc: 0.8771\n",
      "Epoch 17/20\n",
      "1750/1750 [==============================] - 29s - loss: 0.1470 - acc: 0.9451 - val_loss: 0.4581 - val_acc: 0.8840\n",
      "Epoch 18/20\n",
      "1750/1750 [==============================] - 29s - loss: 0.1350 - acc: 0.9514 - val_loss: 0.4664 - val_acc: 0.8908\n",
      "Epoch 19/20\n",
      "1750/1750 [==============================] - 29s - loss: 0.1276 - acc: 0.9531 - val_loss: 0.5087 - val_acc: 0.8840\n",
      "Epoch 20/20\n",
      "1750/1750 [==============================] - 29s - loss: 0.1132 - acc: 0.9589 - val_loss: 0.4845 - val_acc: 0.8976\n",
      "2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_37 (Conv3D)           (None, 128, 14, 13, 16)   259328    \n",
      "_________________________________________________________________\n",
      "conv3d_38 (Conv3D)           (None, 64, 12, 11, 14)    221248    \n",
      "_________________________________________________________________\n",
      "max_pooling3d_10 (MaxPooling (None, 64, 6, 5, 7)       0         \n",
      "_________________________________________________________________\n",
      "conv3d_39 (Conv3D)           (None, 32, 4, 3, 5)       55328     \n",
      "_________________________________________________________________\n",
      "conv3d_40 (Conv3D)           (None, 32, 2, 1, 3)       27680     \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 192)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 2)                 386       \n",
      "=================================================================\n",
      "Total params: 563,970\n",
      "Trainable params: 563,970\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1750 samples, validate on 293 samples\n",
      "Epoch 1/20\n",
      "1750/1750 [==============================] - 22s - loss: 0.6938 - acc: 0.5606 - val_loss: 0.6918 - val_acc: 0.5529\n",
      "Epoch 2/20\n",
      "1750/1750 [==============================] - 23s - loss: 0.6502 - acc: 0.6120 - val_loss: 0.6905 - val_acc: 0.5700\n",
      "Epoch 3/20\n",
      "1750/1750 [==============================] - 24s - loss: 0.6077 - acc: 0.6606 - val_loss: 0.7323 - val_acc: 0.6451\n",
      "Epoch 4/20\n",
      "1750/1750 [==============================] - 24s - loss: 0.5297 - acc: 0.7223 - val_loss: 0.6575 - val_acc: 0.7031\n",
      "Epoch 5/20\n",
      "1750/1750 [==============================] - 24s - loss: 0.4488 - acc: 0.7920 - val_loss: 0.6018 - val_acc: 0.7986\n",
      "Epoch 6/20\n",
      "1750/1750 [==============================] - 24s - loss: 0.4047 - acc: 0.8480 - val_loss: 0.5418 - val_acc: 0.8191\n",
      "Epoch 7/20\n",
      "1750/1750 [==============================] - 24s - loss: 0.3388 - acc: 0.8674 - val_loss: 0.5214 - val_acc: 0.8225\n",
      "Epoch 8/20\n",
      "1750/1750 [==============================] - 24s - loss: 0.2971 - acc: 0.8857 - val_loss: 0.6332 - val_acc: 0.7304\n",
      "Epoch 9/20\n",
      "1750/1750 [==============================] - 24s - loss: 0.2618 - acc: 0.8989 - val_loss: 0.4282 - val_acc: 0.8669\n",
      "Epoch 10/20\n",
      "1750/1750 [==============================] - 24s - loss: 0.2257 - acc: 0.9114 - val_loss: 0.6683 - val_acc: 0.7065\n",
      "Epoch 11/20\n",
      "1750/1750 [==============================] - 24s - loss: 0.2341 - acc: 0.9137 - val_loss: 0.4545 - val_acc: 0.8259\n",
      "Epoch 12/20\n",
      "1750/1750 [==============================] - 24s - loss: 0.1838 - acc: 0.9274 - val_loss: 0.4622 - val_acc: 0.8498\n",
      "Epoch 13/20\n",
      "1750/1750 [==============================] - 24s - loss: 0.1777 - acc: 0.9314 - val_loss: 0.5639 - val_acc: 0.8020\n",
      "Epoch 14/20\n",
      "1750/1750 [==============================] - 24s - loss: 0.1617 - acc: 0.9383 - val_loss: 0.4768 - val_acc: 0.8362\n",
      "Epoch 15/20\n",
      "1750/1750 [==============================] - 24s - loss: 0.1445 - acc: 0.9474 - val_loss: 0.4988 - val_acc: 0.8396\n",
      "Epoch 16/20\n",
      "1750/1750 [==============================] - 24s - loss: 0.1369 - acc: 0.9503 - val_loss: 0.5213 - val_acc: 0.8396\n",
      "Epoch 17/20\n",
      "1750/1750 [==============================] - 24s - loss: 0.1286 - acc: 0.9503 - val_loss: 0.5426 - val_acc: 0.8464\n",
      "Epoch 18/20\n",
      "1750/1750 [==============================] - 24s - loss: 0.1158 - acc: 0.9571 - val_loss: 0.5515 - val_acc: 0.8464\n",
      "Epoch 19/20\n",
      "1750/1750 [==============================] - 24s - loss: 0.0956 - acc: 0.9651 - val_loss: 0.6254 - val_acc: 0.8362\n",
      "Epoch 20/20\n",
      "1750/1750 [==============================] - 24s - loss: 0.0965 - acc: 0.9663 - val_loss: 0.6604 - val_acc: 0.8225\n",
      "3\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_41 (Conv3D)           (None, 128, 14, 13, 16)   259328    \n",
      "_________________________________________________________________\n",
      "conv3d_42 (Conv3D)           (None, 64, 12, 11, 14)    221248    \n",
      "_________________________________________________________________\n",
      "max_pooling3d_11 (MaxPooling (None, 64, 6, 5, 7)       0         \n",
      "_________________________________________________________________\n",
      "conv3d_43 (Conv3D)           (None, 32, 4, 3, 5)       55328     \n",
      "_________________________________________________________________\n",
      "conv3d_44 (Conv3D)           (None, 32, 2, 1, 3)       27680     \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 192)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 2)                 386       \n",
      "=================================================================\n",
      "Total params: 563,970\n",
      "Trainable params: 563,970\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1751 samples, validate on 292 samples\n",
      "Epoch 1/20\n",
      "1751/1751 [==============================] - 25s - loss: 0.6896 - acc: 0.5540 - val_loss: 0.6887 - val_acc: 0.5479\n",
      "Epoch 2/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.6323 - acc: 0.6368 - val_loss: 0.6604 - val_acc: 0.6815\n",
      "Epoch 3/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.5790 - acc: 0.7264 - val_loss: 0.5325 - val_acc: 0.6815\n",
      "Epoch 4/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.4920 - acc: 0.7801 - val_loss: 0.5087 - val_acc: 0.7158\n",
      "Epoch 5/20\n",
      "1751/1751 [==============================] - 23s - loss: 0.4222 - acc: 0.8315 - val_loss: 0.4768 - val_acc: 0.7671\n",
      "Epoch 6/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.3799 - acc: 0.8412 - val_loss: 0.4223 - val_acc: 0.8356\n",
      "Epoch 7/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.3237 - acc: 0.8669 - val_loss: 0.4346 - val_acc: 0.8356\n",
      "Epoch 8/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.2946 - acc: 0.8824 - val_loss: 0.3640 - val_acc: 0.8493\n",
      "Epoch 9/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.2689 - acc: 0.8886 - val_loss: 0.3851 - val_acc: 0.8596\n",
      "Epoch 10/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.2468 - acc: 0.9023 - val_loss: 0.3468 - val_acc: 0.8630\n",
      "Epoch 11/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.2315 - acc: 0.9098 - val_loss: 0.3322 - val_acc: 0.8596\n",
      "Epoch 12/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.2039 - acc: 0.9195 - val_loss: 0.4497 - val_acc: 0.8151\n",
      "Epoch 13/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.2006 - acc: 0.9206 - val_loss: 0.3272 - val_acc: 0.8870\n",
      "Epoch 14/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.1665 - acc: 0.9389 - val_loss: 0.3106 - val_acc: 0.8664\n",
      "Epoch 15/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.1615 - acc: 0.9372 - val_loss: 0.4548 - val_acc: 0.8253\n",
      "Epoch 16/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.1531 - acc: 0.9383 - val_loss: 0.4391 - val_acc: 0.8767\n",
      "Epoch 17/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.1432 - acc: 0.9475 - val_loss: 0.3477 - val_acc: 0.8870\n",
      "Epoch 18/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.1195 - acc: 0.9572 - val_loss: 0.3851 - val_acc: 0.8801\n",
      "Epoch 19/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.1147 - acc: 0.9589 - val_loss: 0.5400 - val_acc: 0.8390\n",
      "Epoch 20/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.1132 - acc: 0.9583 - val_loss: 0.3371 - val_acc: 0.8767\n",
      "4\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_45 (Conv3D)           (None, 128, 14, 13, 16)   259328    \n",
      "_________________________________________________________________\n",
      "conv3d_46 (Conv3D)           (None, 64, 12, 11, 14)    221248    \n",
      "_________________________________________________________________\n",
      "max_pooling3d_12 (MaxPooling (None, 64, 6, 5, 7)       0         \n",
      "_________________________________________________________________\n",
      "conv3d_47 (Conv3D)           (None, 32, 4, 3, 5)       55328     \n",
      "_________________________________________________________________\n",
      "conv3d_48 (Conv3D)           (None, 32, 2, 1, 3)       27680     \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 192)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 2)                 386       \n",
      "=================================================================\n",
      "Total params: 563,970\n",
      "Trainable params: 563,970\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1751 samples, validate on 292 samples\n",
      "Epoch 1/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.6932 - acc: 0.5751 - val_loss: 0.6831 - val_acc: 0.5753\n",
      "Epoch 2/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.6450 - acc: 0.6288 - val_loss: 0.6764 - val_acc: 0.6678\n",
      "Epoch 3/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.5858 - acc: 0.6750 - val_loss: 0.6748 - val_acc: 0.6884\n",
      "Epoch 4/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.5119 - acc: 0.7516 - val_loss: 0.6296 - val_acc: 0.7021\n",
      "Epoch 5/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.4602 - acc: 0.7898 - val_loss: 0.5598 - val_acc: 0.8014\n",
      "Epoch 6/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.4001 - acc: 0.8344 - val_loss: 0.5653 - val_acc: 0.8116\n",
      "Epoch 7/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.3509 - acc: 0.8447 - val_loss: 0.6033 - val_acc: 0.7705\n",
      "Epoch 8/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.3109 - acc: 0.8618 - val_loss: 0.7101 - val_acc: 0.7637\n",
      "Epoch 9/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.2850 - acc: 0.8784 - val_loss: 0.5545 - val_acc: 0.8219\n",
      "Epoch 10/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.2521 - acc: 0.9012 - val_loss: 0.5541 - val_acc: 0.8596\n",
      "Epoch 11/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.2417 - acc: 0.8955 - val_loss: 0.6034 - val_acc: 0.8493\n",
      "Epoch 12/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.2137 - acc: 0.9138 - val_loss: 0.5638 - val_acc: 0.8596\n",
      "Epoch 13/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.1940 - acc: 0.9149 - val_loss: 0.6232 - val_acc: 0.8527\n",
      "Epoch 14/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.1892 - acc: 0.9229 - val_loss: 1.0367 - val_acc: 0.7534\n",
      "Epoch 15/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.1786 - acc: 0.9315 - val_loss: 0.5914 - val_acc: 0.8664\n",
      "Epoch 16/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.1500 - acc: 0.9429 - val_loss: 0.6022 - val_acc: 0.8630\n",
      "Epoch 17/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.1427 - acc: 0.9463 - val_loss: 0.6402 - val_acc: 0.8562\n",
      "Epoch 18/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.1265 - acc: 0.9503 - val_loss: 0.6483 - val_acc: 0.8596\n",
      "Epoch 19/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.1312 - acc: 0.9475 - val_loss: 1.0021 - val_acc: 0.7911\n",
      "Epoch 20/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.1177 - acc: 0.9566 - val_loss: 0.6257 - val_acc: 0.8630\n",
      "5\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_49 (Conv3D)           (None, 128, 14, 13, 16)   259328    \n",
      "_________________________________________________________________\n",
      "conv3d_50 (Conv3D)           (None, 64, 12, 11, 14)    221248    \n",
      "_________________________________________________________________\n",
      "max_pooling3d_13 (MaxPooling (None, 64, 6, 5, 7)       0         \n",
      "_________________________________________________________________\n",
      "conv3d_51 (Conv3D)           (None, 32, 4, 3, 5)       55328     \n",
      "_________________________________________________________________\n",
      "conv3d_52 (Conv3D)           (None, 32, 2, 1, 3)       27680     \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 192)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 2)                 386       \n",
      "=================================================================\n",
      "Total params: 563,970\n",
      "Trainable params: 563,970\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1752 samples, validate on 291 samples\n",
      "Epoch 1/20\n",
      "1752/1752 [==============================] - 25s - loss: 0.6938 - acc: 0.5474 - val_loss: 0.7023 - val_acc: 0.5670\n",
      "Epoch 2/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.6620 - acc: 0.6090 - val_loss: 0.6964 - val_acc: 0.5670\n",
      "Epoch 3/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.6103 - acc: 0.6336 - val_loss: 0.5916 - val_acc: 0.6426\n",
      "Epoch 4/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.5590 - acc: 0.6918 - val_loss: 0.5694 - val_acc: 0.7629\n",
      "Epoch 5/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.4759 - acc: 0.7911 - val_loss: 0.6510 - val_acc: 0.6426\n",
      "Epoch 6/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.4202 - acc: 0.8333 - val_loss: 0.5078 - val_acc: 0.7732\n",
      "Epoch 7/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.3987 - acc: 0.8402 - val_loss: 0.3918 - val_acc: 0.8488\n",
      "Epoch 8/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.3296 - acc: 0.8664 - val_loss: 0.3761 - val_acc: 0.8385\n",
      "Epoch 9/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.3108 - acc: 0.8761 - val_loss: 0.3493 - val_acc: 0.8660\n",
      "Epoch 10/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.2783 - acc: 0.8881 - val_loss: 0.3315 - val_acc: 0.8660\n",
      "Epoch 11/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.2582 - acc: 0.8904 - val_loss: 0.3483 - val_acc: 0.8282\n",
      "Epoch 12/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.2362 - acc: 0.9041 - val_loss: 0.3371 - val_acc: 0.8660\n",
      "Epoch 13/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.2353 - acc: 0.8978 - val_loss: 0.3576 - val_acc: 0.8625\n",
      "Epoch 14/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.2186 - acc: 0.9115 - val_loss: 0.3389 - val_acc: 0.8419\n",
      "Epoch 15/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.1931 - acc: 0.9172 - val_loss: 0.3062 - val_acc: 0.8625\n",
      "Epoch 16/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.1744 - acc: 0.9309 - val_loss: 0.2851 - val_acc: 0.8935\n",
      "Epoch 17/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.1676 - acc: 0.9361 - val_loss: 0.2866 - val_acc: 0.9107\n",
      "Epoch 18/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.1571 - acc: 0.9458 - val_loss: 0.3983 - val_acc: 0.8557\n",
      "Epoch 19/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.1422 - acc: 0.9458 - val_loss: 0.3064 - val_acc: 0.8866\n",
      "Epoch 20/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.1386 - acc: 0.9441 - val_loss: 0.3259 - val_acc: 0.8866\n",
      "6\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_53 (Conv3D)           (None, 128, 14, 13, 16)   259328    \n",
      "_________________________________________________________________\n",
      "conv3d_54 (Conv3D)           (None, 64, 12, 11, 14)    221248    \n",
      "_________________________________________________________________\n",
      "max_pooling3d_14 (MaxPooling (None, 64, 6, 5, 7)       0         \n",
      "_________________________________________________________________\n",
      "conv3d_55 (Conv3D)           (None, 32, 4, 3, 5)       55328     \n",
      "_________________________________________________________________\n",
      "conv3d_56 (Conv3D)           (None, 32, 2, 1, 3)       27680     \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 192)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 2)                 386       \n",
      "=================================================================\n",
      "Total params: 563,970\n",
      "Trainable params: 563,970\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1752 samples, validate on 291 samples\n",
      "Epoch 1/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.6879 - acc: 0.5679 - val_loss: 0.7086 - val_acc: 0.5704\n",
      "Epoch 2/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.6459 - acc: 0.6210 - val_loss: 0.5989 - val_acc: 0.6220\n",
      "Epoch 3/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.5890 - acc: 0.6844 - val_loss: 0.5258 - val_acc: 0.6804\n",
      "Epoch 4/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.4846 - acc: 0.7683 - val_loss: 0.4444 - val_acc: 0.8557\n",
      "Epoch 5/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.4216 - acc: 0.8191 - val_loss: 0.3930 - val_acc: 0.8454\n",
      "Epoch 6/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.3607 - acc: 0.8556 - val_loss: 0.4268 - val_acc: 0.7766\n",
      "Epoch 7/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.3177 - acc: 0.8624 - val_loss: 0.4114 - val_acc: 0.8694\n",
      "Epoch 8/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.2937 - acc: 0.8807 - val_loss: 0.3065 - val_acc: 0.8763\n",
      "Epoch 9/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.2677 - acc: 0.8898 - val_loss: 0.3698 - val_acc: 0.8729\n",
      "Epoch 10/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.2507 - acc: 0.8967 - val_loss: 0.3183 - val_acc: 0.8900\n",
      "Epoch 11/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.2240 - acc: 0.9035 - val_loss: 0.4951 - val_acc: 0.8351\n",
      "Epoch 12/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.2151 - acc: 0.9104 - val_loss: 0.3020 - val_acc: 0.8797\n",
      "Epoch 13/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.1882 - acc: 0.9224 - val_loss: 0.3107 - val_acc: 0.8900\n",
      "Epoch 14/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.1726 - acc: 0.9315 - val_loss: 0.3028 - val_acc: 0.8900\n",
      "Epoch 15/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.1697 - acc: 0.9281 - val_loss: 0.3713 - val_acc: 0.8797\n",
      "Epoch 16/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.1500 - acc: 0.9378 - val_loss: 0.3681 - val_acc: 0.8866\n",
      "Epoch 17/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.1439 - acc: 0.9475 - val_loss: 0.2884 - val_acc: 0.8935\n",
      "Epoch 18/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.1223 - acc: 0.9566 - val_loss: 0.3434 - val_acc: 0.9003\n",
      "Epoch 19/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.1191 - acc: 0.9532 - val_loss: 0.3652 - val_acc: 0.8900\n",
      "Epoch 20/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.1395 - acc: 0.9492 - val_loss: 0.3339 - val_acc: 0.8935\n",
      "7\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_57 (Conv3D)           (None, 128, 14, 13, 16)   259328    \n",
      "_________________________________________________________________\n",
      "conv3d_58 (Conv3D)           (None, 64, 12, 11, 14)    221248    \n",
      "_________________________________________________________________\n",
      "max_pooling3d_15 (MaxPooling (None, 64, 6, 5, 7)       0         \n",
      "_________________________________________________________________\n",
      "conv3d_59 (Conv3D)           (None, 32, 4, 3, 5)       55328     \n",
      "_________________________________________________________________\n",
      "conv3d_60 (Conv3D)           (None, 32, 2, 1, 3)       27680     \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 192)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 2)                 386       \n",
      "=================================================================\n",
      "Total params: 563,970\n",
      "Trainable params: 563,970\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1752 samples, validate on 291 samples\n",
      "Epoch 1/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.6964 - acc: 0.5519 - val_loss: 0.6736 - val_acc: 0.5773\n",
      "Epoch 2/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.6486 - acc: 0.6341 - val_loss: 0.6265 - val_acc: 0.6117\n",
      "Epoch 3/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.5924 - acc: 0.6598 - val_loss: 0.5792 - val_acc: 0.7354\n",
      "Epoch 4/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.5594 - acc: 0.7346 - val_loss: 0.5359 - val_acc: 0.7560\n",
      "Epoch 5/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.4431 - acc: 0.8105 - val_loss: 0.4996 - val_acc: 0.7938\n",
      "Epoch 6/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.3738 - acc: 0.8493 - val_loss: 0.5293 - val_acc: 0.7835\n",
      "Epoch 7/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.3256 - acc: 0.8710 - val_loss: 0.5107 - val_acc: 0.8076\n",
      "Epoch 8/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1752/1752 [==============================] - 24s - loss: 0.2914 - acc: 0.8807 - val_loss: 0.5015 - val_acc: 0.8179\n",
      "Epoch 9/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.2733 - acc: 0.8836 - val_loss: 0.4931 - val_acc: 0.8076\n",
      "Epoch 10/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.2424 - acc: 0.9053 - val_loss: 0.4580 - val_acc: 0.8316\n",
      "Epoch 11/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.2148 - acc: 0.9110 - val_loss: 0.5114 - val_acc: 0.8282\n",
      "Epoch 12/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.1927 - acc: 0.9229 - val_loss: 0.5429 - val_acc: 0.8316\n",
      "Epoch 13/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.1797 - acc: 0.9315 - val_loss: 0.5364 - val_acc: 0.8247\n",
      "Epoch 14/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.1686 - acc: 0.9304 - val_loss: 0.5360 - val_acc: 0.8419\n",
      "Epoch 15/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.1677 - acc: 0.9372 - val_loss: 0.5787 - val_acc: 0.8454\n",
      "Epoch 16/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.1360 - acc: 0.9492 - val_loss: 0.5454 - val_acc: 0.8591\n",
      "Epoch 17/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.1354 - acc: 0.9481 - val_loss: 0.6274 - val_acc: 0.8557\n",
      "Epoch 18/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.1165 - acc: 0.9566 - val_loss: 0.6495 - val_acc: 0.8454\n",
      "Epoch 19/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.1096 - acc: 0.9623 - val_loss: 0.6852 - val_acc: 0.8522\n",
      "Epoch 20/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.1064 - acc: 0.9606 - val_loss: 0.7209 - val_acc: 0.8419\n",
      "Epoch 1/20\n",
      "1752/1752 [==============================] - 23s - loss: 0.1010 - acc: 0.9680    \n",
      "Epoch 2/20\n",
      "1752/1752 [==============================] - 23s - loss: 0.0916 - acc: 0.9692    \n",
      "Epoch 3/20\n",
      "1752/1752 [==============================] - 23s - loss: 0.0821 - acc: 0.9755    \n",
      "Epoch 4/20\n",
      "1752/1752 [==============================] - 23s - loss: 0.0790 - acc: 0.9715    \n",
      "Epoch 5/20\n",
      "1752/1752 [==============================] - 23s - loss: 0.0704 - acc: 0.9795    \n",
      "Epoch 6/20\n",
      "1752/1752 [==============================] - 23s - loss: 0.0687 - acc: 0.9760    \n",
      "Epoch 7/20\n",
      "1752/1752 [==============================] - 22s - loss: 0.0702 - acc: 0.9783    \n",
      "Epoch 8/20\n",
      "1752/1752 [==============================] - 22s - loss: 0.0950 - acc: 0.9737    \n",
      "Epoch 9/20\n",
      "1752/1752 [==============================] - 23s - loss: 0.0544 - acc: 0.9846    \n",
      "Epoch 10/20\n",
      "1752/1752 [==============================] - 23s - loss: 0.0525 - acc: 0.9834    \n",
      "Epoch 11/20\n",
      "1752/1752 [==============================] - 22s - loss: 0.0503 - acc: 0.9869    \n",
      "Epoch 12/20\n",
      "1752/1752 [==============================] - 23s - loss: 0.0465 - acc: 0.9880    \n",
      "Epoch 13/20\n",
      "1752/1752 [==============================] - 23s - loss: 0.0435 - acc: 0.9874    \n",
      "Epoch 14/20\n",
      "1752/1752 [==============================] - 23s - loss: 0.0454 - acc: 0.9869    \n",
      "Epoch 15/20\n",
      "1752/1752 [==============================] - 23s - loss: 0.0363 - acc: 0.9920    \n",
      "Epoch 16/20\n",
      "1752/1752 [==============================] - 23s - loss: 0.0544 - acc: 0.9834    \n",
      "Epoch 17/20\n",
      "1752/1752 [==============================] - 23s - loss: 0.0298 - acc: 0.9943    \n",
      "Epoch 18/20\n",
      "1752/1752 [==============================] - 23s - loss: 0.0268 - acc: 0.9937    \n",
      "Epoch 19/20\n",
      "1752/1752 [==============================] - 23s - loss: 0.0255 - acc: 0.9954    \n",
      "Epoch 20/20\n",
      "1752/1752 [==============================] - 23s - loss: 0.0246 - acc: 0.9960    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.86930983847283405"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cnn first attempt - new dataset + tf with 'channels_first'\n",
    "best_validation_acc = 0.0\n",
    "best_model = None\n",
    "num_classes = 2\n",
    "for i, (train_index, validation_index) in enumerate(skf.split(X_train, Y_train)):\n",
    "    print(i+1)\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", validation_index)\n",
    "    Xtrain, Xvalidation = X_train[train_index], X_train[validation_index]\n",
    "    ytrain, yvalidation = Y_train[train_index], Y_train[validation_index]\n",
    "    model = create_nn_model()\n",
    "    Ytrain = np_utils.to_categorical(ytrain)\n",
    "    Yvalidation = np_utils.to_categorical(yvalidation)\n",
    "    \n",
    "    history = model.fit(Xtrain, Ytrain, batch_size=64,\n",
    "                        epochs=20, verbose=1,\n",
    "                        validation_data = (Xvalidation, Yvalidation))\n",
    "    validation_acc = history.history['val_acc']\n",
    "    if validation_acc > best_validation_acc:\n",
    "        best_validation_acc = validation_acc\n",
    "        best_model = model\n",
    "Ytrain = np_utils.to_categorical(ytrain)\n",
    "best_model.fit(Xtrain, Ytrain, batch_size=64, epochs=20)  # replicate conf.\n",
    "\n",
    "predictions = best_model.predict(X_test)\n",
    "cls_predictions = np.argmax(predictions, axis=1)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(Y_test, cls_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with decreasing ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_61 (Conv3D)           (None, 64, 14, 13, 16)    129664    \n",
      "_________________________________________________________________\n",
      "conv3d_62 (Conv3D)           (None, 128, 12, 11, 14)   221312    \n",
      "_________________________________________________________________\n",
      "max_pooling3d_16 (MaxPooling (None, 128, 6, 5, 7)      0         \n",
      "_________________________________________________________________\n",
      "conv3d_63 (Conv3D)           (None, 256, 4, 3, 5)      884992    \n",
      "_________________________________________________________________\n",
      "conv3d_64 (Conv3D)           (None, 512, 2, 1, 3)      3539456   \n",
      "_________________________________________________________________\n",
      "flatten_16 (Flatten)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 2)                 6146      \n",
      "=================================================================\n",
      "Total params: 4,781,570\n",
      "Trainable params: 4,781,570\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1750 samples, validate on 293 samples\n",
      "Epoch 1/20\n",
      "1750/1750 [==============================] - 22s - loss: 0.6929 - acc: 0.5629 - val_loss: 0.8541 - val_acc: 0.5666\n",
      "Epoch 2/20\n",
      "1750/1750 [==============================] - 22s - loss: 0.6687 - acc: 0.6086 - val_loss: 0.6048 - val_acc: 0.6109\n",
      "Epoch 3/20\n",
      "1750/1750 [==============================] - 23s - loss: 0.5704 - acc: 0.6954 - val_loss: 0.4908 - val_acc: 0.8294\n",
      "Epoch 4/20\n",
      "1750/1750 [==============================] - 23s - loss: 0.4690 - acc: 0.7897 - val_loss: 0.4347 - val_acc: 0.8157\n",
      "Epoch 5/20\n",
      "1750/1750 [==============================] - 23s - loss: 0.3914 - acc: 0.8326 - val_loss: 0.5215 - val_acc: 0.7884\n",
      "Epoch 6/20\n",
      "1750/1750 [==============================] - 24s - loss: 0.3237 - acc: 0.8714 - val_loss: 0.3816 - val_acc: 0.8703\n",
      "Epoch 7/20\n",
      "1750/1750 [==============================] - 24s - loss: 0.2913 - acc: 0.8909 - val_loss: 0.3963 - val_acc: 0.8840\n",
      "Epoch 8/20\n",
      "1750/1750 [==============================] - 24s - loss: 0.2578 - acc: 0.8971 - val_loss: 0.3971 - val_acc: 0.8805\n",
      "Epoch 9/20\n",
      "1750/1750 [==============================] - 24s - loss: 0.2383 - acc: 0.9109 - val_loss: 0.6086 - val_acc: 0.8225\n",
      "Epoch 10/20\n",
      "1750/1750 [==============================] - 24s - loss: 0.2305 - acc: 0.9126 - val_loss: 0.4128 - val_acc: 0.8874\n",
      "Epoch 11/20\n",
      "1750/1750 [==============================] - 24s - loss: 0.1843 - acc: 0.9286 - val_loss: 0.4624 - val_acc: 0.8840\n",
      "Epoch 12/20\n",
      "1750/1750 [==============================] - 24s - loss: 0.1633 - acc: 0.9366 - val_loss: 0.5291 - val_acc: 0.8805\n",
      "Epoch 13/20\n",
      "1750/1750 [==============================] - 24s - loss: 0.1363 - acc: 0.9486 - val_loss: 0.6483 - val_acc: 0.8840\n",
      "Epoch 14/20\n",
      "1750/1750 [==============================] - 24s - loss: 0.1240 - acc: 0.9520 - val_loss: 0.5205 - val_acc: 0.8805\n",
      "Epoch 15/20\n",
      "1750/1750 [==============================] - 24s - loss: 0.1318 - acc: 0.9526 - val_loss: 0.5422 - val_acc: 0.8840\n",
      "Epoch 16/20\n",
      "1750/1750 [==============================] - 24s - loss: 0.1109 - acc: 0.9663 - val_loss: 0.5374 - val_acc: 0.8908\n",
      "Epoch 17/20\n",
      "1750/1750 [==============================] - 24s - loss: 0.0884 - acc: 0.9686 - val_loss: 0.5249 - val_acc: 0.8874\n",
      "Epoch 18/20\n",
      "1750/1750 [==============================] - 24s - loss: 0.0829 - acc: 0.9737 - val_loss: 0.8711 - val_acc: 0.8703\n",
      "Epoch 19/20\n",
      "1750/1750 [==============================] - 24s - loss: 0.0985 - acc: 0.9737 - val_loss: 0.6308 - val_acc: 0.8942\n",
      "Epoch 20/20\n",
      "1750/1750 [==============================] - 24s - loss: 0.0688 - acc: 0.9846 - val_loss: 0.9106 - val_acc: 0.8669\n",
      "2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_65 (Conv3D)           (None, 64, 14, 13, 16)    129664    \n",
      "_________________________________________________________________\n",
      "conv3d_66 (Conv3D)           (None, 128, 12, 11, 14)   221312    \n",
      "_________________________________________________________________\n",
      "max_pooling3d_17 (MaxPooling (None, 128, 6, 5, 7)      0         \n",
      "_________________________________________________________________\n",
      "conv3d_67 (Conv3D)           (None, 256, 4, 3, 5)      884992    \n",
      "_________________________________________________________________\n",
      "conv3d_68 (Conv3D)           (None, 512, 2, 1, 3)      3539456   \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 2)                 6146      \n",
      "=================================================================\n",
      "Total params: 4,781,570\n",
      "Trainable params: 4,781,570\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1750 samples, validate on 293 samples\n",
      "Epoch 1/20\n",
      "1750/1750 [==============================] - 24s - loss: 0.7014 - acc: 0.5697 - val_loss: 0.6837 - val_acc: 0.5734\n",
      "Epoch 2/20\n",
      "1750/1750 [==============================] - 24s - loss: 0.6607 - acc: 0.6154 - val_loss: 0.6642 - val_acc: 0.6826\n",
      "Epoch 3/20\n",
      "1750/1750 [==============================] - 24s - loss: 0.5652 - acc: 0.7149 - val_loss: 0.5750 - val_acc: 0.7918\n",
      "Epoch 4/20\n",
      "1750/1750 [==============================] - 24s - loss: 0.4742 - acc: 0.8046 - val_loss: 0.6013 - val_acc: 0.7167\n",
      "Epoch 5/20\n",
      "1750/1750 [==============================] - 24s - loss: 0.3674 - acc: 0.8406 - val_loss: 0.4393 - val_acc: 0.8259\n",
      "Epoch 6/20\n",
      "1750/1750 [==============================] - 24s - loss: 0.3094 - acc: 0.8760 - val_loss: 0.4470 - val_acc: 0.8464\n",
      "Epoch 7/20\n",
      "1750/1750 [==============================] - 24s - loss: 0.2655 - acc: 0.8931 - val_loss: 0.4515 - val_acc: 0.8259\n",
      "Epoch 8/20\n",
      "1750/1750 [==============================] - 24s - loss: 0.2314 - acc: 0.9126 - val_loss: 0.4348 - val_acc: 0.8498\n",
      "Epoch 9/20\n",
      "1750/1750 [==============================] - 24s - loss: 0.2069 - acc: 0.9229 - val_loss: 0.4949 - val_acc: 0.8532\n",
      "Epoch 10/20\n",
      "1750/1750 [==============================] - 24s - loss: 0.1820 - acc: 0.9303 - val_loss: 0.4715 - val_acc: 0.8635\n",
      "Epoch 11/20\n",
      "1750/1750 [==============================] - 24s - loss: 0.1510 - acc: 0.9491 - val_loss: 0.5692 - val_acc: 0.8567\n",
      "Epoch 12/20\n",
      "1750/1750 [==============================] - 24s - loss: 0.1450 - acc: 0.9469 - val_loss: 0.5757 - val_acc: 0.8191\n",
      "Epoch 13/20\n",
      "1750/1750 [==============================] - 24s - loss: 0.1189 - acc: 0.9543 - val_loss: 0.5589 - val_acc: 0.8362\n",
      "Epoch 14/20\n",
      "1750/1750 [==============================] - 24s - loss: 0.0954 - acc: 0.9691 - val_loss: 0.6412 - val_acc: 0.8703\n",
      "Epoch 15/20\n",
      "1750/1750 [==============================] - 24s - loss: 0.1157 - acc: 0.9691 - val_loss: 0.7486 - val_acc: 0.8259\n",
      "Epoch 16/20\n",
      "1750/1750 [==============================] - 24s - loss: 0.0847 - acc: 0.9771 - val_loss: 0.6860 - val_acc: 0.8430\n",
      "Epoch 17/20\n",
      "1750/1750 [==============================] - 24s - loss: 0.0875 - acc: 0.9754 - val_loss: 0.7417 - val_acc: 0.8362\n",
      "Epoch 18/20\n",
      "1750/1750 [==============================] - 24s - loss: 0.0582 - acc: 0.9880 - val_loss: 0.7220 - val_acc: 0.8464\n",
      "Epoch 19/20\n",
      "1750/1750 [==============================] - 24s - loss: 0.0488 - acc: 0.9897 - val_loss: 0.8216 - val_acc: 0.8703\n",
      "Epoch 20/20\n",
      "1750/1750 [==============================] - 24s - loss: 0.0450 - acc: 0.9903 - val_loss: 0.8783 - val_acc: 0.8259\n",
      "3\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_69 (Conv3D)           (None, 64, 14, 13, 16)    129664    \n",
      "_________________________________________________________________\n",
      "conv3d_70 (Conv3D)           (None, 128, 12, 11, 14)   221312    \n",
      "_________________________________________________________________\n",
      "max_pooling3d_18 (MaxPooling (None, 128, 6, 5, 7)      0         \n",
      "_________________________________________________________________\n",
      "conv3d_71 (Conv3D)           (None, 256, 4, 3, 5)      884992    \n",
      "_________________________________________________________________\n",
      "conv3d_72 (Conv3D)           (None, 512, 2, 1, 3)      3539456   \n",
      "_________________________________________________________________\n",
      "flatten_18 (Flatten)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 2)                 6146      \n",
      "=================================================================\n",
      "Total params: 4,781,570\n",
      "Trainable params: 4,781,570\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1751 samples, validate on 292 samples\n",
      "Epoch 1/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.6981 - acc: 0.5448 - val_loss: 0.6837 - val_acc: 0.5788\n",
      "Epoch 2/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.6624 - acc: 0.6014 - val_loss: 0.6017 - val_acc: 0.6267\n",
      "Epoch 3/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.5848 - acc: 0.6910 - val_loss: 0.5800 - val_acc: 0.6507\n",
      "Epoch 4/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.5210 - acc: 0.7584 - val_loss: 0.4781 - val_acc: 0.7055\n",
      "Epoch 5/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.3845 - acc: 0.8401 - val_loss: 0.4400 - val_acc: 0.8185\n",
      "Epoch 6/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.3140 - acc: 0.8704 - val_loss: 0.3905 - val_acc: 0.8493\n",
      "Epoch 7/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.2894 - acc: 0.8761 - val_loss: 0.3742 - val_acc: 0.8767\n",
      "Epoch 8/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.2418 - acc: 0.8972 - val_loss: 0.5817 - val_acc: 0.8288\n",
      "Epoch 9/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.2193 - acc: 0.9143 - val_loss: 0.3887 - val_acc: 0.8630\n",
      "Epoch 10/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.2074 - acc: 0.9178 - val_loss: 0.3138 - val_acc: 0.8733\n",
      "Epoch 11/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.1696 - acc: 0.9286 - val_loss: 0.3456 - val_acc: 0.8801\n",
      "Epoch 12/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.1488 - acc: 0.9446 - val_loss: 0.5697 - val_acc: 0.8390\n",
      "Epoch 13/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.1517 - acc: 0.9412 - val_loss: 0.3577 - val_acc: 0.8801\n",
      "Epoch 14/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.1216 - acc: 0.9526 - val_loss: 0.4009 - val_acc: 0.8596\n",
      "Epoch 15/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.0969 - acc: 0.9652 - val_loss: 0.4945 - val_acc: 0.8664\n",
      "Epoch 16/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.0916 - acc: 0.9663 - val_loss: 0.4834 - val_acc: 0.8664\n",
      "Epoch 17/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.0797 - acc: 0.9726 - val_loss: 0.5248 - val_acc: 0.8630\n",
      "Epoch 18/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.0838 - acc: 0.9686 - val_loss: 0.5936 - val_acc: 0.8185\n",
      "Epoch 19/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.1438 - acc: 0.9572 - val_loss: 0.3608 - val_acc: 0.8836\n",
      "Epoch 20/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.0519 - acc: 0.9863 - val_loss: 0.4225 - val_acc: 0.8870\n",
      "4\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_73 (Conv3D)           (None, 64, 14, 13, 16)    129664    \n",
      "_________________________________________________________________\n",
      "conv3d_74 (Conv3D)           (None, 128, 12, 11, 14)   221312    \n",
      "_________________________________________________________________\n",
      "max_pooling3d_19 (MaxPooling (None, 128, 6, 5, 7)      0         \n",
      "_________________________________________________________________\n",
      "conv3d_75 (Conv3D)           (None, 256, 4, 3, 5)      884992    \n",
      "_________________________________________________________________\n",
      "conv3d_76 (Conv3D)           (None, 512, 2, 1, 3)      3539456   \n",
      "_________________________________________________________________\n",
      "flatten_19 (Flatten)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 2)                 6146      \n",
      "=================================================================\n",
      "Total params: 4,781,570\n",
      "Trainable params: 4,781,570\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1751 samples, validate on 292 samples\n",
      "Epoch 1/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.7017 - acc: 0.5585 - val_loss: 0.6831 - val_acc: 0.5925\n",
      "Epoch 2/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.6604 - acc: 0.6071 - val_loss: 0.6263 - val_acc: 0.6575\n",
      "Epoch 3/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.5596 - acc: 0.7213 - val_loss: 0.5621 - val_acc: 0.7466\n",
      "Epoch 4/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.4393 - acc: 0.7904 - val_loss: 0.5560 - val_acc: 0.7432\n",
      "Epoch 5/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.3618 - acc: 0.8332 - val_loss: 0.4989 - val_acc: 0.8459\n",
      "Epoch 6/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.2871 - acc: 0.8812 - val_loss: 0.5983 - val_acc: 0.8253\n",
      "Epoch 7/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.2727 - acc: 0.8932 - val_loss: 0.6179 - val_acc: 0.8048\n",
      "Epoch 8/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.2233 - acc: 0.9098 - val_loss: 0.4350 - val_acc: 0.8596\n",
      "Epoch 9/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.2019 - acc: 0.9126 - val_loss: 0.5103 - val_acc: 0.8733\n",
      "Epoch 10/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.1675 - acc: 0.9263 - val_loss: 0.5203 - val_acc: 0.8836\n",
      "Epoch 11/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.1528 - acc: 0.9343 - val_loss: 0.4931 - val_acc: 0.8973\n",
      "Epoch 12/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.1307 - acc: 0.9457 - val_loss: 0.5502 - val_acc: 0.8801\n",
      "Epoch 13/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.1162 - acc: 0.9583 - val_loss: 0.5519 - val_acc: 0.8904\n",
      "Epoch 14/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.1007 - acc: 0.9646 - val_loss: 0.6780 - val_acc: 0.8630\n",
      "Epoch 15/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.0819 - acc: 0.9732 - val_loss: 0.7445 - val_acc: 0.8562\n",
      "Epoch 16/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.0658 - acc: 0.9817 - val_loss: 0.5968 - val_acc: 0.8870\n",
      "Epoch 17/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.0585 - acc: 0.9817 - val_loss: 0.6909 - val_acc: 0.8664\n",
      "Epoch 18/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.0599 - acc: 0.9817 - val_loss: 0.5865 - val_acc: 0.8836\n",
      "Epoch 19/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.0429 - acc: 0.9852 - val_loss: 0.8093 - val_acc: 0.8459\n",
      "Epoch 20/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.0328 - acc: 0.9937 - val_loss: 0.6296 - val_acc: 0.8801\n",
      "5\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_77 (Conv3D)           (None, 64, 14, 13, 16)    129664    \n",
      "_________________________________________________________________\n",
      "conv3d_78 (Conv3D)           (None, 128, 12, 11, 14)   221312    \n",
      "_________________________________________________________________\n",
      "max_pooling3d_20 (MaxPooling (None, 128, 6, 5, 7)      0         \n",
      "_________________________________________________________________\n",
      "conv3d_79 (Conv3D)           (None, 256, 4, 3, 5)      884992    \n",
      "_________________________________________________________________\n",
      "conv3d_80 (Conv3D)           (None, 512, 2, 1, 3)      3539456   \n",
      "_________________________________________________________________\n",
      "flatten_20 (Flatten)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 2)                 6146      \n",
      "=================================================================\n",
      "Total params: 4,781,570\n",
      "Trainable params: 4,781,570\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1752 samples, validate on 291 samples\n",
      "Epoch 1/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.6961 - acc: 0.5314 - val_loss: 0.6828 - val_acc: 0.6082\n",
      "Epoch 2/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.6389 - acc: 0.6290 - val_loss: 0.5626 - val_acc: 0.7457\n",
      "Epoch 3/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.5696 - acc: 0.7334 - val_loss: 0.5453 - val_acc: 0.6598\n",
      "Epoch 4/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.4582 - acc: 0.8168 - val_loss: 0.3749 - val_acc: 0.8282\n",
      "Epoch 5/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.3559 - acc: 0.8630 - val_loss: 0.3274 - val_acc: 0.8557\n",
      "Epoch 6/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.2948 - acc: 0.8876 - val_loss: 0.2643 - val_acc: 0.9003\n",
      "Epoch 7/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.2631 - acc: 0.8938 - val_loss: 0.4266 - val_acc: 0.7526\n",
      "Epoch 8/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.2395 - acc: 0.9053 - val_loss: 0.2949 - val_acc: 0.8797\n",
      "Epoch 9/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.2104 - acc: 0.9144 - val_loss: 0.3396 - val_acc: 0.8454\n",
      "Epoch 10/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.1890 - acc: 0.9315 - val_loss: 0.2603 - val_acc: 0.8969\n",
      "Epoch 11/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.1514 - acc: 0.9424 - val_loss: 0.4212 - val_acc: 0.8591\n",
      "Epoch 12/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.1464 - acc: 0.9395 - val_loss: 0.2752 - val_acc: 0.9038\n",
      "Epoch 13/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.1129 - acc: 0.9635 - val_loss: 0.4788 - val_acc: 0.8694\n",
      "Epoch 14/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.1003 - acc: 0.9663 - val_loss: 0.3740 - val_acc: 0.8832\n",
      "Epoch 15/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.1084 - acc: 0.9629 - val_loss: 0.2774 - val_acc: 0.9072\n",
      "Epoch 16/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.0785 - acc: 0.9795 - val_loss: 0.4109 - val_acc: 0.8832\n",
      "Epoch 17/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.0749 - acc: 0.9749 - val_loss: 0.3632 - val_acc: 0.9038\n",
      "Epoch 18/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.0631 - acc: 0.9846 - val_loss: 0.5329 - val_acc: 0.8797\n",
      "Epoch 19/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.0528 - acc: 0.9869 - val_loss: 0.4826 - val_acc: 0.8935\n",
      "Epoch 20/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.0864 - acc: 0.9732 - val_loss: 0.4256 - val_acc: 0.9003\n",
      "6\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_81 (Conv3D)           (None, 64, 14, 13, 16)    129664    \n",
      "_________________________________________________________________\n",
      "conv3d_82 (Conv3D)           (None, 128, 12, 11, 14)   221312    \n",
      "_________________________________________________________________\n",
      "max_pooling3d_21 (MaxPooling (None, 128, 6, 5, 7)      0         \n",
      "_________________________________________________________________\n",
      "conv3d_83 (Conv3D)           (None, 256, 4, 3, 5)      884992    \n",
      "_________________________________________________________________\n",
      "conv3d_84 (Conv3D)           (None, 512, 2, 1, 3)      3539456   \n",
      "_________________________________________________________________\n",
      "flatten_21 (Flatten)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 2)                 6146      \n",
      "=================================================================\n",
      "Total params: 4,781,570\n",
      "Trainable params: 4,781,570\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1752 samples, validate on 291 samples\n",
      "Epoch 1/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.6973 - acc: 0.5668 - val_loss: 0.6795 - val_acc: 0.5739\n",
      "Epoch 2/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.6479 - acc: 0.6113 - val_loss: 0.5617 - val_acc: 0.6976\n",
      "Epoch 3/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.5856 - acc: 0.7123 - val_loss: 0.4652 - val_acc: 0.7698\n",
      "Epoch 4/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.4597 - acc: 0.8122 - val_loss: 0.4984 - val_acc: 0.8041\n",
      "Epoch 5/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.3720 - acc: 0.8447 - val_loss: 0.4232 - val_acc: 0.7629\n",
      "Epoch 6/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.3024 - acc: 0.8699 - val_loss: 0.2631 - val_acc: 0.8797\n",
      "Epoch 7/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.2720 - acc: 0.8916 - val_loss: 0.2739 - val_acc: 0.8797\n",
      "Epoch 8/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.2260 - acc: 0.9058 - val_loss: 0.3451 - val_acc: 0.8797\n",
      "Epoch 9/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.2111 - acc: 0.9167 - val_loss: 0.3035 - val_acc: 0.8832\n",
      "Epoch 10/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.1842 - acc: 0.9241 - val_loss: 0.5903 - val_acc: 0.7904\n",
      "Epoch 11/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.1607 - acc: 0.9389 - val_loss: 0.3459 - val_acc: 0.8797\n",
      "Epoch 12/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.1513 - acc: 0.9401 - val_loss: 0.3680 - val_acc: 0.8900\n",
      "Epoch 13/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.1493 - acc: 0.9475 - val_loss: 0.2765 - val_acc: 0.9003\n",
      "Epoch 14/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.1062 - acc: 0.9669 - val_loss: 0.4380 - val_acc: 0.8660\n",
      "Epoch 15/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.0910 - acc: 0.9726 - val_loss: 0.3744 - val_acc: 0.8900\n",
      "Epoch 16/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.0845 - acc: 0.9726 - val_loss: 0.3838 - val_acc: 0.8866\n",
      "Epoch 17/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.0717 - acc: 0.9817 - val_loss: 0.3471 - val_acc: 0.9003\n",
      "Epoch 18/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.0652 - acc: 0.9840 - val_loss: 0.4398 - val_acc: 0.8935\n",
      "Epoch 19/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.0551 - acc: 0.9846 - val_loss: 0.4118 - val_acc: 0.9141\n",
      "Epoch 20/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.0654 - acc: 0.9846 - val_loss: 0.3705 - val_acc: 0.8935\n",
      "7\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_85 (Conv3D)           (None, 64, 14, 13, 16)    129664    \n",
      "_________________________________________________________________\n",
      "conv3d_86 (Conv3D)           (None, 128, 12, 11, 14)   221312    \n",
      "_________________________________________________________________\n",
      "max_pooling3d_22 (MaxPooling (None, 128, 6, 5, 7)      0         \n",
      "_________________________________________________________________\n",
      "conv3d_87 (Conv3D)           (None, 256, 4, 3, 5)      884992    \n",
      "_________________________________________________________________\n",
      "conv3d_88 (Conv3D)           (None, 512, 2, 1, 3)      3539456   \n",
      "_________________________________________________________________\n",
      "flatten_22 (Flatten)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 2)                 6146      \n",
      "=================================================================\n",
      "Total params: 4,781,570\n",
      "Trainable params: 4,781,570\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1752 samples, validate on 291 samples\n",
      "Epoch 1/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.7019 - acc: 0.5439 - val_loss: 0.6835 - val_acc: 0.5636\n",
      "Epoch 2/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.6652 - acc: 0.6107 - val_loss: 0.6307 - val_acc: 0.5945\n",
      "Epoch 3/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.5800 - acc: 0.6849 - val_loss: 0.5484 - val_acc: 0.7663\n",
      "Epoch 4/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.4823 - acc: 0.7945 - val_loss: 0.5403 - val_acc: 0.8007\n",
      "Epoch 5/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.3595 - acc: 0.8516 - val_loss: 0.4988 - val_acc: 0.7938\n",
      "Epoch 6/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.3236 - acc: 0.8727 - val_loss: 0.4593 - val_acc: 0.8316\n",
      "Epoch 7/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.2618 - acc: 0.8898 - val_loss: 0.5147 - val_acc: 0.8041\n",
      "Epoch 8/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1752/1752 [==============================] - 24s - loss: 0.2372 - acc: 0.9070 - val_loss: 0.4817 - val_acc: 0.8385\n",
      "Epoch 9/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.1975 - acc: 0.9258 - val_loss: 0.5004 - val_acc: 0.8522\n",
      "Epoch 10/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.1635 - acc: 0.9326 - val_loss: 0.5430 - val_acc: 0.8625\n",
      "Epoch 11/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.1586 - acc: 0.9418 - val_loss: 0.5252 - val_acc: 0.8591\n",
      "Epoch 12/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.1481 - acc: 0.9412 - val_loss: 0.5517 - val_acc: 0.8419\n",
      "Epoch 13/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.1250 - acc: 0.9532 - val_loss: 0.6801 - val_acc: 0.8076\n",
      "Epoch 14/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.1152 - acc: 0.9572 - val_loss: 0.6074 - val_acc: 0.8797\n",
      "Epoch 15/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.0934 - acc: 0.9640 - val_loss: 0.6535 - val_acc: 0.8729\n",
      "Epoch 16/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.0801 - acc: 0.9692 - val_loss: 0.7030 - val_acc: 0.8694\n",
      "Epoch 17/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.0676 - acc: 0.9772 - val_loss: 0.7890 - val_acc: 0.8660\n",
      "Epoch 18/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.0585 - acc: 0.9812 - val_loss: 0.8084 - val_acc: 0.8797\n",
      "Epoch 19/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.0706 - acc: 0.9749 - val_loss: 0.8425 - val_acc: 0.8660\n",
      "Epoch 20/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.0582 - acc: 0.9777 - val_loss: 0.9162 - val_acc: 0.8625\n",
      "Epoch 1/20\n",
      "1752/1752 [==============================] - 23s - loss: 0.1287 - acc: 0.9715    \n",
      "Epoch 2/20\n",
      "1752/1752 [==============================] - 23s - loss: 0.0840 - acc: 0.9772    \n",
      "Epoch 3/20\n",
      "1752/1752 [==============================] - 23s - loss: 0.0520 - acc: 0.9869    \n",
      "Epoch 4/20\n",
      "1752/1752 [==============================] - 23s - loss: 0.0440 - acc: 0.9909    \n",
      "Epoch 5/20\n",
      "1752/1752 [==============================] - 23s - loss: 0.0373 - acc: 0.9926    \n",
      "Epoch 6/20\n",
      "1752/1752 [==============================] - 23s - loss: 0.0430 - acc: 0.9897    \n",
      "Epoch 7/20\n",
      "1752/1752 [==============================] - 23s - loss: 0.0485 - acc: 0.9932    \n",
      "Epoch 8/20\n",
      "1752/1752 [==============================] - 23s - loss: 0.0295 - acc: 0.9960    \n",
      "Epoch 9/20\n",
      "1752/1752 [==============================] - 23s - loss: 0.0250 - acc: 0.9966    \n",
      "Epoch 10/20\n",
      "1752/1752 [==============================] - 23s - loss: 0.0232 - acc: 0.9971    \n",
      "Epoch 11/20\n",
      "1752/1752 [==============================] - 23s - loss: 0.0210 - acc: 0.9977    \n",
      "Epoch 12/20\n",
      "1752/1752 [==============================] - 23s - loss: 0.0200 - acc: 0.9977    \n",
      "Epoch 13/20\n",
      "1752/1752 [==============================] - 23s - loss: 0.0217 - acc: 0.9977    \n",
      "Epoch 14/20\n",
      "1752/1752 [==============================] - 23s - loss: 0.0200 - acc: 0.9966    \n",
      "Epoch 15/20\n",
      "1752/1752 [==============================] - 23s - loss: 0.0167 - acc: 0.9977    \n",
      "Epoch 16/20\n",
      "1752/1752 [==============================] - 23s - loss: 0.0165 - acc: 0.9977    \n",
      "Epoch 17/20\n",
      "1752/1752 [==============================] - 23s - loss: 0.0156 - acc: 0.9983    \n",
      "Epoch 18/20\n",
      "1752/1752 [==============================] - 23s - loss: 0.0151 - acc: 0.9983    \n",
      "Epoch 19/20\n",
      "1752/1752 [==============================] - 23s - loss: 0.0142 - acc: 0.9983    \n",
      "Epoch 20/20\n",
      "1752/1752 [==============================] - 23s - loss: 0.0137 - acc: 0.9983    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.88839941262848754"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cnn first attempt - new dataset + tf with 'channels_first'\n",
    "best_validation_acc = 0.0\n",
    "best_model = None\n",
    "num_classes = 2\n",
    "for i, (train_index, validation_index) in enumerate(skf.split(X_train, Y_train)):\n",
    "    print(i+1)\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", validation_index)\n",
    "    Xtrain, Xvalidation = X_train[train_index], X_train[validation_index]\n",
    "    ytrain, yvalidation = Y_train[train_index], Y_train[validation_index]\n",
    "    model = create_nn_model()\n",
    "    Ytrain = np_utils.to_categorical(ytrain)\n",
    "    Yvalidation = np_utils.to_categorical(yvalidation)\n",
    "    \n",
    "    history = model.fit(Xtrain, Ytrain, batch_size=64,\n",
    "                        epochs=20, verbose=1,\n",
    "                        validation_data = (Xvalidation, Yvalidation))\n",
    "    validation_acc = history.history['val_acc']\n",
    "    if validation_acc > best_validation_acc:\n",
    "        best_validation_acc = validation_acc\n",
    "        best_model = model\n",
    "Ytrain = np_utils.to_categorical(ytrain)\n",
    "best_model.fit(Xtrain, Ytrain, batch_size=64, epochs=20)  # replicate conf.\n",
    "\n",
    "predictions = best_model.predict(X_test)\n",
    "cls_predictions = np.argmax(predictions, axis=1)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(Y_test, cls_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fb0546c8910>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhM3/A8nk+kjoJwdoAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb05697c590>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCCEaSVIQQgjRSJKCEEKIRpIUhBBCNPp/ewoHZ057eQkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb054696110>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure()\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.grid()\n",
    "plt.legend(['Training', 'Validation'])\n",
    "\n",
    "plt.figure()\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.grid()\n",
    "plt.legend(['Training', 'Validation'], loc='lower right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cnn2 - no dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Negative dimension size caused by subtracting 3 from 1 for 'conv3d_93/convolution' (op: 'Conv3D') with input shapes: [?,1,1,2,256], [3,3,3,256,256].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-70ecf263e373>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mXtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXvalidation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalidation_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mytrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myvalidation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalidation_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_nn_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mYtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mytrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mYvalidation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myvalidation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-55-43f8fd332cab>\u001b[0m in \u001b[0;36mcnn_model3\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConv3D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMaxPooling3D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConv3D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cdesio/.local/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    467\u001b[0m                           output_shapes=[self.outputs[0]._keras_shape])\n\u001b[1;32m    468\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m             \u001b[0moutput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    470\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m                 raise TypeError('All layers in a Sequential model '\n",
      "\u001b[0;32m/home/cdesio/.local/lib/python2.7/site-packages/keras/engine/topology.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m             \u001b[0;31m# Actually call the layer, collecting output(s), mask(s), and shape(s).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    597\u001b[0m             \u001b[0moutput_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cdesio/.local/lib/python2.7/site-packages/keras/layers/convolutional.pyc\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m                 \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m                 dilation_rate=self.dilation_rate)\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cdesio/.local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36mconv3d\u001b[0;34m(x, kernel, strides, padding, data_format, dilation_rate)\u001b[0m\n\u001b[1;32m   3303\u001b[0m         \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3304\u001b[0m         \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3305\u001b[0;31m         data_format='NDHWC')\n\u001b[0m\u001b[1;32m   3306\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_postprocess_conv3d_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cdesio/.local/lib/python2.7/site-packages/tensorflow/python/ops/nn_ops.pyc\u001b[0m in \u001b[0;36mconvolution\u001b[0;34m(input, filter, padding, strides, dilation_rate, name, data_format)\u001b[0m\n\u001b[1;32m    668\u001b[0m         \u001b[0mdilation_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdilation_rate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m         \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 670\u001b[0;31m         op=op)\n\u001b[0m\u001b[1;32m    671\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cdesio/.local/lib/python2.7/site-packages/tensorflow/python/ops/nn_ops.pyc\u001b[0m in \u001b[0;36mwith_space_to_batch\u001b[0;34m(input, dilation_rate, padding, op, filter_shape, spatial_dims, data_format)\u001b[0m\n\u001b[1;32m    336\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dilation_rate must be positive\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconst_rate\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 338\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_spatial_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m   \u001b[0;31m# We have two padding contributions. The first is used for converting \"SAME\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cdesio/.local/lib/python2.7/site-packages/tensorflow/python/ops/nn_ops.pyc\u001b[0m in \u001b[0;36mop\u001b[0;34m(input_converted, _, padding)\u001b[0m\n\u001b[1;32m    660\u001b[0m           \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m           \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 662\u001b[0;31m           name=name)\n\u001b[0m\u001b[1;32m    663\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m     return with_space_to_batch(\n",
      "\u001b[0;32m/home/cdesio/.local/lib/python2.7/site-packages/tensorflow/python/ops/nn_ops.pyc\u001b[0m in \u001b[0;36m_non_atrous_convolution\u001b[0;34m(input, filter, padding, data_format, strides, name)\u001b[0m\n\u001b[1;32m    144\u001b[0m           \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m           \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m           name=name)\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cdesio/.local/lib/python2.7/site-packages/tensorflow/python/ops/gen_nn_ops.pyc\u001b[0m in \u001b[0;36mconv3d\u001b[0;34m(input, filter, strides, padding, data_format, name)\u001b[0m\n\u001b[1;32m    524\u001b[0m   result = _op_def_lib.apply_op(\"Conv3D\", input=input, filter=filter,\n\u001b[1;32m    525\u001b[0m                                 \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m                                 data_format=data_format, name=name)\n\u001b[0m\u001b[1;32m    527\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cdesio/.local/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.pyc\u001b[0m in \u001b[0;36mapply_op\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    765\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    766\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 767\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    768\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cdesio/.local/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[1;32m   2506\u001b[0m                     original_op=self._default_original_op, op_def=op_def)\n\u001b[1;32m   2507\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcompute_shapes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2508\u001b[0;31m       \u001b[0mset_shapes_for_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2509\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2510\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_record_op_seen_by_control_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cdesio/.local/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mset_shapes_for_outputs\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   1871\u001b[0m       \u001b[0mshape_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1872\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1873\u001b[0;31m   \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1874\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshapes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1875\u001b[0m     raise RuntimeError(\n",
      "\u001b[0;32m/home/cdesio/.local/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mcall_with_requiring\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   1821\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1822\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1823\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall_cpp_shape_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequire_shape_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m   \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cdesio/.local/lib/python2.7/site-packages/tensorflow/python/framework/common_shapes.pyc\u001b[0m in \u001b[0;36mcall_cpp_shape_fn\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, debug_python_shape_fn, require_shape_fn)\u001b[0m\n\u001b[1;32m    608\u001b[0m     res = _call_cpp_shape_fn_impl(op, input_tensors_needed,\n\u001b[1;32m    609\u001b[0m                                   \u001b[0minput_tensors_as_shapes_needed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m                                   debug_python_shape_fn, require_shape_fn)\n\u001b[0m\u001b[1;32m    611\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m       \u001b[0;31m# Handles the case where _call_cpp_shape_fn_impl calls unknown_shape(op).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cdesio/.local/lib/python2.7/site-packages/tensorflow/python/framework/common_shapes.pyc\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, debug_python_shape_fn, require_shape_fn)\u001b[0m\n\u001b[1;32m    674\u001b[0m       \u001b[0mmissing_shape_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmissing_shape_fn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Negative dimension size caused by subtracting 3 from 1 for 'conv3d_93/convolution' (op: 'Conv3D') with input shapes: [?,1,1,2,256], [3,3,3,256,256]."
     ]
    }
   ],
   "source": [
    "#cnn first attempt - new dataset + tf with 'channels_first'\n",
    "best_validation_acc = 0.0\n",
    "best_model = None\n",
    "num_classes = 2\n",
    "for i, (train_index, validation_index) in enumerate(skf.split(X_train, Y_train)):\n",
    "    print(i+1)\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", validation_index)\n",
    "    Xtrain, Xvalidation = X_train[train_index], X_train[validation_index]\n",
    "    ytrain, yvalidation = Y_train[train_index], Y_train[validation_index]\n",
    "    model = create_nn_model()\n",
    "    Ytrain = np_utils.to_categorical(ytrain)\n",
    "    Yvalidation = np_utils.to_categorical(yvalidation)\n",
    "    \n",
    "    history = model.fit(Xtrain, Ytrain, batch_size=64,\n",
    "                        epochs=20, verbose=1,\n",
    "                        validation_data = (Xvalidation, Yvalidation))\n",
    "    validation_acc = history.history['val_acc']\n",
    "    if validation_acc > best_validation_acc:\n",
    "        best_validation_acc = validation_acc\n",
    "        best_model = model\n",
    "Ytrain = np_utils.to_categorical(ytrain)\n",
    "best_model.fit(Xtrain, Ytrain, batch_size=64, epochs=20)  # replicate conf.\n",
    "\n",
    "predictions = best_model.predict(X_test)\n",
    "cls_predictions = np.argmax(predictions, axis=1)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(Y_test, cls_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_138 (Conv3D)          (None, 128, 14, 13, 16)   259328    \n",
      "_________________________________________________________________\n",
      "conv3d_139 (Conv3D)          (None, 64, 12, 11, 14)    221248    \n",
      "_________________________________________________________________\n",
      "max_pooling3d_36 (MaxPooling (None, 64, 6, 5, 7)       0         \n",
      "_________________________________________________________________\n",
      "conv3d_140 (Conv3D)          (None, 32, 4, 3, 5)       55328     \n",
      "_________________________________________________________________\n",
      "conv3d_141 (Conv3D)          (None, 32, 2, 1, 3)       27680     \n",
      "_________________________________________________________________\n",
      "flatten_34 (Flatten)         (None, 192)               0         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 2)                 386       \n",
      "=================================================================\n",
      "Total params: 563,970\n",
      "Trainable params: 563,970\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1750 samples, validate on 293 samples\n",
      "Epoch 1/20\n",
      "1750/1750 [==============================] - 22s - loss: 0.6890 - acc: 0.5497 - val_loss: 0.6893 - val_acc: 0.5666\n",
      "Epoch 2/20\n",
      "1750/1750 [==============================] - 21s - loss: 0.6611 - acc: 0.6051 - val_loss: 0.6444 - val_acc: 0.6314\n",
      "Epoch 3/20\n",
      "1750/1750 [==============================] - 21s - loss: 0.6107 - acc: 0.6514 - val_loss: 0.5824 - val_acc: 0.6621\n",
      "Epoch 4/20\n",
      "1750/1750 [==============================] - 22s - loss: 0.5208 - acc: 0.7280 - val_loss: 0.5106 - val_acc: 0.7577\n",
      "Epoch 5/20\n",
      "1750/1750 [==============================] - 22s - loss: 0.4613 - acc: 0.8057 - val_loss: 0.4530 - val_acc: 0.8567\n",
      "Epoch 6/20\n",
      "1750/1750 [==============================] - 22s - loss: 0.4132 - acc: 0.8383 - val_loss: 0.4252 - val_acc: 0.8294\n",
      "Epoch 7/20\n",
      "1750/1750 [==============================] - 22s - loss: 0.3638 - acc: 0.8497 - val_loss: 0.3875 - val_acc: 0.8737\n",
      "Epoch 8/20\n",
      "1750/1750 [==============================] - 22s - loss: 0.3468 - acc: 0.8497 - val_loss: 0.3878 - val_acc: 0.8635\n",
      "Epoch 9/20\n",
      "1750/1750 [==============================] - 23s - loss: 0.3051 - acc: 0.8754 - val_loss: 0.3970 - val_acc: 0.8567\n",
      "Epoch 10/20\n",
      "1750/1750 [==============================] - 23s - loss: 0.2819 - acc: 0.8840 - val_loss: 0.4051 - val_acc: 0.8840\n",
      "Epoch 11/20\n",
      "1750/1750 [==============================] - 23s - loss: 0.2512 - acc: 0.9000 - val_loss: 0.4785 - val_acc: 0.8430\n",
      "Epoch 12/20\n",
      "1750/1750 [==============================] - 23s - loss: 0.2453 - acc: 0.9063 - val_loss: 0.3648 - val_acc: 0.8976\n",
      "Epoch 13/20\n",
      "1750/1750 [==============================] - 23s - loss: 0.2036 - acc: 0.9206 - val_loss: 0.4017 - val_acc: 0.8908\n",
      "Epoch 14/20\n",
      "1750/1750 [==============================] - 23s - loss: 0.1968 - acc: 0.9257 - val_loss: 0.4506 - val_acc: 0.8805\n",
      "Epoch 15/20\n",
      "1750/1750 [==============================] - 23s - loss: 0.1768 - acc: 0.9246 - val_loss: 1.1921e-07 - val_acc: 0.4334\n",
      "Epoch 16/20\n",
      "1750/1750 [==============================] - 23s - loss: 1.1921e-07 - acc: 0.4326 - val_loss: 1.1921e-07 - val_acc: 0.4334\n",
      "Epoch 17/20\n",
      "1750/1750 [==============================] - 23s - loss: 1.1921e-07 - acc: 0.4326 - val_loss: 1.1921e-07 - val_acc: 0.4334\n",
      "Epoch 18/20\n",
      "1750/1750 [==============================] - 23s - loss: 1.1921e-07 - acc: 0.4326 - val_loss: 1.1921e-07 - val_acc: 0.4334\n",
      "Epoch 19/20\n",
      "1750/1750 [==============================] - 23s - loss: 1.1921e-07 - acc: 0.4326 - val_loss: 1.1921e-07 - val_acc: 0.4334\n",
      "Epoch 20/20\n",
      "1750/1750 [==============================] - 23s - loss: 1.1921e-07 - acc: 0.4326 - val_loss: 1.1921e-07 - val_acc: 0.4334\n",
      "2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_142 (Conv3D)          (None, 128, 14, 13, 16)   259328    \n",
      "_________________________________________________________________\n",
      "conv3d_143 (Conv3D)          (None, 64, 12, 11, 14)    221248    \n",
      "_________________________________________________________________\n",
      "max_pooling3d_37 (MaxPooling (None, 64, 6, 5, 7)       0         \n",
      "_________________________________________________________________\n",
      "conv3d_144 (Conv3D)          (None, 32, 4, 3, 5)       55328     \n",
      "_________________________________________________________________\n",
      "conv3d_145 (Conv3D)          (None, 32, 2, 1, 3)       27680     \n",
      "_________________________________________________________________\n",
      "flatten_35 (Flatten)         (None, 192)               0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 2)                 386       \n",
      "=================================================================\n",
      "Total params: 563,970\n",
      "Trainable params: 563,970\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1750 samples, validate on 293 samples\n",
      "Epoch 1/20\n",
      "1750/1750 [==============================] - 24s - loss: 0.6907 - acc: 0.5451 - val_loss: 0.6765 - val_acc: 0.5666\n",
      "Epoch 2/20\n",
      "1750/1750 [==============================] - 23s - loss: 0.6574 - acc: 0.6171 - val_loss: 0.6534 - val_acc: 0.5973\n",
      "Epoch 3/20\n",
      "1750/1750 [==============================] - 24s - loss: 0.5872 - acc: 0.6606 - val_loss: 0.6915 - val_acc: 0.7440\n",
      "Epoch 4/20\n",
      "1750/1750 [==============================] - 24s - loss: 0.5050 - acc: 0.7543 - val_loss: 0.5677 - val_acc: 0.7577\n",
      "Epoch 5/20\n",
      "1750/1750 [==============================] - 24s - loss: 0.4447 - acc: 0.8166 - val_loss: 0.5810 - val_acc: 0.7235\n",
      "Epoch 6/20\n",
      "1750/1750 [==============================] - 24s - loss: 0.3746 - acc: 0.8377 - val_loss: 0.5334 - val_acc: 0.7713\n",
      "Epoch 7/20\n",
      "1750/1750 [==============================] - 24s - loss: 0.3360 - acc: 0.8554 - val_loss: 0.4726 - val_acc: 0.8328\n",
      "Epoch 8/20\n",
      "1750/1750 [==============================] - 24s - loss: 0.3050 - acc: 0.8709 - val_loss: 0.4167 - val_acc: 0.8328\n",
      "Epoch 9/20\n",
      "1750/1750 [==============================] - 24s - loss: 0.2802 - acc: 0.8857 - val_loss: 0.3783 - val_acc: 0.8567\n",
      "Epoch 10/20\n",
      "1750/1750 [==============================] - 24s - loss: 0.2544 - acc: 0.8954 - val_loss: 0.4320 - val_acc: 0.8396\n",
      "Epoch 11/20\n",
      "1750/1750 [==============================] - 24s - loss: 0.2223 - acc: 0.9091 - val_loss: 0.5001 - val_acc: 0.8191\n",
      "Epoch 12/20\n",
      "1750/1750 [==============================] - 24s - loss: 0.2003 - acc: 0.9211 - val_loss: 0.4191 - val_acc: 0.8635\n",
      "Epoch 13/20\n",
      "1750/1750 [==============================] - 24s - loss: 0.1772 - acc: 0.9297 - val_loss: 0.4602 - val_acc: 0.8567\n",
      "Epoch 14/20\n",
      "1750/1750 [==============================] - 24s - loss: 0.1635 - acc: 0.9291 - val_loss: 0.4738 - val_acc: 0.8635\n",
      "Epoch 15/20\n",
      "1750/1750 [==============================] - 24s - loss: 0.1436 - acc: 0.9474 - val_loss: 0.4698 - val_acc: 0.8601\n",
      "Epoch 16/20\n",
      "1750/1750 [==============================] - 24s - loss: 0.1233 - acc: 0.9509 - val_loss: 0.5050 - val_acc: 0.8567\n",
      "Epoch 17/20\n",
      "1750/1750 [==============================] - 24s - loss: 0.1376 - acc: 0.9480 - val_loss: 0.4906 - val_acc: 0.8601\n",
      "Epoch 18/20\n",
      "1750/1750 [==============================] - 24s - loss: 0.1066 - acc: 0.9640 - val_loss: 0.5112 - val_acc: 0.8567\n",
      "Epoch 19/20\n",
      "1750/1750 [==============================] - 24s - loss: 0.0899 - acc: 0.9686 - val_loss: 0.5811 - val_acc: 0.8464\n",
      "Epoch 20/20\n",
      "1750/1750 [==============================] - 24s - loss: 0.0855 - acc: 0.9714 - val_loss: 0.5852 - val_acc: 0.8567\n",
      "3\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_146 (Conv3D)          (None, 128, 14, 13, 16)   259328    \n",
      "_________________________________________________________________\n",
      "conv3d_147 (Conv3D)          (None, 64, 12, 11, 14)    221248    \n",
      "_________________________________________________________________\n",
      "max_pooling3d_38 (MaxPooling (None, 64, 6, 5, 7)       0         \n",
      "_________________________________________________________________\n",
      "conv3d_148 (Conv3D)          (None, 32, 4, 3, 5)       55328     \n",
      "_________________________________________________________________\n",
      "conv3d_149 (Conv3D)          (None, 32, 2, 1, 3)       27680     \n",
      "_________________________________________________________________\n",
      "flatten_36 (Flatten)         (None, 192)               0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 2)                 386       \n",
      "=================================================================\n",
      "Total params: 563,970\n",
      "Trainable params: 563,970\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1751 samples, validate on 292 samples\n",
      "Epoch 1/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.6850 - acc: 0.5717 - val_loss: 0.6906 - val_acc: 0.5719\n",
      "Epoch 2/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.6522 - acc: 0.6265 - val_loss: 0.6033 - val_acc: 0.6062\n",
      "Epoch 3/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.5805 - acc: 0.6933 - val_loss: 0.5601 - val_acc: 0.7774\n",
      "Epoch 4/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.4908 - acc: 0.8115 - val_loss: 0.4655 - val_acc: 0.8185\n",
      "Epoch 5/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.4176 - acc: 0.8270 - val_loss: 0.4229 - val_acc: 0.8151\n",
      "Epoch 6/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.3695 - acc: 0.8509 - val_loss: 0.3843 - val_acc: 0.8151\n",
      "Epoch 7/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.3390 - acc: 0.8595 - val_loss: 0.3884 - val_acc: 0.8356\n",
      "Epoch 8/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.3052 - acc: 0.8749 - val_loss: 0.3542 - val_acc: 0.8493\n",
      "Epoch 9/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.2738 - acc: 0.8858 - val_loss: 0.4183 - val_acc: 0.8459\n",
      "Epoch 10/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.2674 - acc: 0.8915 - val_loss: 0.3164 - val_acc: 0.8664\n",
      "Epoch 11/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.2373 - acc: 0.9058 - val_loss: 0.3553 - val_acc: 0.8562\n",
      "Epoch 12/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.2253 - acc: 0.9075 - val_loss: 0.4129 - val_acc: 0.8048\n",
      "Epoch 13/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.2131 - acc: 0.9166 - val_loss: 0.3603 - val_acc: 0.8767\n",
      "Epoch 14/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.1893 - acc: 0.9263 - val_loss: 0.3311 - val_acc: 0.8870\n",
      "Epoch 15/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.1836 - acc: 0.9360 - val_loss: 0.3569 - val_acc: 0.8801\n",
      "Epoch 16/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.1658 - acc: 0.9395 - val_loss: 0.3319 - val_acc: 0.8767\n",
      "Epoch 17/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.1646 - acc: 0.9338 - val_loss: 0.4183 - val_acc: 0.8596\n",
      "Epoch 18/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.1469 - acc: 0.9520 - val_loss: 0.3523 - val_acc: 0.8870\n",
      "Epoch 19/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.1315 - acc: 0.9509 - val_loss: 0.3560 - val_acc: 0.8836\n",
      "Epoch 20/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.1211 - acc: 0.9566 - val_loss: 0.4220 - val_acc: 0.8904\n",
      "4\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_150 (Conv3D)          (None, 128, 14, 13, 16)   259328    \n",
      "_________________________________________________________________\n",
      "conv3d_151 (Conv3D)          (None, 64, 12, 11, 14)    221248    \n",
      "_________________________________________________________________\n",
      "max_pooling3d_39 (MaxPooling (None, 64, 6, 5, 7)       0         \n",
      "_________________________________________________________________\n",
      "conv3d_152 (Conv3D)          (None, 32, 4, 3, 5)       55328     \n",
      "_________________________________________________________________\n",
      "conv3d_153 (Conv3D)          (None, 32, 2, 1, 3)       27680     \n",
      "_________________________________________________________________\n",
      "flatten_37 (Flatten)         (None, 192)               0         \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 2)                 386       \n",
      "=================================================================\n",
      "Total params: 563,970\n",
      "Trainable params: 563,970\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1751 samples, validate on 292 samples\n",
      "Epoch 1/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.6886 - acc: 0.5728 - val_loss: 0.6736 - val_acc: 0.5822\n",
      "Epoch 2/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.6590 - acc: 0.6008 - val_loss: 0.7014 - val_acc: 0.5685\n",
      "Epoch 3/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.5926 - acc: 0.6545 - val_loss: 0.9602 - val_acc: 0.5719\n",
      "Epoch 4/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.5633 - acc: 0.6996 - val_loss: 0.5625 - val_acc: 0.7466\n",
      "Epoch 5/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.4678 - acc: 0.8001 - val_loss: 0.5573 - val_acc: 0.8185\n",
      "Epoch 6/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.4184 - acc: 0.8258 - val_loss: 0.5368 - val_acc: 0.7911\n",
      "Epoch 7/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.3666 - acc: 0.8395 - val_loss: 0.5329 - val_acc: 0.8767\n",
      "Epoch 8/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.3365 - acc: 0.8595 - val_loss: 0.4936 - val_acc: 0.8801\n",
      "Epoch 9/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.3060 - acc: 0.8669 - val_loss: 0.4849 - val_acc: 0.8493\n",
      "Epoch 10/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.2813 - acc: 0.8766 - val_loss: 0.4493 - val_acc: 0.8733\n",
      "Epoch 11/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.2549 - acc: 0.8932 - val_loss: 0.4602 - val_acc: 0.8493\n",
      "Epoch 12/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.2340 - acc: 0.9063 - val_loss: 0.4845 - val_acc: 0.8630\n",
      "Epoch 13/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.2267 - acc: 0.9109 - val_loss: 0.4547 - val_acc: 0.8767\n",
      "Epoch 14/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.1960 - acc: 0.9229 - val_loss: 0.4681 - val_acc: 0.8733\n",
      "Epoch 15/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.1901 - acc: 0.9200 - val_loss: 0.4911 - val_acc: 0.8767\n",
      "Epoch 16/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.1783 - acc: 0.9286 - val_loss: 0.5194 - val_acc: 0.8801\n",
      "Epoch 17/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.1711 - acc: 0.9332 - val_loss: 0.5008 - val_acc: 0.8767\n",
      "Epoch 18/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.1538 - acc: 0.9389 - val_loss: 0.5303 - val_acc: 0.8733\n",
      "Epoch 19/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.1368 - acc: 0.9486 - val_loss: 0.5279 - val_acc: 0.8836\n",
      "Epoch 20/20\n",
      "1751/1751 [==============================] - 24s - loss: 0.1247 - acc: 0.9515 - val_loss: 0.5950 - val_acc: 0.8630\n",
      "5\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_154 (Conv3D)          (None, 128, 14, 13, 16)   259328    \n",
      "_________________________________________________________________\n",
      "conv3d_155 (Conv3D)          (None, 64, 12, 11, 14)    221248    \n",
      "_________________________________________________________________\n",
      "max_pooling3d_40 (MaxPooling (None, 64, 6, 5, 7)       0         \n",
      "_________________________________________________________________\n",
      "conv3d_156 (Conv3D)          (None, 32, 4, 3, 5)       55328     \n",
      "_________________________________________________________________\n",
      "conv3d_157 (Conv3D)          (None, 32, 2, 1, 3)       27680     \n",
      "_________________________________________________________________\n",
      "flatten_38 (Flatten)         (None, 192)               0         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 2)                 386       \n",
      "=================================================================\n",
      "Total params: 563,970\n",
      "Trainable params: 563,970\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1752 samples, validate on 291 samples\n",
      "Epoch 1/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.6878 - acc: 0.5662 - val_loss: 0.6696 - val_acc: 0.6117\n",
      "Epoch 2/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.6489 - acc: 0.6073 - val_loss: 0.6071 - val_acc: 0.7285\n",
      "Epoch 3/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.5875 - acc: 0.6872 - val_loss: 0.5235 - val_acc: 0.7869\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1752/1752 [==============================] - 24s - loss: 0.4961 - acc: 0.7934 - val_loss: 0.5869 - val_acc: 0.6460\n",
      "Epoch 5/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.4392 - acc: 0.8253 - val_loss: 0.3853 - val_acc: 0.8247\n",
      "Epoch 6/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.3594 - acc: 0.8373 - val_loss: 0.3464 - val_acc: 0.8419\n",
      "Epoch 7/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.3286 - acc: 0.8596 - val_loss: 0.3276 - val_acc: 0.8522\n",
      "Epoch 8/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.2979 - acc: 0.8750 - val_loss: 0.3244 - val_acc: 0.8591\n",
      "Epoch 9/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.2779 - acc: 0.8847 - val_loss: 0.3409 - val_acc: 0.8316\n",
      "Epoch 10/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.2548 - acc: 0.8973 - val_loss: 0.3018 - val_acc: 0.8797\n",
      "Epoch 11/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.2356 - acc: 0.9007 - val_loss: 0.3000 - val_acc: 0.8866\n",
      "Epoch 12/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.2136 - acc: 0.9115 - val_loss: 0.2783 - val_acc: 0.9038\n",
      "Epoch 13/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.2036 - acc: 0.9144 - val_loss: 0.2550 - val_acc: 0.9038\n",
      "Epoch 14/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.1829 - acc: 0.9247 - val_loss: 0.2848 - val_acc: 0.8591\n",
      "Epoch 15/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.1677 - acc: 0.9355 - val_loss: 0.5202 - val_acc: 0.8282\n",
      "Epoch 16/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.1558 - acc: 0.9429 - val_loss: 0.3393 - val_acc: 0.8832\n",
      "Epoch 17/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.1369 - acc: 0.9463 - val_loss: 0.3171 - val_acc: 0.8969\n",
      "Epoch 18/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.1448 - acc: 0.9435 - val_loss: 0.3746 - val_acc: 0.8282\n",
      "Epoch 19/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.1290 - acc: 0.9509 - val_loss: 0.3063 - val_acc: 0.8935\n",
      "Epoch 20/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.1104 - acc: 0.9578 - val_loss: 0.3535 - val_acc: 0.8866\n",
      "6\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_158 (Conv3D)          (None, 128, 14, 13, 16)   259328    \n",
      "_________________________________________________________________\n",
      "conv3d_159 (Conv3D)          (None, 64, 12, 11, 14)    221248    \n",
      "_________________________________________________________________\n",
      "max_pooling3d_41 (MaxPooling (None, 64, 6, 5, 7)       0         \n",
      "_________________________________________________________________\n",
      "conv3d_160 (Conv3D)          (None, 32, 4, 3, 5)       55328     \n",
      "_________________________________________________________________\n",
      "conv3d_161 (Conv3D)          (None, 32, 2, 1, 3)       27680     \n",
      "_________________________________________________________________\n",
      "flatten_39 (Flatten)         (None, 192)               0         \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 2)                 386       \n",
      "=================================================================\n",
      "Total params: 563,970\n",
      "Trainable params: 563,970\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1752 samples, validate on 291 samples\n",
      "Epoch 1/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.6924 - acc: 0.5588 - val_loss: 0.6789 - val_acc: 0.5911\n",
      "Epoch 2/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.6508 - acc: 0.5970 - val_loss: 0.6232 - val_acc: 0.6529\n",
      "Epoch 3/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.6000 - acc: 0.6393 - val_loss: 0.6073 - val_acc: 0.7079\n",
      "Epoch 4/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.5383 - acc: 0.7095 - val_loss: 0.4771 - val_acc: 0.7663\n",
      "Epoch 5/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.3004 - acc: 0.6484 - val_loss: 1.1921e-07 - val_acc: 0.4330\n",
      "Epoch 6/20\n",
      "1752/1752 [==============================] - 24s - loss: 1.1921e-07 - acc: 0.4326 - val_loss: 1.1921e-07 - val_acc: 0.4330\n",
      "Epoch 7/20\n",
      "1752/1752 [==============================] - 24s - loss: 1.1921e-07 - acc: 0.4326 - val_loss: 1.1921e-07 - val_acc: 0.4330\n",
      "Epoch 8/20\n",
      "1752/1752 [==============================] - 24s - loss: 1.1921e-07 - acc: 0.4326 - val_loss: 1.1921e-07 - val_acc: 0.4330\n",
      "Epoch 9/20\n",
      "1752/1752 [==============================] - 24s - loss: 1.1921e-07 - acc: 0.4326 - val_loss: 1.1921e-07 - val_acc: 0.4330\n",
      "Epoch 10/20\n",
      "1752/1752 [==============================] - 24s - loss: 1.1921e-07 - acc: 0.4326 - val_loss: 1.1921e-07 - val_acc: 0.4330\n",
      "Epoch 11/20\n",
      "1752/1752 [==============================] - 24s - loss: 1.1921e-07 - acc: 0.4326 - val_loss: 1.1921e-07 - val_acc: 0.4330\n",
      "Epoch 12/20\n",
      "1752/1752 [==============================] - 24s - loss: 1.1921e-07 - acc: 0.4326 - val_loss: 1.1921e-07 - val_acc: 0.4330\n",
      "Epoch 13/20\n",
      "1752/1752 [==============================] - 24s - loss: 1.1921e-07 - acc: 0.4326 - val_loss: 1.1921e-07 - val_acc: 0.4330\n",
      "Epoch 14/20\n",
      "1752/1752 [==============================] - 24s - loss: 1.1921e-07 - acc: 0.4326 - val_loss: 1.1921e-07 - val_acc: 0.4330\n",
      "Epoch 15/20\n",
      "1752/1752 [==============================] - 24s - loss: 1.1921e-07 - acc: 0.4326 - val_loss: 1.1921e-07 - val_acc: 0.4330\n",
      "Epoch 16/20\n",
      "1752/1752 [==============================] - 24s - loss: 1.1921e-07 - acc: 0.4326 - val_loss: 1.1921e-07 - val_acc: 0.4330\n",
      "Epoch 17/20\n",
      "1752/1752 [==============================] - 24s - loss: 1.1921e-07 - acc: 0.4326 - val_loss: 1.1921e-07 - val_acc: 0.4330\n",
      "Epoch 18/20\n",
      "1752/1752 [==============================] - 24s - loss: 1.1921e-07 - acc: 0.4326 - val_loss: 1.1921e-07 - val_acc: 0.4330\n",
      "Epoch 19/20\n",
      "1752/1752 [==============================] - 24s - loss: 1.1921e-07 - acc: 0.4326 - val_loss: 1.1921e-07 - val_acc: 0.4330\n",
      "Epoch 20/20\n",
      "1752/1752 [==============================] - 24s - loss: 1.1921e-07 - acc: 0.4326 - val_loss: 1.1921e-07 - val_acc: 0.4330\n",
      "7\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_162 (Conv3D)          (None, 128, 14, 13, 16)   259328    \n",
      "_________________________________________________________________\n",
      "conv3d_163 (Conv3D)          (None, 64, 12, 11, 14)    221248    \n",
      "_________________________________________________________________\n",
      "max_pooling3d_42 (MaxPooling (None, 64, 6, 5, 7)       0         \n",
      "_________________________________________________________________\n",
      "conv3d_164 (Conv3D)          (None, 32, 4, 3, 5)       55328     \n",
      "_________________________________________________________________\n",
      "conv3d_165 (Conv3D)          (None, 32, 2, 1, 3)       27680     \n",
      "_________________________________________________________________\n",
      "flatten_40 (Flatten)         (None, 192)               0         \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 2)                 386       \n",
      "=================================================================\n",
      "Total params: 563,970\n",
      "Trainable params: 563,970\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1752 samples, validate on 291 samples\n",
      "Epoch 1/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.6867 - acc: 0.5696 - val_loss: 0.6694 - val_acc: 0.5808\n",
      "Epoch 2/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.6475 - acc: 0.6107 - val_loss: 0.6055 - val_acc: 0.6117\n",
      "Epoch 3/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.5632 - acc: 0.7003 - val_loss: 0.5284 - val_acc: 0.7904\n",
      "Epoch 4/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.4737 - acc: 0.8002 - val_loss: 0.5540 - val_acc: 0.7216\n",
      "Epoch 5/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.4103 - acc: 0.8288 - val_loss: 0.4763 - val_acc: 0.7973\n",
      "Epoch 6/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.3480 - acc: 0.8602 - val_loss: 0.4574 - val_acc: 0.8213\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1752/1752 [==============================] - 24s - loss: 0.3081 - acc: 0.8704 - val_loss: 0.4397 - val_acc: 0.8488\n",
      "Epoch 8/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.2809 - acc: 0.8876 - val_loss: 0.4808 - val_acc: 0.8282\n",
      "Epoch 9/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.2632 - acc: 0.8921 - val_loss: 0.4108 - val_acc: 0.8591\n",
      "Epoch 10/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.2255 - acc: 0.9070 - val_loss: 0.4383 - val_acc: 0.8694\n",
      "Epoch 11/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.2172 - acc: 0.9144 - val_loss: 0.4272 - val_acc: 0.8419\n",
      "Epoch 12/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.2017 - acc: 0.9201 - val_loss: 0.5559 - val_acc: 0.8110\n",
      "Epoch 13/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.1830 - acc: 0.9252 - val_loss: 0.4452 - val_acc: 0.8694\n",
      "Epoch 14/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.1679 - acc: 0.9366 - val_loss: 0.4094 - val_acc: 0.8729\n",
      "Epoch 15/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.1518 - acc: 0.9406 - val_loss: 0.4456 - val_acc: 0.8729\n",
      "Epoch 16/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.1357 - acc: 0.9492 - val_loss: 0.4577 - val_acc: 0.8763\n",
      "Epoch 17/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.1282 - acc: 0.9481 - val_loss: 0.5551 - val_acc: 0.8385\n",
      "Epoch 18/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.1238 - acc: 0.9521 - val_loss: 0.4676 - val_acc: 0.8694\n",
      "Epoch 19/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.1373 - acc: 0.9441 - val_loss: 0.4579 - val_acc: 0.8797\n",
      "Epoch 20/20\n",
      "1752/1752 [==============================] - 24s - loss: 0.0942 - acc: 0.9629 - val_loss: 0.4988 - val_acc: 0.8866\n",
      "Epoch 1/20\n",
      "1752/1752 [==============================] - 23s - loss: 0.1392 - acc: 0.9452    \n",
      "Epoch 2/20\n",
      "1752/1752 [==============================] - 23s - loss: 0.1102 - acc: 0.9583    \n",
      "Epoch 3/20\n",
      "1752/1752 [==============================] - 23s - loss: 0.0965 - acc: 0.9658    \n",
      "Epoch 4/20\n",
      "1752/1752 [==============================] - 23s - loss: 0.0864 - acc: 0.9709    \n",
      "Epoch 5/20\n",
      "1752/1752 [==============================] - 23s - loss: 0.0958 - acc: 0.9640    \n",
      "Epoch 6/20\n",
      "1752/1752 [==============================] - 23s - loss: 0.0779 - acc: 0.9709    \n",
      "Epoch 7/20\n",
      "1752/1752 [==============================] - 23s - loss: 0.0650 - acc: 0.9783    \n",
      "Epoch 8/20\n",
      "1752/1752 [==============================] - 23s - loss: 0.0603 - acc: 0.9800    \n",
      "Epoch 9/20\n",
      "1752/1752 [==============================] - 23s - loss: 0.0556 - acc: 0.9829    \n",
      "Epoch 10/20\n",
      "1752/1752 [==============================] - 23s - loss: 0.0519 - acc: 0.9852    \n",
      "Epoch 11/20\n",
      "1752/1752 [==============================] - 23s - loss: 0.0474 - acc: 0.9880    \n",
      "Epoch 12/20\n",
      "1752/1752 [==============================] - 23s - loss: 0.0418 - acc: 0.9897    \n",
      "Epoch 13/20\n",
      "1752/1752 [==============================] - 23s - loss: 0.0371 - acc: 0.9892    \n",
      "Epoch 14/20\n",
      "1752/1752 [==============================] - 23s - loss: 0.0459 - acc: 0.9852    \n",
      "Epoch 15/20\n",
      "1752/1752 [==============================] - 23s - loss: 0.0342 - acc: 0.9914    \n",
      "Epoch 16/20\n",
      "1752/1752 [==============================] - 23s - loss: 0.0269 - acc: 0.9932    \n",
      "Epoch 17/20\n",
      "1752/1752 [==============================] - 23s - loss: 0.0245 - acc: 0.9932    \n",
      "Epoch 18/20\n",
      "1752/1752 [==============================] - 23s - loss: 0.0228 - acc: 0.9937    \n",
      "Epoch 19/20\n",
      "1752/1752 [==============================] - 23s - loss: 0.0259 - acc: 0.9932    \n",
      "Epoch 20/20\n",
      "1752/1752 [==============================] - 23s - loss: 0.0330 - acc: 0.9920    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.90014684287812041"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cnn_sigmoid in the last layer\n",
    "#cnn first attempt - new dataset + tf with 'channels_first'\n",
    "best_validation_acc = 0.0\n",
    "best_model = None\n",
    "num_classes = 2\n",
    "for i, (train_index, validation_index) in enumerate(skf.split(X_train, Y_train)):\n",
    "    print(i+1)\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", validation_index)\n",
    "    Xtrain, Xvalidation = X_train[train_index], X_train[validation_index]\n",
    "    ytrain, yvalidation = Y_train[train_index], Y_train[validation_index]\n",
    "    model = create_nn_model()\n",
    "    Ytrain = np_utils.to_categorical(ytrain)\n",
    "    Yvalidation = np_utils.to_categorical(yvalidation)\n",
    "    \n",
    "    history = model.fit(Xtrain, Ytrain, batch_size=64,\n",
    "                        epochs=20, verbose=1,\n",
    "                        validation_data = (Xvalidation, Yvalidation), shuffle = False)\n",
    "    validation_acc = history.history['val_acc']\n",
    "    if validation_acc > best_validation_acc:\n",
    "        best_validation_acc = validation_acc\n",
    "        best_model = model\n",
    "Ytrain = np_utils.to_categorical(ytrain)\n",
    "best_history = best_model.fit(Xtrain, Ytrain, batch_size=64, epochs=20, shuffle=False)  # replicate conf.\n",
    "\n",
    "predictions = best_model.predict(X_test)\n",
    "cls_predictions = np.argmax(predictions, axis=1)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(Y_test, cls_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1752/1752 [==============================] - 20s - loss: 0.0271 - acc: 0.9937    \n",
      "Epoch 2/30\n",
      "1752/1752 [==============================] - 21s - loss: 0.0258 - acc: 0.9943    \n",
      "Epoch 3/30\n",
      "1752/1752 [==============================] - 22s - loss: 0.0245 - acc: 0.9954    \n",
      "Epoch 4/30\n",
      "1752/1752 [==============================] - 23s - loss: 0.0234 - acc: 0.9954    \n",
      "Epoch 5/30\n",
      "1752/1752 [==============================] - 23s - loss: 0.0226 - acc: 0.9966    \n",
      "Epoch 6/30\n",
      "1752/1752 [==============================] - 23s - loss: 0.0340 - acc: 0.9903    \n",
      "Epoch 7/30\n",
      "1752/1752 [==============================] - 23s - loss: 0.0346 - acc: 0.9932    \n",
      "Epoch 8/30\n",
      "1752/1752 [==============================] - 23s - loss: 0.0206 - acc: 0.9966    \n",
      "Epoch 9/30\n",
      "1752/1752 [==============================] - 23s - loss: 0.0192 - acc: 0.9971    \n",
      "Epoch 10/30\n",
      "1752/1752 [==============================] - 23s - loss: 0.0186 - acc: 0.9971    \n",
      "Epoch 11/30\n",
      "1752/1752 [==============================] - 23s - loss: 0.0181 - acc: 0.9977    \n",
      "Epoch 12/30\n",
      "1752/1752 [==============================] - 23s - loss: 0.0179 - acc: 0.9977    \n",
      "Epoch 13/30\n",
      "1752/1752 [==============================] - 23s - loss: 0.0172 - acc: 0.9977    \n",
      "Epoch 14/30\n",
      "1752/1752 [==============================] - 23s - loss: 0.0167 - acc: 0.9977    \n",
      "Epoch 15/30\n",
      "1752/1752 [==============================] - 23s - loss: 0.0160 - acc: 0.9977    \n",
      "Epoch 16/30\n",
      "1752/1752 [==============================] - 23s - loss: 0.0522 - acc: 0.9903    \n",
      "Epoch 17/30\n",
      "1752/1752 [==============================] - 23s - loss: 0.0291 - acc: 0.9949    \n",
      "Epoch 18/30\n",
      "1752/1752 [==============================] - 23s - loss: 0.0162 - acc: 0.9983    \n",
      "Epoch 19/30\n",
      "1752/1752 [==============================] - 23s - loss: 0.0159 - acc: 0.9983    \n",
      "Epoch 20/30\n",
      "1752/1752 [==============================] - 23s - loss: 0.0155 - acc: 0.9983    \n",
      "Epoch 21/30\n",
      "1752/1752 [==============================] - 23s - loss: 0.0152 - acc: 0.9983    \n",
      "Epoch 22/30\n",
      "1752/1752 [==============================] - 23s - loss: 0.0149 - acc: 0.9983    \n",
      "Epoch 23/30\n",
      "1752/1752 [==============================] - 23s - loss: 0.0147 - acc: 0.9977    \n",
      "Epoch 24/30\n",
      "1752/1752 [==============================] - 23s - loss: 0.0145 - acc: 0.9977    \n",
      "Epoch 25/30\n",
      "1752/1752 [==============================] - 23s - loss: 0.0143 - acc: 0.9977    \n",
      "Epoch 26/30\n",
      "1752/1752 [==============================] - 23s - loss: 0.0139 - acc: 0.9977    \n",
      "Epoch 27/30\n",
      "1752/1752 [==============================] - 23s - loss: 0.0136 - acc: 0.9977    \n",
      "Epoch 28/30\n",
      "1752/1752 [==============================] - 23s - loss: 0.0483 - acc: 0.9909    \n",
      "Epoch 29/30\n",
      "1752/1752 [==============================] - 23s - loss: 0.0138 - acc: 0.9983    \n",
      "Epoch 30/30\n",
      "1752/1752 [==============================] - 23s - loss: 0.0136 - acc: 0.9983    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.88839941262848754"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_history = best_model.fit(Xtrain, Ytrain, batch_size=64, epochs=30, shuffle=False)  # replicate conf.\n",
    "\n",
    "predictions = best_model.predict(X_test)\n",
    "cls_predictions = np.argmax(predictions, axis=1)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(Y_test, cls_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7faf256d6210>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7faf25777b10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEKCAYAAAAB0GKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7faf25698150>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure()\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.grid()\n",
    "plt.legend(['Training', 'Validation'])\n",
    "\n",
    "plt.figure()\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.grid()\n",
    "plt.legend(['Training', 'Validation'], loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7faf25824850>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEKCAYAAAA4t9PUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xl8XOV56PHfM6PVGi2WZMkrlrwEMAkYowAJJIgQUqBJ\nna0ppEkIaevQS0japC1Obz83lKb30jQrCYWQhBSyQGjSJA4QCAGrhBADBozxImPh3ZYsWV40Y2lG\nGum5f5wz8nisZTSLZs74+X4++mjmLDPv6yPPM+9y3kdUFWOMMSZVvlwXwBhjjLdZIDHGGJMWCyTG\nGGPSYoHEGGNMWiyQGGOMSYsFEmOMMWmxQGKMMSYtFkiMMcakxQKJMcaYtBTlugDTob6+XpuamlI6\n9/jx41RUVGS2QDlWaHUqtPpA4dWp0OoDhVenserz4osvHlLVWZOde1oEkqamJtavX5/SuW1tbbS2\ntma2QDlWaHUqtPpA4dWp0OoDhVenseojIruTOde6towxxqTFAokxxpi0WCAxxhiTltNijMQYc3oZ\nGhpi3759hMPhrL1HdXU1W7duzdrrT6eysjJEJOXzLZAYYwrOvn37qKyspKmpKa0PyIkEg0EqKyuz\n8trTSVXp7e1NawaadW0ZYwpOOBymrq4ua0GkkIgIdXV1+P3+lF/DAokxpiBZEEleuv9WFkiMySOq\nyn+t30tk2FJgG++wQGJMHnm9J8Tf/3Qj67uiuS6KSUNvby/Lly9n+fLlzJ49m3nz5o0+HxwcTOo1\nbrjhBrZt2zbhMXfeeSc/+tGPMlHktNhguzF55Gj/EADHItYi8bK6ujo2bNgAwK233kogEODv/u7v\nTjpGVVFVfL6xv89///vfn/R9brrppvQLmwHWIjEmjwQjTkvk2KAFkkLU0dHBsmXL+PM//3POOecc\nOjs7WbVqFS0tLZxzzjncdttto8deeumlbNiwgWg0Sk1NDatXr+a8887jLW95C93d3QD80z/9E1//\n+tdHj1+9ejUXXnghZ555Js8++yzgrKH1gQ98gGXLlvHBD36QlpaW0SCXKdYiMSaPBMNOIOmzQJIx\n//yrzWw50JfR11w2t4rPtp6R0rnt7e3cf//9tLS0AHD77bdTW1tLNBrl8ssv54Mf/CDLli076Zxj\nx45x2WWXcfvtt/PZz36We++9l9WrV5/y2qrK888/z5o1a7jtttt47LHH+OY3v8ns2bP52c9+xiuv\nvMKKFStSKvdErEViTB4JxQKJdW0VrMWLF48GEYAHHniAFStWsGLFCrZu3cqWLVtOOae8vJyrr74a\ngAsuuIBdu3aN+drvf//7TznmmWee4dprrwXgvPPO45xzzslgbRzWIjEmjwTDzhhJX3LjsSYJX3hP\n5j84wbkhMRXxN/5t376db3zjGzz//PPU1NTwkY98ZMy78UtKSkYf+/1+otGxJ2OUlpZOekw2WIvE\nmDwSiljX1umkr6+PyspKqqqq6Ozs5PHHH8/4e1xyySU89NBDALz66qtjtnjSZS0SY/JIbIwkOKiM\njCg+n91UV8hWrFjBsmXLOOuss1i4cCGXXHJJxt/j5ptv5mMf+xjLli0b/amurs7oe2Q1kIjIVcA3\nAD/wXVW9PWG/uPuvAfqBj6vqS+6+XUAQGAaiqtribq8FfgI0AbuAD6nqkWzWw5jpEgskIwpH+gep\nC5TmuEQmXbfeeuvo4yVLlpw0Y0pE+MEPfjDmec8888zo46NHj44+vvbaa0fHPL74xS+Oefzs2bPp\n6OgAnAUZf/zjH1NWVsb27dt517vexYIFC9KrVIKsBRIR8QN3AlcC+4AXRGSNqsa3q64Glro/FwF3\nub9jLlfVQwkvvRp4UlVvF5HV7vNbslQNY6ZVKDI0+rj3uAUSk75QKMQVV1xBNBpFVfn2t79NUVFm\nP/qz2SK5EOhQ1R0AIvIgsBKIDyQrgftVVYF1IlIjInNUtXOC110JtLqP7wPasEBiCkQwHEUEVOFQ\nMMIbGr2/uqzJrZqaGl588cWsvkc2A8k8YG/c832c3NoY75h5QCegwG9FZBj4tqre4x7TGBdouoDG\nsd5cRFYBqwAaGxtpa2tLqRKhUCjlc/NVodWpkOrT2TNAXZlwaEB5+oUNDO4rjGHM6b5G1dXV9PX1\nZXXhxuHh4ZRnbuUbVWVkZCTla5TPf6WXqup+EWkAnhCRdlV9Ov4AVVURGXN6ixt47gFoaWnRxKT2\nyWprayPVc/NVodWpkOrzz+vbOLuxnN9tP0TDgsW0Xtqc6yJlxHRfo507dzI4OJjVpeQLLR+JqqZ8\njbIZSPYD8SM6891tSR2jqrHf3SLyc5yusqeBg7HuLxGZA3RnqfzGTLtgOMr8meX4BQ6FIrkujmfN\nnz+fffv20dPTk7X3CIfDlJWVZe31p1NZWRnHjx9P+fxsBpIXgKUi0owTHK4FPpxwzBrgU+74yUXA\nMTdAVAA+VQ26j98F3BZ3zvXA7e7vX2axDsZMq2B4iKqyYipLhN6Q3ZWYquLiYpqbs9uaa2tr4/zz\nz8/qe0yn3bt3p3xu1gKJqkZF5FPA4zjTf+9V1c0icqO7/27gUZypvx04039vcE9vBH7uNkmLgB+r\n6mPuvtuBh0TkL4DdwIeyVQdjptNgdIRIdIRAaRFVJWItEuMZWR0jUdVHcYJF/La74x4rcMo6yO5M\nr/PGec1e4IrMltSY3Ivd1V5ZVkRVqQUS4x22RIoxeSK2YGOgrNhtkVjXlvEGCyTG5Ik+d8HGyrIT\nXVtOo92Y/GaBxJg8Mdq1VVpEdakQiY6MbjOFLRSJcvMDL9MT9GZ3pgUSY/JEbJ2tyrJiqtxVw23m\n1ulh0/5j/OqVA6zfdTjXRUmJBRJj8kRsna2A27UFdi/J6WJ01eewN1ugFkiMyRMnWiTOrC2wQHK6\nGE1oFh6a5Mj8ZIHEmDwRCySx+0gAm7l1mrAWiTEmI4LhKCV+H2XFfiqta+u0EmuRWCAxxqQlFBki\nUObcI1zkE2bOKLZAcpo40SKxri1jTBqC4SiVZScWm6gLlNqsrdNEnxtIbIzEGJOWUDhKoPREIKkP\nlFiL5DRhXVvGmIxIbJHUB0ptsP00YYPtxpiMCEaiBEqLR587gcRaJKeDEy0S69oyxqTByUVyctdW\nMBwlPDScw1KZ6dBnLRJjTCaEItHRWVvgtEgAeo9b91ahi78h0YsLdVogMSYPqOqYs7YAeq17q+DF\nWiJDw0okOpLj0kxdVgOJiFwlIttEpENEVo+xX0TkDnf/RhFZkbDfLyIvi8jDcdtuFZH9IrLB/bkm\nm3UwZjqEh0YYHtGEMRJn5UYbJyls0eER+geHR1ugXpwCnLVAIiJ+4E7gamAZcJ2ILEs47Gpgqfuz\nCrgrYf9ngK1jvPzXVHW5+/PoGPuN8ZRgXC6SmNgHy6GgdW0VsliqgHkzywFvjpNks0VyIdChqjtU\ndRB4EFiZcMxK4H51rANqRGQOgIjMB/4Y+G4Wy2hMXgjGpdmNGQ0kx61FUshigWN+jQWSscwD9sY9\n3+duS/aYrwP/AIzVYXiz2xV2r4jMzFB5jcmZ+JV/Y8pL/FSU+K1FUuBiXVlza8oAb04BLpr8kOkn\nIu8GulX1RRFpTdh9F/AvgLq/vwJ8YozXWIXTXUZjYyNtbW0plSUUCqV8br4qtDoVQn02H3Km+G7f\nsglf19bROlUUjbBlxx7a2rpzXML0FMI1SpSpOrUfdq59f89+AP7w4isM75/+j+Z06pPN0u4HFsQ9\nn+9uS+aYDwB/4g6klwFVIvJDVf2Iqh6MHSwi3wEeZgyqeg9wD0BLS4u2tramVIm2tjZSPTdfFVqd\nCqE+A692wvqXePtb3szZc6pG6zR/y+/xl/hpbb0410VMSyFco0SZqtPQloPw/Hre/uY38aP2Fzlj\n0RtovfCM9As4RenUJ5tdWy8AS0WkWURKgGuBNQnHrAE+5s7euhg4pqqdqvp5VZ2vqk3ueU+p6kcA\nYmMorvcBm7JYB2OmRWyMJH6tLXDvbreurYIW68qa5+Exkqy1SFQ1KiKfAh4H/MC9qrpZRG50998N\nPApcA3QA/cANSbz0l0RkOU7X1i7gk1kovjHTKvbhUVVWfNL2+spSXtx9JBdFMtOkb8AJJLOryxCx\nMZJTuFNzH03YdnfcYwVumuQ12oC2uOcfzWghjckDITeQVJT6T9peX1HC4f5BhkcUv09yUTSTZfFf\nIgKlRaPLpXiJ3dluTB4IhoeYUeKnyH/yf8n6ylJU4bAtk1KwgpEopUU+Sop8VJUVe7JrywKJMXkg\nFImeMj4CcfeS2N3tBSsYHqLS7dKsLCuyO9uNMalJXGcrpq7CWSbFMiUWrr5wlKpy59o7LRILJMaY\nFAQjUQIJA+3gdG2BtUgKmfMl4kSLxLq2jDEpScxFEmNdW4Uv/tpbIDHGpCwxX3tMVVkRJX6fpdwt\nYPHdmpXWtWWMSdV4YyQiQl2gxFokBSwYHqKyNH6wPeq55FYWSIzJA6GEfO3xLHd7YUtskQyPKAMe\nS69sgcSYHBseUUKRsVskAHWBEpu1VaCG3KRWscH22Owtr42TWCAxJseOD566hHw8a5EUrlBC+oBY\nQPHaOIkFEmNybKxcJPHqA6X0hgY9129uJpd47WO/vbZMigUSY3Is9q10/DGSEgaHRzz34WIm1zea\nYtnt2iqzri1jTArGytcez+4lKVyjCzaWn9y1FVsR2CsskBiTY6O5SCYLJEELJIUm9iWiarRFEhsj\nsRaJMWYKTiwjPv6sLYBeWwG44Iw3RmKD7caYKZl8jMS6tgpVMGGMZEaJH79PrEVijJma2IfJeF1b\ntRUliFjXViFKbJGICIHSImuRxBORq0Rkm4h0iMjqMfaLiNzh7t8oIisS9vtF5GUReThuW62IPCEi\n293fM7NZB2OyLRSJIgIVJf4x9/t9Qu2MEg5Z11bBCUailBX7KI5LaBZbJsVLshZIRMQP3AlcDSwD\nrhORZQmHXQ0sdX9WAXcl7P8MsDVh22rgSVVdCjzpPjfGs4Lugo0i46fSrQ+UWoukAPUNnEhqFePF\nhRuz2SK5EOhQ1R2qOgg8CKxMOGYlcL861gE1IjIHQETmA38MfHeMc+5zH98HvDdbFTBmOgTD0dHZ\nOuOpr7SFGwvRWIt1VlmL5CTzgL1xz/e525I95uvAPwAjCec0qmqn+7gLaMxIaY3JkWB4aMwl5OPV\nVZTarK0C1Bcer0XirUAy8V9vjojIu4FuVX1RRFrHO05VVUTGXDdCRFbhdJfR2NhIW1tbSmUJhUIp\nn5uvCq1OXq/P3q4BRkY4qQ6JdQofjXDwaNSz9fT6NRpLJuq0v3uA8qKTr33/sQg9R4en/d8rnfpk\nM5DsBxbEPZ/vbkvmmA8AfyIi1wBlQJWI/FBVPwIcFJE5qtrpdoN1j/XmqnoPcA9AS0uLtra2plSJ\ntrY2Uj03XxVanbxen6+8+gyNgRJaWy8c3ZZYpy108Jvd27jorW+jfJxB+Xzm9Ws0lkzU6V9ebKNp\ndhWtrSfmGa09tonNRw5M+79XOvXJZtfWC8BSEWkWkRLgWmBNwjFrgI+5s7cuBo6paqeqfl5V56tq\nk3veU24QiZ1zvfv4euCXWayDMVnnLCE/yRhJhd1LUojGGiOJDbZ7aZHOrAUSVY0CnwIex5l59ZCq\nbhaRG0XkRvewR4EdQAfwHeB/JfHStwNXish24J3uc2M8K5kxkvpK5+52CySFZexAUsSIwvFB7yS3\nyuoYiao+ihMs4rfdHfdYgZsmeY02oC3ueS9wRSbLaUwuObO2Jgkko3e324B7oRgaHmFgaPiU1mhV\n+YmcJJN9wcgXdme7MTk0GB0hEh2ZfNaWG0h6rUVSMBKTWsVUenApeQskxuRQKDJxUquYugrr2io0\nJ5ZHOXX6r7PfOzclWiAxJodOrLM18WB7WbGfyrIi69oqIH3j5KHxYpZECyTG5NBkaXbjWe72wjJe\nIImNl3kpuZUFEmNyaDSQJDGoWh+wZVIKyYk8NAmD7R5MbmWBxJgcOjFGMnHXFsRaJNa1VSjGa41W\nWiAxxkzFZLlI4tUFSmzWVgFJTLMbU1bso8gnNthujElOsrO2wGmRHOkfYmg4cR1T40WxFkfilwgR\nobKsyFokxpjkjH6YJDVG4txLcthWAS4IwfAQ5cX+k5JaxVSWFY8OxnuBBRJjcigYjlLi91FWPPlC\njPUBu5ekkIy1PEqMtUiMMUkLhoeSGh8BWyal0EwUSKo8liXRAokxOeSs/DvFQGIpdwvCWEmtYqxF\nYoxJWixfezLq3K6t3uMWSApB34RdW97KkmiBxJgcCk3wYZIoUFpEaZHPurYKRDA8dMrU35jKsiIb\nbDfGJKcvPESgdPKbEcGZFlofKLWurQIx8RhJEaFIlJERbyS3skBiTA6FIpPnIolXHyjhkE3/LQjB\n8NBo7pFEVeXFqEJo0BvdWxZIjMmhYDia9KwtwFokBWJoeITw0Mi4a6x5LSdJVgOJiFwlIttEpENE\nVo+xX0TkDnf/RhFZ4W4vE5HnReQVEdkqIrfHnXOriOwXkQ3uzzXZrIMx2aKqU5q1BbYCcKGYbNVn\nr+UkyVoeRxHxA3cCVwL7gBdEZI2qbok77GpgqftzEXCX+zsCvENVQyJSDDwjIm9T1d+5531NVb+c\nrbIbMx0GhoYZHtGkx0jAmbl1+PggIyOKzydZLJ3JpuDoEvLjD7Y7x1mL5EKgQ1V3qOog8CCwMuGY\nlcD96lgH1IjIHPd5yD2mGPADR7JYVmOm3XipVidSHyglOqIc81CuCnOqZFskXslJks3M8vOAvXHP\n9+G0NiY7Zh7Q6bZoXgSWAHer6qa4424WkY8B64HPqeopQUZEVgGrABobG2lra0upEqFQKOVz81Wh\n1cmr9TkQchZf3LtjO23hnSftG69O3Z3OB9Cja59hXsA7Q5xevUYTSadOW3uHAXi9fTNtPe2n7O90\n/zaee/lV/Ae3plzGqUjrGqlqVn6ADwLfjXv+UeBbCcc8DFwa9/xJoCXhmBrgOeBy93kjTgvFB/wr\ncO9kZbngggs0VWvXrk353HyVTJ129oR0T+/x7BcmA7x6jV7ec0QX3vKwPrm165R949Xp99t7dOEt\nD+uzHYeyXLrM8uo1mkg6dXpsU6cuvOVhfXXf0TH3d/eFdeEtD+v9z+5M+T2maqz6AOs1ic/7pFok\nIrIY2KeqERFpBc7F6ZI6OsFp+4EFcc/nu9umdIyqHhWRR4AWYK2qHowr13dwgpFJU3homOd3Hmbt\ntm7Wtnezq7efeTXl/H71O3JdtII1motkCmMk9ZWx9bZswN3LYl1WE92QCN7J255s19bPgBYRWQLc\nA/wS+DEw0YypF4ClItKMExyuBT6ccMwa4FMi8iBOt9cxVe0UkVnAkBtEynEG7G8DcMdQOt3z3wds\nwqRk/9EB1rZ307atm9939DIwNExpkY+3Lq6jqb6Ctm09BCdYD8ikJ9UxErBA4nWTjZGUFfsp8fs8\nM9ie7F/wiKpGReR9wDdV9Zsi8vJEJ7jHfwp4HKcr6l5V3SwiN7r77wYexQlGHUA/cIN7+hzgPhHx\n4XRh/VBVn3D3fUlElgMK7AI+mWQdDPDyniM8tG2Q//vy//DaQWc+w/yZ5fxpy3wuP7OBixfVUV7i\n57FNnbRt62F3bz9vnFed41IXpqnkIompKS/G7xN6bZkUTxsvqVU8Z+HGwhpsHxKR64Drgfe42yb9\nmqqqj+IEi/htd8c9VuCmMc7bCJw/zmt+NMkymwSdxwZ43388i1/g4sVVfKhlAa1nNrB4VgUiJ08l\nbaqvAGDHoeMWSLIk6GZHHK97Yyw+n1BbUWItEo8LhoeYUTJ2UqsYZ72twmqR3ADcCPyrqu50u6t+\nkL1imWzYvL8PgH94cxmffP/FEx7bVOcEkl2Hjme9XKerWNdWRenkSa3i2U2J3jfROlsxVeXeyUmS\nVCBR5ybCTwOIyEygUlX/LZsFM5nX3uUEkjOqJp82WlbsZ251GTstkGRN7Ftp0QTfSsdSHyixFYA9\nLhiZfOzRSzlJkvoLFpE2EakSkVrgJeA7IvLV7BbNZFp7V5AFteWUFyV3R3TzrAoLJFkUiiSfiySe\ntUi8L5kWSWWpd1okyX4VqlbVPuD9ONN+LwLemb1imWxo7wpy1uyqpI9vqrNAkk3JfJiMxWmRRGL3\nWRkPcpJanWYtEqBIROYAH8Lu2/Ck8NAwO3pCnD27MulzmusrODYwxBFbtjwrgpEogRSmVtcFSgkP\njdA/OJyFUpnp4Eyrn6RF4qEsickGkttwpvG+rqoviMgiYHv2imUyraM7xIjCWXOSb5E0x83cMpnn\nZMhLrWsL7F4SLwuGJ89DU+kmtxr2QHKrpAKJqv6Xqp6rqn/tPt+hqh/IbtFMJm3tdAbaz5piiwRs\n5la2hKaQrz1evZu73QKJd/UNTD7YHkt6FfJAqyTZwfb5IvJzEel2f34mIvOzXTiTOe1dQcqKfSx0\np/UmY0HtDPw+sXGSLEl9jCTWIrEuRy8ajI4QiY6f1CrmxDIp+T/gnmzX1vdxljOZ6/78yt1mPKK9\nq48zGyvxTyGHRbHfx4KZ5ezstUCSDc6sramPkVjXlredyEUyyX0kHspJkmwgmaWq31fVqPvzn8Cs\nLJbLZJCqsrUzyJlT6NaKaaqvsK6tLBgemXp2xJjaCrdrK2gtEi+KBYbx8rXHeClLYrKBpFdEPiIi\nfvfnI0BvNgtmMqcnFOHw8cEpTf2Naa53pgDbVNPMOj449QUbY0qKfFSXF9N73FokXnRiwcbJp/+C\nN1YATjaQfAJn6m8X0ImTa+TjWSqTybBtXUEAzpoz9RZJc30F/YPD9ATtQyuTJlv9dTKxe0mM9yTf\ntVVgLRJV3a2qf6Kqs1S1QVXfC9isLY9o73QDSYotErApwJkWGl35N7Ul+usDpda15VF9SX6J8FLe\n9nRydX42Y6UwWbW1q4/GqtLRvvWpsMUbsyPZb6XjqQ+Ucsi6tjwpdu0nW/W5EMdIxpL89B+TU+2d\nU1saJd7cmnJK/D6bApxhsSXkJ8pHMZH6QAmHrLvRk5Lt1iwp8lFa5I3kVukEEht99YCh4RE6ukMp\njY8A+H3CwroZFkgybHTmThotkr5wlEjUlknxmqkkNKssK/b+YLuIBEWkb4yfIM79JBMSkatEZJuI\ndIjI6jH2i4jc4e7fKCIr3O1lIvK8iLwiIltF5Pa4c2pF5AkR2e7+nplCvU8bOw8dZ3B4hLNTbJGA\nMwXYAklmpTtGUufeS3LY1kHznL4ppA+oKivy/g2JqlqpqlVj/FSq6oThVET8wJ3A1cAy4DoRWZZw\n2NXAUvdnFXCXuz0CvENVzwPOBS4Xkbe5+1YDT6rqUuBJ97kZR2xplFTuIYlZVF/B7sP9nljzxyvS\nHyOxe0m8KpkFG2Mqy72xcGM6XVuTuRDocNflGgQeBFYmHLMSZ1l6VdV1QI2IzHGfh9xjinFyvh+J\nO+c+9/F9wHuzWAfPa+8KUuQTFs8KpPwaTfUVDEZHOHB0IIMlO72FIlF8AjNKppYdMaa+0u5u96pg\nEkvIx1R5JG97NgPJPGBv3PN97rakjnFvfNwAdANtqrrJPaZRVTvdx11AY6YLXkjaO/tY0hCgpCj1\nSz26eKMtlZIxQXfBRpHU5qzUV1gg8apkVv6N8UpOktTa1dNAVYeB5SJSAzwuIper6tqEY1RExuxv\nEZFVON1lNDY20tbWllI5QqFQyufmg1d293PmTN9JdZhqnY6ERwB4/NkNDO9PrU8/m7x4jbbvilDM\n8LjlnqxOkajzZ//8xq3MCr2ehRJmlhev0WRSrdP+ngECxZLUuaEjEQ4dG//vJJPSuUbZDCT7gQVx\nz+e726Z0jKoeFZFHgBZgLXDQ7f7qdJNtdY/15qp6D3APQEtLi7a2tqZUiba2NlI9N9eO9Q9x+LHf\ncNnypbRetnh0+1TrpKr872cfp7h2Lq2t52ShpOnx4jX68Z71zBrpp7X17WPuT6ZOM55+jKqG+bS2\nJg495h8vXqPJpFqn29a3sXBuFa2tKyY99pnQFtZ375mWf7t0rlE2u7ZeAJaKSLOIlADX4qwgHG8N\n8DF39tbFwDE3QMxyWyKISDlwJbAh7pzr3cfXA7/MYh08rb1r6jlIxiIiNNXZ4o2ZlGq+9nh1gRJ6\nrWvLc5JJsxtTWVZM/+AwQ8MjWS5VerLWIlHVqIh8Ciezoh+4V1U3i8iN7v67gUeBa4AOoB+4wT19\nDnCfiPhwgt0PVfUJd9/twEMi8hfAbpw1wMwY2t01ts6eQlbE8TTPqmDz/mNpv45xBMPR0ZlXqaoP\nlFpOEg+aSmbMqnLnuFA4yswUVqaYLlkdI1HVR3GCRfy2u+MeK3DTGOdtBM4f5zV7gSsyW9LC1N7V\nx8wZxTS4M3zS0VxXwWObuhgaHqE4ifnvZmKhSJSm+uSTjI2lPlDKnt7+DJXITIfRpFZJD7bHlknJ\n70BinwgFbKu7NEqqM4PiNddXMDyi7D1sH1yZMJV7CcZzRu0Mdh8+zojd3+MZJ+4fSrZryxtZEi2Q\nFKiREWVbV2rJrMbSZFOAMyoYjk6aanUySxoChIdG2G/393hGsiv/xnhlBWALJAVqz+F+BoaGOTvF\nNbYSLYotJ99jgSRdU+3eGE/sJtOOntAkR5p8MdUWSWyFYGuRmJw4MWMr/YF2gJkVJVSXF1uLJANC\nkeQX7ZvIkgYnkLzebYHEK6aa0Kwqbowkn1kgKVDtXUFE4A2NmWmRwIm0uyY9U/1WOp7aihJqK0ro\nsEDiGcnmIok50bVlLRKTA+2dQZrrKihPcS2nsTTXV7DrkA22p2t0GfE0u7YAlswK8Lp1bXnGVMdI\nAjZGYnKpvasv5Rwk42mqq2D/0QHCQ5YDIx3p5muPt7ghYC0SDzmRhya5Fkmx30d5sd9aJGb6HY9E\n2X24P2PjIzHNs5wB991270JaYmMklSnmIom3pCHAkf4hu8PdI2IBYSqtUS8s3GiBpAC9djCIavpL\noyRqdvO37zxk34DTkW4ukniL3eBurRJvCIajVJT48fuSv7er0gPJrSyQTOCnL+7jOxsjnstCl8ml\nUeI11c+zN5QfAAAf9UlEQVQAYKeNk6QllGa+9nixmVs2BdgbnBtRp9YSrfJAcisLJBM4FIqwrjPK\nO77SxkPr9+Ks6JL/2jv7qCjxM6+mPKOvW1lWTH2g1BZvTFMmx0jmVpdTXuy3FolHOEmtpnbdvZC3\n3QLJBG68bDG3vbWcpQ0B/uGnG/mze9bR0R3MdbEmtdW9o903heZzshbZFOC0BcNRSvw+SovSn1Hn\n8wmLGyp43W4U9YS+FJbGqfRAlkQLJJOYV+njJ6vewr994E1s6wpy9Td+x5cf35a3M5dUlfbOPs7K\ncLdWTFP9DHbaTYlpycQ6W/GWzArYTYkeMZU0uzFVNtheGHw+4c/efAZPfu4y3nPuXL61toM/+vrT\n/G57T66LdoquvjB94ShnZ3igPaa5PkBPMJL335DyWSgSzcj4SMyShgD7jw5wPJLfHzYmja6tgfz+\n/2aBZArqA6V89c+W8+O/vAifCB/93vN8+oGX6Q6Gc120Ue2dTtdbtlokze6Au00BTl0qHyYTia25\nZeug5b9geIiq8qm3SCLREQaj+ZvcygJJCt66pJ5ff+ZtfOaKpTy2qYsrvvI//HDd7rxYznuru8ZW\nplb9TdRc735o2ThJykLh9LMjxjsxcyv/x+9Od30ptkggv5dJsUCSorJiP3975Rv49d+8jTfOreaf\nfrGJ99/1LJtynEWwvTPIvJrypO+cnaqFdU6LxGZupa4vhSmgE1lYV4HfJzZzK89FosMMRkem/H/T\nC0vJZzWQiMhVIrJNRDpEZPUY+0VE7nD3bxSRFe72BSKyVkS2iMhmEflM3Dm3ish+Edng/lyTzTpM\nZvGsAD/+q4v46ofOY+/hfv7kW8/wz7/anLNvD+1dfRlbOn4sZcXOtGKbuZW6UCT9XCTxSop8LKyb\nwevddk3yWarTvis9sAJw1gKJiPiBO4GrgWXAdSKyLOGwq4Gl7s8q4C53exT4nKouAy4Gbko492uq\nutz9OSmVby6ICO9fMZ+nPtfKhy86g/98dhdXfOV/+NUrB6b13pNIdJjXe45nfGmURE31MyyQpCHT\nYyTgzNyymxLzW+qBJP9XAM5mi+RCoENVd6jqIPAgsDLhmJXA/epYB9SIyBxV7VTVlwBUNQhsBeZl\nsawZUT2jmC++90384n9dQmNVGTc/8DIf/d7z7Jim/+Ad3SGGRzRr4yMxtpx86lQ147O2wBkn2XXo\nOEPD+Tsge7obXRpnimuseSHdbjYDyTxgb9zzfZwaDCY9RkSagPOB5+I23+x2hd0rIjMzVeBMOW9B\nDb+46RJuW3kOr+w9ylVf/x1f/U327z2JzdjKZtcWOKsAHxsY4ojHlo7JBwNDwwyPaEbHSMDpYo2O\nqM2my2N9A6m1SE5kSczfrq3Mfi3KMBEJAD8D/kZV+9zNdwH/Aqj7+yvAJ8Y4dxVOdxmNjY20tbWl\nVIZQKJTyuWcA//LWYn7SPsgdT3XwwB9e56PLSjh3Vnb+2Z9oj1Dkg92b1rNvgrva06kTQKjb+YP+\n2W9+x5KZmct3kqp06zOdjoadFsOB3Ttoa9s77nFTrdOxY86XlF+uXccFjfn339pL1yhZU63TC13O\n/5ttmzYwsCf5/zfHh5zu8Zc3tdMQen1KZZyKtK6RqmblB3gL8Hjc888Dn0845tvAdXHPtwFz3MfF\nwOPAZyd4jyZg02RlueCCCzRVa9euTfnceL/v6NF3fHmtLrzlYV11/wv6encwI68b7yPfXad/fMfT\nkx6Xbp1e7w7qwlse1p+u35vW62RKpq7RdNh+0Pm3+8XL+yY8bqp1CoaHdOEtD+u3ntqeRumyx0vX\nKFlTrdNPnt+jC295WPf0Hp/SedHhEV14y8P6tSe2Tem8qRqrPsB6TeLzPptdWy8AS0WkWURKgGuB\nNQnHrAE+5s7euhg4pqqdIiLA94CtqvrV+BNEZE7c0/cBm7JXhcx56+J6fv2Zt/P3f3Qmz2w/xJVf\ne5r//fNXM3ozY3tXMOsD7QALamfg94mNk6RgNBdJhsdIAqVFzKkus6VS8lhsjGOqNyT6fUJFiT+v\nZ21lrQ2sqlER+RROq8IP3Kuqm0XkRnf/3cCjwDVAB9AP3OCefgnwUeBVEdngbvtHdWZofUlEluN0\nbe0CPpmtOmRaSZGPmy5fwodaFvDNp7bz4+f28POX9/OXb1vEqrcvSusmtUOhCD3BSMZzkIyl2O9j\nwcxyW3MrBZnK1z6WJQ02cyufjaZYTuH/eWVZcV7P2spqZ6r7wf9owra74x4rcNMY5z0DjNnJr6of\nzXAxp92sylJuW/lGPnFJM//+m23c8eR2frRuN5++YinXXXgGJUVTbyhuy1IOkvE01VfYTYkpCKXx\nYTKZxbMC/Jeb7sBp1Jt8EnRXNJhKUquYqvKi0cH6fGR3tudQU30Fd354Bb+86RKWNgb4wprNXPk1\n5/6TqS63srXTmYswHS0SODEFWD2SoyVfZDIXSaLFDQGODw7TeSx/1n4zJ6Sz6nNlWTHBSP62SCyQ\n5IHzFtTwwF9dzPdveDPlxX5ufuBl3vsfv+fZjkNJv0Z7V5D6QCl1gdIslvSE5voK+geH6QlarvCp\nCGYwX3uiJe7ijbZUSn5K50bUfM/bboEkT4gIl5/ZwCOffhtf+dPz6A0N8uHvPsd77/w9//3Svknv\nQcn20iiJmuudXOG2eOPUxPq5M31DIsQt3miBJC8FI6mvseaMkVggMUny+4QPXDCfJz93Gf/8J+fQ\nFx7isw+9wltvf4rbf93O3sOn3nAWHR7htYOhaevWAuemRLDFG6cqFI4yo8SfUj/5ZOoDJVSXF/O6\nDbjnpfRbJPnbtZV/dy4ZwFkc8fq3NvGxtyzk9x293P+HXdzz9Ot8++nXueKsBj5y8ULevnQWPp+w\nq/c4g9GRaZn6GzO3ppySIp9NAZ6ibKyzFSMizswta5Hkpb6BIRa6X8CmqrIsvwfbLZDkORHh0qX1\nXLq0ngNHB/jxc3t48IU9/HZrN011M/jIxQspK3bukj1rGru2/D5hYa0t3jhVoUhmc5EkWjIrwJPt\nB7P2+iZ16XyJqCorZnB4hPDQ8Oj/93xigcRD5taU83d/dCY3X7GExzZ18YM/7OaLj2wFnA/2WB/5\ndLHFG6cu07lIEi1uqOAn6wc52j9IzYySrL2Pmbr0AsmJnCQWSExGlBb5Wbl8HiuXz2PzgWP8cN0e\nAqV+Soum9w+sub6Cttd6GB7RrPT5F6JQJHtdW3DygHtLU23W3sdMTXhomMHhqSe1ionPkjircnpm\nZk6FBRKPO2duNf/v/W/KyXs311cwGB3hwNEBFtTOyEkZvCYYjjKnuixrr79kltO9aYEkv8RmXFWl\nMdge/zr5xmZtmZQ1uVOAd9lSKUnLdL72RPNmllNa5LOZW3km3aVx8j1LogUSk7JFbiCxcZLkBbM8\nRuL3CYtm2cytfJPuigZV5fmd3MoCiUnZrMpSKkr8FkiSNDyiHB8czmqLBGzxxnx0IpCkP0aSjyyQ\nmJSJiC3eOAXZWkI+0eJZFew7MpD1jJwmeSe6tmyMxJhTNNkU4KRNVyBZ0hBAFRsnySPpdm0FSooQ\nyd90uxZITFqa6yrYe2SAoeGRXBcl72UzF0k8W3Mr//Slee19PiFQkr/LpFggMWlprq9geETHXAPM\nnCybuUjiNddX4BN4vcdaivmiLwPXPp+XSbFAYtISmwK86UBfjkuS/0Yz5GW5a6u0yM8ZtTMs7W4e\nCYaHUk5qFVNVnr9ZErMaSETkKhHZJiIdIrJ6jP0iIne4+zeKyAp3+wIRWSsiW0Rks4h8Ju6cWhF5\nQkS2u79nZrMOZmJnza5kbnUZn3toA998crt1cU0glosk1ZvSpsIWb8wvwXA07euezzlJshZIRMQP\n3AlcDSwDrhORZQmHXQ0sdX9WAXe526PA51R1GXAxcFPcuauBJ1V1KfCk+9zkSEVpEY98+m1c9cY5\nfOWJ13j/fzzLaweDuS5WXhrNRZKFpFaJFs8KsPPQcaIW2PNCJu4fyucsidlskVwIdKjqDlUdBB4E\nViYcsxK4Xx3rgBoRmaOqnar6EoCqBoGtwLy4c+5zH98HvDeLdTBJmFlRwjevO5//+PMV7D86wLvv\neIa72l5neIrpggtdKItpdhMtbggwODzC3iMDWX8vM7lMpA/I5xZJNv+i5wF7457vAy5K4ph5QGds\ng4g0AecDz7mbGlU1tr8LaBzrzUVkFU4rh8bGRtra2lKoAoRCoZTPzVfZqtMM4NYLi7hvyzD/9lg7\nP/3Da/zlm0qZE8juUJxXrtGm1wYR4Plnf4fIxH3l6dap76hzD8kvnvoD5zfkfkk9r1yjqZhKnQ70\nDFBVKmn9GwR7Ixzui2bt3zGda5T7v7AJiEgA+BnwN6p6ymiuqqqIjPm1V1XvAe4BaGlp0dbW1pTK\n0NbWRqrn5qts1+k971LWvHKA//PLzdy6LsLf/9GZfOKSZnxZWiHYK9eorW8zlQf2cfnll09+bJp1\nWhEe4ovrfkN5YzOtly1O+XUyxSvXaCqmVKcX1tI0t4bW1vNTfr/nw+08vX8Hl1122aRfRFKRzjXK\n5lfF/cCCuOfz3W1JHSMixThB5Eeq+t9xxxwUkTnuMXOA7gyX26RJRFi5fB5P/O3buXRJPV98ZCvX\n3rOO3af54o7ZzkUSr6qsmIbKUhtwzxOZ6doqJjqihIfyb9wrm4HkBWCpiDSLSAlwLbAm4Zg1wMfc\n2VsXA8dUtVOccPs9YKuqfnWMc653H18P/DJ7VTDpaKgq47vXt/DlPz2PrV19XPX133Hn2o7TdkmV\nUBbT7I7FZm7lB1V1A0m6g+2xZVLyb8A9a3/VqhoVkU8BjwN+4F5V3SwiN7r77wYeBa4BOoB+4Ab3\n9EuAjwKvisgGd9s/quqjwO3AQyLyF8Bu4EPZqoNJn4jwwQvmc8mSOj7/36/y749v498f38aiWRW8\n8+xG3nFWAy0LZ1LkL/xbmoJZXkI+0eJZAX7x8n5UNStdISY5kegIg8MjGRlsB+fmxoaqTJQsc7L6\nV+1+8D+asO3uuMcK3DTGec8AY/7lq2ovcEVmS2qybU51Of95w4Xs6e3nqfaDPNnezfd/v5N7nt5B\nVVkRrWc2cMXZDVz2hlkFmyI2FIlSH5i+ui1pCBCMROkORmisyl4yLTOx2PIo6d5HUpXHKwDn9WC7\nKTxn1M3g45c08/FLmglFojyzvYcnt3azdls3a145gE+gZWEt7zi7gYsX1XHO3CqKC6S1EgwPja4E\nMB3i19yyQJI76S4hH5PPKwBbIDE5Eygt4qo3zuGqN85hZETZuP8YT211Wiu3/7odgLJiH+fOr+GC\nhTO54IyZXLBwJjMrvNliyXa+9kTxgeSSJfXT9r7mZKNpdsvTbJGUO4EoH5NbWSAxecHnE5YvqGH5\ngho++64z6e4Ls373EV7cfYT1u4/wnad3cJd7g+OiWRWjQaWlaSYj6o0bH/vCUSqncYykobKUytIi\nW04+xzK16rO1SIyZooaqMq550xyuedMcAMJDw2zcd4z1uw/z0u4j/HbrQf7rxX0AlPihecPTnFE3\ng4W1MzijbgZn1M5gYV0F82rKKSnKfddYJDrMYDT9AdepEBEW28ytnEs3F0lMPmdJtEBiPKGs2M+F\nzbVc2FwLOFMqdxw6zou7jvDE+i3ojHJ2HTrO06/1EImemGfvE2egf2GdE1jesriO1jNnjQ5cTpfp\nWkI+0eJZAX63vWda39OcLFMtkooSPz6xFokxGSMiLJ4VYPGsAA3HX6e19c0AjIwoPaEIu3v72d17\nnL2H+9l9uJ/dvf08svEADzy/h2K/cPGiOt55diPvXNbIvJryrJf3RHbE6Q1gSxoC/OylffSFh6Y9\neBpHplokIkKgND/X27JAYgqKzyc0VpXRWFU22nqJGR5RXt5zhCe2HOSJrQf5wprNfGHNZpbNqeLK\nZY1cuayRc+ZWZeWei+nKRZIofsB9xRmWcSEX+sJRRJx0uemqLCumb8C6tozJGb9PaGmqpaWpls9f\nczav94T47ZaDPLHlIHc8tZ1vPLmdOdVlJ26UbJqZsRZEpr6VTpUFktwLhocIlBRlZK25qvLivMzb\nboHEnLYWzwqw+LIAn7xsMb2hCE+2d/PbLQf56Yv7+MG63fh9whvnVnHRojouXuQEoFS7h0a7tqYh\nF0m8BTPLKfH7bOZWDvUNZG7at7OUvLVIjMlLdYFSPtSygA+1LCA8NMyLu4+wbkcvz+04zH/+fhf3\nPL0Dn8CyuVVc3FzHRYvquLCpluoZyQWGEwOu0/tfrsjvo7m+wtLu5lAmklrFVJUVceBoOCOvlUkW\nSIxJUFbs55Il9aM38YWHhnlpzxGe23GYdTt6uX/dbr77zE5EGB1fefe5c0e7kcYSa5FM9xgJwOKG\nCrYcOCULg5kmmVj5N8bJkph/GUgtkBgzibJiP29dXM9bF58ILBv2HuW5HYf5fcchvvHkdr7+2+2c\nPaeK95w3h/ecO5cFtTNOeo1cjZEALJkV4LFNXYSHhikr9k/7+5/ugpEhGiozs0RNvmZJtEBizBSV\nFfu5eFEdFy+q4zPvXMrBvjCPbOzkVxsP8KXHtvGlx7Zx3oIa3nPuHP743DnMqS4nGI5S4vdRWjT9\nH+SLGwKMqDPg/sZ51dP+/qe7YDjK4lmZ+aitKismGI7m3YrOFkiMSVNjVRmfuLSZT1zazN7D/Tzy\naicPbzzAFx/Zyhcf2cqFTbWEo8M5aY0AnDXbWXP83d98hsaqUprrK+J+AjTXV3BG7Yy8WAGgEGW2\na6uI4RGlf3CYimm+uXUi+VMSYwrAgtoZ3HjZYm68bDE7ekI8vNEJKq8dDHFmY2VOynTm7Eq+f8Ob\n2XKgj52HjrPz0HF+s/kgvccHR4/xCcyfOYPm+gqWNARYNqeKZXOrWNIQKJjVl3PBSWqVucH2E8uk\nRC2QGHM6WDQrwKevWMqnr1jKaweDlOTwA/nyMxu4/MyGk7Yd6x9iZ+9xdh4KsbPnODt7+9nRE+K5\nnb2j6VxL/D6WNp4ILMvmVHH23Cq7Sz5JkegIQ8Oa0RYJODPBZlfnT2qArAYSEbkK+AZOhsTvqurt\nCfvF3X8NTobEj6vqS+6+e4F3A92q+sa4c24F/gqILSAUy5xoTN56Q45aIxOpnlHM8hnOisvxosMj\n7Oo9zuYDfWzp7GPLgT6eau8eXSQTYEFtuRNU5lRx1uwqzppdyRm1MzJy010h6cvQOlsx8VkS80nW\nAomI+IE7gSuBfcALIrJGVbfEHXY1sNT9uQi4y/0N8J/At4D7x3j5r6nql7NUdGNOa0V+H0saKlnS\nUMnK5fMAp4umJxhhsxtYYgHmN1sOElvFf0aJnzc0VnL2nMrR4HLW7Kqk77UpRKO5SDI4/RfyLydJ\nNlskFwIdqroDQEQeBFYC8YFkJXC/m3J3nYjUiMgcVe1U1adFpCmL5TPGJElEaKgqo6Gq7KQusoHB\nYV47GKS9q4+tnc7vX2/q4oHn944eM7e6jNqiIZ448ioLamewYOYMFtSWs2DmDGpmFOfV7KNMi62L\nlamurery/MxJks1AMg/YG/d8HydaGxMdMw/onOS1bxaRjwHrgc+p6pE0y2qMSUF5iZ/zFtRwXlz3\nmKpysC/C1q4+tnUF2drZxys7unjk1U6O9p/8TTpQWsT8meWcUTvDDTLlzK4up7GqlNnVZdQHSj09\n2J+pNLsx+ZqTxIuD7XcB/wKo+/srwCcSDxKRVcAqgMbGRtra2lJ6s1AolPK5+arQ6lRo9YHCqJMA\nZwFnzYYrA8MEAuUMRIvp6R+hZ0A5NKDu43427wnRtk0ZHD71NapKhZpSYWapUFN24ndNqVBdIlSW\nCFWlQvE0j88kc42e73ICSfurGzi+K/2AGIk6/YivbN7GvIGdab9evHT+5rIZSPYDC+Kez3e3TfWY\nk6jqwdhjEfkO8PA4x90D3APQ0tKira2tyZb7JG1tbaR6br4qtDoVWn2g8OqUTH1Uld7jg3QdC9Md\nDNN1LMLBvjAH+8J09YU52Bdh4+Ewh+OmLcerLCtiVqCUukAJ9XG/6wOlzKspZ0FtOfNnzsjY3f3J\n1Knr+T2w4VWueNtbmJuBvDeqiv+pXzNr3hm0tp6V9uvFS+dvLpuB5AVgqYg04wSHa4EPJxyzBviU\nO35yEXBMVSfs1oqNobhP3wdsymyxjTG5ICKjH/ww/h34kegw3X0RekIRDgUj9B4fHP3dE4rQG4qw\nvTvEuh0RjvSf2gVUHygdHaOZP7N8dNxm/sxy5s0sz2hXWqaXxhGRvFwmJWuBRFWjIvIp4HGc6b/3\nqupmEbnR3X838CjO1N8OnOm/N8TOF5EHgFagXkT2AV9Q1e8BXxKR5ThdW7uAT2arDsaY/FNa5Hc+\n/BPWMxvL0PAIvaFB9h/tZ+/hAfYdcX7vPdLPhr1HefTVTqIjOnp8id/HG2YHOGdONcvmVnHOXGeK\nc6o3/wXDQ4hARQaSWsVU5WFyq6yOkbj3dzyasO3uuMcK3DTOudeNs/2jmSyjMaZwFft9zK4uY3Z1\nGRcsPHV/dHiEg8EIew/3s/dwPx09IbYc6OOJrQf5yXpnHpAINNdVcLYbWM6ZW83ZcypR1VNfMEFf\nOEqgNDNJrWJOqxaJMcbkuyK/j3k15cyrKefiRXWj22MzzzYfOObcmHmgj437jvLIxhM97yV+WPBS\nG3NryplbXe78riljXo3zeHZ1GcFwNOOrAFSWFfHSniP87U82UB8ooc7tDqwLlDDLfVxbUTKta6dZ\nIDHGmAQiMtqSueLsxtHtxwaG2NrZR3tnH+tefQ1fZSX7j4Zp7+qmJxg55XWKfDJhnppUvH/FfH70\n3B5e2HWYQ6HI6HI2iarLi6kLlPB/3/emk4JkNlggMcaYJFWXF4+mEGga2k1r6wWj+yLRYbqOhdl/\ndIADR8McODrA/iMDXLSoNqNliGXyBKfl1D84zKFQhEOhQQ6FIvSO/na2VZdnf2UBCyTGGJMBpUV+\nFtZVsLCuYtreU0SoKC2iorRoWt83kXdvGTXGGJMXLJAYY4xJiwUSY4wxabFAYowxJi0WSIwxxqTF\nAokxxpi0WCAxxhiTFgskxhhj0iLJLDzmdSLSA+xO8fR64FAGi5MPCq1OhVYfKLw6FVp9oPDqNFZ9\nFqrqrMlOPC0CSTpEZL2qtuS6HJlUaHUqtPpA4dWp0OoDhVendOpjXVvGGGPSYoHEGGNMWiyQTO6e\nXBcgCwqtToVWHyi8OhVafaDw6pRyfWyMxBhjTFqsRWKMMSYtFkgmICJXicg2EekQkdW5Lk+6RGSX\niLwqIhtEZH2uy5MKEblXRLpFZFPctloReUJEtru/Z+ayjFMxTn1uFZH97nXaICLX5LKMUyEiC0Rk\nrYhsEZHNIvIZd7uXr9F4dfLkdRKRMhF5XkReEZGtInK7uz3la2RdW+MQET/wGnAlsA94AbhOVbfk\ntGBpEJFdQIuqenbuu4i8HQgB96vqG91tXwIOq+rtbsCfqaq35LKcyRqnPrcCIVX9ci7LlgoRmQPM\nUdWXRKQSeBF4L/BxvHuNxqvTh/DgdRIRASpUNSQixcAzwN8B7yHFa2QtkvFdCHSo6g5VHQQeBFbm\nuEynPVV9GjicsHklcJ/7+D6c/+SeME59PEtVO1X1JfdxENgKzMPb12i8OnmSOkLu02LADxwhjWtk\ngWR884C9cc/34eE/HpcCvxWRF0VkVa4Lk0GNqtrpPu4CGnNZmAy5WUQ2ul1fnukGiiciTcD5wHMU\nyDVKqBN49DqJiF9ENgDdQJuqbiKNa2SB5PRyqaouB64GbnK7VQqKOn21Xu+vvQtYBCwHOoGv5LY4\nUyciAeBnwN+oal/8Pq9eozHq5NnrpKrD7mfBfOBtInJ5wv4pXSMLJOPbDyyIez7f3eZZqrrf/d0N\n/Byn+64QHHT7sWP92d05Lk9aVPWg+x99BPgOHrtObr/7z4Afqep/u5s9fY3GqpPXrxOAqh4FHgFa\nSOMaWSAZ3wvAUhFpFpES4FpgTY7LlDIRqXAHChGRCuBdwKaJz/KMNcD17uPrgV/msCxpi/1ndr0P\nD10ndyD3e8BWVf1q3C7PXqPx6uTV6yQis0Skxn1cjjOhaANpXCObtTUBdzrf13EGo+5V1X/NcZFS\nJiKLcFohAEXAj71YHxF5AGjFWan0IPAF4BfAQ8AZOKs8f0hVPTGAPU59WnG6SxTYBXwyru86r4nI\npcDvgFeBEXfzP+KMKXj1Go1Xp+vw4HUSkXNxBtN97s8PVfXfRKSOFK+RBRJjjDFpsa4tY4wxabFA\nYowxJi0WSIwxxqTFAokxxpi0WCAxxhiTFgskxqRBRIbjVn/dkMlVokWkKX5VYGPyVVGuC2CMxw24\nS00Yc9qyFokxWeDmfvmSm//leRFZ4m5vEpGn3IX+nhSRM9ztjSLyczdHxCsi8lb3pfwi8h03D8Zv\n3DuREZFPu/kxNorIgzmqpjGABRJj0lWe0LX1Z3H7jqnqm4Bv4ayQAPBN4D5VPRf4EXCHu/0O4H9U\n9TxgBbDZ3b4UuFNVzwGOAh9wt68Gzndf58ZsVc6YZNid7cakQURCqhoYY/su4B2qusNd8K9LVetE\n5BBOkqQhd3unqtaLSA8wX1Ujca/RBDyhqkvd57cAxar6RRF5DCch1i+AX8TllzBm2lmLxJjs0XEe\nT0Uk7vEwJ8Y1/xi4E6f18oKI2HinyRkLJMZkz5/F/f6D+/hZnJWkAf4cZzFAgCeBv4bRpEPV472o\niPiABaq6FrgFqAZOaRUZM13sW4wx6Sl3M83FPKaqsSnAM0VkI06r4jp3283A90Xk74Ee4AZ3+2eA\ne0TkL3BaHn+NkyxpLH7gh26wEeAON6+EMTlhYyTGZIE7RtKiqodyXRZjss26towxxqTFWiTGGGPS\nYi0SY4wxabFAYowxJi0WSIwxxqTFAokxxpi0WCAxxhiTFgskxhhj0vL/AWF0GRnpo5P6AAAAAElF\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7faf2592b1d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEKCAYAAAA4t9PUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7faf2585f250>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure()\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.plot(best_history.history['loss'])\n",
    "#plt.plot(best_history.history['val_loss'])\n",
    "plt.grid()\n",
    "plt.legend(['Training', 'Validation'])\n",
    "\n",
    "plt.figure()\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.plot(best_history.history['acc'])\n",
    "#plt.plot(besthistory.history['val_acc'])\n",
    "plt.grid()\n",
    "plt.legend(['Training', 'Validation'], loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New network, without SKF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_numu_categ = np_utils.to_categorical(Y_numu, 2)\n",
    "y_nue_categ = np_utils.to_categorical(Y_nue, 2)\n",
    "Y = np.concatenate((y_numu_categ, y_nue_categ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input_shape for \"channels_first\" image_data_format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_channel = X_train.shape[1]\n",
    "conv_dim_1 = X_train.shape[2]\n",
    "conv_dim_2 = X_train.shape[3]\n",
    "conv_dim_3 = X_train.shape[4]\n",
    "inputshape = (img_channel, conv_dim_1, conv_dim_2, conv_dim_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input shape for \" image_data_format\" = \"channels_last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_channel = X_train.shape[4]\n",
    "conv_dim_1 = X_train.shape[1]\n",
    "conv_dim_2 = X_train.shape[2]\n",
    "conv_dim_3 = X_train.shape[3]\n",
    "inputshape = (conv_dim_1, conv_dim_2, conv_dim_3, img_channel)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check inputshape- shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75, 16, 15, 18)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2043, 75, 16, 15, 18)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(681, 75, 16, 15, 18)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make sure sample size is a power of 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = np.vstack((X_train, X_test[:5]))\n",
    "Y_train = np.vstack((Y_train, Y_test[:5]))\n",
    "X_test = X_test[5:]\n",
    "Y_test = Y_test[5:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2048, 75, 16, 15, 18)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(676, 75, 16, 15, 18)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "zero_padding3d_40 (ZeroPaddi (None, 18, 17, 20, 75)    0         \n",
      "_________________________________________________________________\n",
      "uno (Conv3D)                 (None, 16, 15, 18, 64)    129664    \n",
      "_________________________________________________________________\n",
      "zero_padding3d_41 (ZeroPaddi (None, 18, 17, 20, 64)    0         \n",
      "_________________________________________________________________\n",
      "due (Conv3D)                 (None, 16, 15, 18, 64)    110656    \n",
      "_________________________________________________________________\n",
      "primo_pooling (MaxPooling3D) (None, 8, 7, 9, 64)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding3d_42 (ZeroPaddi (None, 10, 9, 11, 64)     0         \n",
      "_________________________________________________________________\n",
      "tre (Conv3D)                 (None, 8, 7, 9, 128)      221312    \n",
      "_________________________________________________________________\n",
      "zero_padding3d_43 (ZeroPaddi (None, 10, 9, 11, 128)    0         \n",
      "_________________________________________________________________\n",
      "quattro (Conv3D)             (None, 10, 9, 11, 128)    442496    \n",
      "_________________________________________________________________\n",
      "secondo_pooling (MaxPooling3 (None, 4, 4, 5, 128)      0         \n",
      "_________________________________________________________________\n",
      "zero_padding3d_44 (ZeroPaddi (None, 6, 6, 7, 128)      0         \n",
      "_________________________________________________________________\n",
      "conv3d_29 (Conv3D)           (None, 4, 4, 5, 256)      884992    \n",
      "_________________________________________________________________\n",
      "zero_padding3d_45 (ZeroPaddi (None, 6, 6, 7, 256)      0         \n",
      "_________________________________________________________________\n",
      "conv3d_30 (Conv3D)           (None, 4, 4, 5, 256)      1769728   \n",
      "_________________________________________________________________\n",
      "zero_padding3d_46 (ZeroPaddi (None, 6, 6, 7, 256)      0         \n",
      "_________________________________________________________________\n",
      "conv3d_31 (Conv3D)           (None, 4, 4, 5, 256)      1769728   \n",
      "_________________________________________________________________\n",
      "max_pooling3d_10 (MaxPooling (None, 2, 2, 2, 256)      0         \n",
      "_________________________________________________________________\n",
      "zero_padding3d_47 (ZeroPaddi (None, 4, 4, 4, 256)      0         \n",
      "_________________________________________________________________\n",
      "conv3d_32 (Conv3D)           (None, 2, 2, 2, 512)      3539456   \n",
      "_________________________________________________________________\n",
      "zero_padding3d_48 (ZeroPaddi (None, 4, 4, 4, 512)      0         \n",
      "_________________________________________________________________\n",
      "conv3d_33 (Conv3D)           (None, 2, 2, 2, 512)      7078400   \n",
      "_________________________________________________________________\n",
      "zero_padding3d_49 (ZeroPaddi (None, 4, 4, 4, 512)      0         \n",
      "_________________________________________________________________\n",
      "conv3d_34 (Conv3D)           (None, 2, 2, 2, 512)      7078400   \n",
      "_________________________________________________________________\n",
      "max_pooling3d_11 (MaxPooling (None, 1, 1, 1, 512)      0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 4096)              2101248   \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 2)                 8194      \n",
      "=================================================================\n",
      "Total params: 41,915,586\n",
      "Trainable params: 41,915,586\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "###VGG16\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Flatten, Dense, Dropout\n",
    "from keras.layers.convolutional import Conv3D, MaxPooling3D, ZeroPadding3D\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_acc', patience=4, verbose=1)\n",
    "def VGG_16(weights_path=None):\n",
    "    \n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(ZeroPadding3D((1,1,1),input_shape=inputshape))\n",
    "    model.add(Conv3D(64, kernel_size=(3, 3, 3), activation='relu', name=\"uno\"))\n",
    "    model.add(ZeroPadding3D((1,1,1)))\n",
    "    model.add(Conv3D(64, kernel_size=(3, 3, 3), activation='relu',name=\"due\"))\n",
    "    model.add(MaxPooling3D((2,2,2), strides=(2,2,2), data_format='channels_first', name=\"primo_pooling\"))\n",
    "\n",
    "    model.add(ZeroPadding3D((1,1,1)))\n",
    "    model.add(Conv3D(128, kernel_size=(3, 3, 3), activation='relu', name=\"tre\"))\n",
    "    model.add(ZeroPadding3D((1,1,1)))\n",
    "    model.add(Conv3D(128, kernel_size=(3, 3, 3), activation='relu', padding='same',name=\"quattro\"))\n",
    "    model.add(MaxPooling3D((3,3,3), strides=(2,2,2), data_format='channels_last', name=\"secondo_pooling\"))\n",
    "\n",
    "    model.add(ZeroPadding3D((1,1,1)))\n",
    "    model.add(Conv3D(256,kernel_size=(3, 3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding3D((1,1,1)))\n",
    "    model.add(Conv3D(256,kernel_size=(3, 3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding3D((1,1,1)))\n",
    "    model.add(Conv3D(256,kernel_size=(3, 3, 3), activation='relu'))\n",
    "    model.add(MaxPooling3D((2,2,2), strides=(2,2, 2), data_format='channels_last'))\n",
    "\n",
    "    model.add(ZeroPadding3D((1,1,1)))\n",
    "    model.add(Conv3D(512,kernel_size=(3, 3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding3D((1,1,1)))\n",
    "    model.add(Conv3D(512,kernel_size=(3, 3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding3D((1,1,1)))\n",
    "    model.add(Conv3D(512,kernel_size=(3, 3, 3), activation='relu'))\n",
    "    model.add(MaxPooling3D((2,2, 2), strides=(2,2, 2), data_format='channels_last'))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "    if weights_path:\n",
    "        model.load_weights(weights_path)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# Test pretrained model\n",
    "model = VGG_16()\n",
    "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.summary()\n",
    "model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    #model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Conv3D(128, kernel_size=(3, 3, 3), activation='relu'))\n",
    "    #model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Conv3D(128, kernel_size=(3, 3, 3), activation='relu'))\n",
    "    model.add(MaxPooling3D((2,2,2), strides=(2,2,2), data_format='channels_last'))\n",
    "\n",
    "    #model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Conv3D(256,kernel_size=(3, 3, 3), activation='relu'))\n",
    "    #model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Conv3D(256,kernel_size=(3, 3, 3), activation='relu'))\n",
    "    #model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Conv3D(256,kernel_size=(3, 3, 3), activation='relu'))\n",
    "    model.add(MaxPooling3D((2,2, 2), strides=(2,2, 2), data_format='channels_last'))\n",
    "    \n",
    "\n",
    "    #model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Conv3D(512,kernel_size=(3, 3, 3), activation='relu'))\n",
    "    #model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Conv3D(512,kernel_size=(3, 3, 3), activation='relu'))\n",
    "    #model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Conv3D(512,kernel_size=(3, 3, 3), activation='relu'))\n",
    "    model.add(MaxPooling3D((2,2, 2), strides=(2,2, 2), data_format='channels_last'))\n",
    "\n",
    "    #model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Conv3D(512, kernel_size=(3, 3, 3), activation='relu'))\n",
    "    #model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Conv3D(512, kernel_size=(3, 3, 3), activation='relu'))\n",
    "    #model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Conv3D(512, kernel_size=(3, 3, 3), activation='relu'))\n",
    "    model.add(MaxPooling3D((2,2,2), strides=(2,2, 2), data_format='channels_last'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2048 samples, validate on 676 samples\n",
      "Epoch 1/30\n",
      "2048/2048 [==============================] - 65s - loss: 0.6895 - acc: 0.5620 - val_loss: 0.6838 - val_acc: 0.5621\n",
      "Epoch 2/30\n",
      " 256/2048 [==>...........................] - ETA: 53s - loss: 0.6948 - acc: 0.4609"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-1df92c5b3c87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m network_history1 = model.fit(X_train, Y_train, batch_size=64, \n\u001b[0;32m----> 2\u001b[0;31m                             epochs=30, verbose=1, validation_data=(X_test, Y_test), callbacks=[early_stop])\n\u001b[0m",
      "\u001b[0;32m/home/cdesio/.local/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    861\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/home/cdesio/.local/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1428\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1429\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1430\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1432\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cdesio/.local/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m   1077\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1079\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1080\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cdesio/.local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2266\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2267\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2268\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2269\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cdesio/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cdesio/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 997\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    998\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cdesio/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1132\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/cdesio/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1137\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cdesio/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "network_history1 = model.fit(X_train, Y_train, batch_size=64, \n",
    "                            epochs=30, verbose=1, validation_data=(X_test, Y_test), callbacks=[early_stop])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
