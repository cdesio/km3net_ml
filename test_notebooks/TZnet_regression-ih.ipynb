{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from network_models import train_neural_network, inference_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from network_models import TZnet_regression_cosz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from generators import data_generator, metadata_generator, get_n_iterations, get_class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_test_dir = os.path.join(\"cosz\")\n",
    "fnames_train =[os.path.join(train_test_dir, \"Xy_train{}_sel5_doms.npz\".format(i+1)) for i in range(100)]\n",
    "fnames_test =[os.path.join(train_test_dir, \"Xy_test{}_sel5_doms.npz\".format(i+1)) for i in range(100)]\n",
    "fnames_val =[os.path.join(train_test_dir, \"Xy_val{}_sel5_doms.npz\".format(i+1)) for i in range(100)]\n",
    "index_filelist = [os.path.join(train_test_dir, \"Xy_indx{}_sel5_doms.npz\".format(i+1)) for i in range(100)]\n",
    "dir_xy = \"/data/km3net/Xy_multi_data_files\"\n",
    "xy_filelist = [(os.path.join(dir_xy, \"Xy_numu_{}_multi_data.npz\".format(i+1)), \n",
    "                os.path.join(dir_xy, \"Xy_nue_{}_multi_data.npz\".format(i+1))) for i in range(100)]\n",
    "metadata_keylist = [\"E\", \"dirx\", \"diry\", \"dirz\", \"posx\",\"posy\",\"posz\", \"dist\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2588, 165610)\n",
      "(648, 41451)\n",
      "(810, 51818)\n"
     ]
    }
   ],
   "source": [
    "n_files=100\n",
    "batch_size = 64\n",
    "steps_per_epoch, n_events = get_n_iterations(fnames_train[:n_files], batch_size=batch_size)\n",
    "print(steps_per_epoch, n_events)\n",
    "validation_steps, n_evts_val = get_n_iterations(fnames_val[:n_files], batch_size=batch_size)\n",
    "print(validation_steps, n_evts_val)\n",
    "prediction_steps, n_evts_test = get_n_iterations(fnames_test[:n_files], batch_size=batch_size)\n",
    "print(prediction_steps, n_evts_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "from keras import backend as K\n",
    "\n",
    "def process_cosz(y):\n",
    "    y[y>0]=1\n",
    "    y[y<=0]=0\n",
    "    return to_categorical(y)\n",
    "\n",
    "def get_TZ_only(X):\n",
    "    TZ = np.sum(X, axis=(2, 3))\n",
    "    if K.image_data_format() == \"channels_first\":\n",
    "        TZ = TZ[:, np.newaxis, ...]\n",
    "    else:\n",
    "        TZ = TZ[..., np.newaxis]\n",
    "    return TZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_generator = data_generator(fnames_train[:n_files], batch_size=batch_size, \n",
    "                                    fdata=get_TZ_only, ftarget=lambda y: y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validation_generator = data_generator(fnames_val[:n_files], batch_size=batch_size,\n",
    "                                     fdata=get_TZ_only, ftarget=lambda y: y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = TZnet_regression_cosz()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2588/2588 [==============================] - 864s - loss: 0.1386 - val_loss: 0.0510\n",
      "Epoch 2/100\n",
      "2588/2588 [==============================] - 865s - loss: 0.0424 - val_loss: 0.0457\n",
      "Epoch 3/100\n",
      "2588/2588 [==============================] - 864s - loss: 0.0389 - val_loss: 0.0422\n",
      "Epoch 4/100\n",
      "2588/2588 [==============================] - 865s - loss: 0.0372 - val_loss: 0.0402\n",
      "Epoch 5/100\n",
      "2588/2588 [==============================] - 865s - loss: 0.0361 - val_loss: 0.0398\n",
      "Epoch 6/100\n",
      "2588/2588 [==============================] - 865s - loss: 0.0353 - val_loss: 0.0391\n",
      "Epoch 7/100\n",
      "2588/2588 [==============================] - 865s - loss: 0.0346 - val_loss: 0.0388\n",
      "Epoch 8/100\n",
      "2588/2588 [==============================] - 865s - loss: 0.0341 - val_loss: 0.0381\n",
      "Epoch 9/100\n",
      "2588/2588 [==============================] - 865s - loss: 0.0336 - val_loss: 0.0384\n",
      "Epoch 10/100\n",
      "2588/2588 [==============================] - 865s - loss: 0.0331 - val_loss: 0.0381\n",
      "Epoch 11/100\n",
      "2588/2588 [==============================] - 864s - loss: 0.0327 - val_loss: 0.0378\n",
      "Epoch 12/100\n",
      "2588/2588 [==============================] - 865s - loss: 0.0323 - val_loss: 0.0376\n",
      "Epoch 13/100\n",
      "2588/2588 [==============================] - 864s - loss: 0.0319 - val_loss: 0.0376\n",
      "Epoch 14/100\n",
      "2588/2588 [==============================] - 865s - loss: 0.0316 - val_loss: 0.0372\n",
      "Epoch 15/100\n",
      "2588/2588 [==============================] - 864s - loss: 0.0312 - val_loss: 0.0369\n",
      "Epoch 16/100\n",
      "2588/2588 [==============================] - 865s - loss: 0.0309 - val_loss: 0.0364\n",
      "Epoch 17/100\n",
      "2588/2588 [==============================] - 864s - loss: 0.0305 - val_loss: 0.0362\n",
      "Epoch 18/100\n",
      "2588/2588 [==============================] - 865s - loss: 0.0302 - val_loss: 0.0362\n",
      "Epoch 19/100\n",
      "2588/2588 [==============================] - 864s - loss: 0.0298 - val_loss: 0.0364\n",
      "Epoch 20/100\n",
      "2588/2588 [==============================] - 865s - loss: 0.0295 - val_loss: 0.0362\n",
      "Epoch 21/100\n",
      "2588/2588 [==============================] - 865s - loss: 0.0291 - val_loss: 0.0364\n",
      "Epoch 22/100\n",
      "2588/2588 [==============================] - 864s - loss: 0.0287 - val_loss: 0.0364\n",
      "Epoch 23/100\n",
      "2588/2588 [==============================] - 864s - loss: 0.0284 - val_loss: 0.0362\n",
      "Epoch 24/100\n",
      "2588/2588 [==============================] - 865s - loss: 0.0281 - val_loss: 0.0360\n",
      "Epoch 25/100\n",
      "2588/2588 [==============================] - 864s - loss: 0.0277 - val_loss: 0.0367\n",
      "Epoch 26/100\n",
      "2588/2588 [==============================] - 865s - loss: 0.0273 - val_loss: 0.0363\n",
      "Epoch 27/100\n",
      "2588/2588 [==============================] - 864s - loss: 0.0270 - val_loss: 0.0365\n",
      "Epoch 28/100\n",
      "2588/2588 [==============================] - 865s - loss: 0.0266 - val_loss: 0.0367\n",
      "Epoch 29/100\n",
      "2588/2588 [==============================] - 864s - loss: 0.0262 - val_loss: 0.0370\n",
      "Epoch 30/100\n",
      "2588/2588 [==============================] - 865s - loss: 0.0258 - val_loss: 0.0374\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5fb97f2b10>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_neural_network(model, training_generator, steps_per_epoch, validation_generator, validation_steps,\n",
    "                     batch_size=batch_size, log_suffix=\"regression_cosz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "tz_input (InputLayer)        (None, 75, 18, 1)         0         \n",
      "_________________________________________________________________\n",
      "tz_block1_conv1 (Conv2D)     (None, 75, 18, 32)        4640      \n",
      "_________________________________________________________________\n",
      "tz_block1_conv2 (Conv2D)     (None, 75, 18, 32)        147488    \n",
      "_________________________________________________________________\n",
      "tz_block1_pool (AveragePooli (None, 38, 9, 32)         0         \n",
      "_________________________________________________________________\n",
      "tz_block2_conv1 (Conv2D)     (None, 38, 9, 64)         294976    \n",
      "_________________________________________________________________\n",
      "tz_block2_conv2 (Conv2D)     (None, 38, 9, 64)         589888    \n",
      "_________________________________________________________________\n",
      "tz_block2_pool (AveragePooli (None, 19, 5, 64)         0         \n",
      "_________________________________________________________________\n",
      "tz_block3_conv2 (Conv2D)     (None, 19, 5, 128)        1179776   \n",
      "_________________________________________________________________\n",
      "tz_block3_pool (AveragePooli (None, 10, 3, 128)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3840)              0         \n",
      "_________________________________________________________________\n",
      "fc-1 (Dense)                 (None, 512)               1966592   \n",
      "_________________________________________________________________\n",
      "fc-2 (Dense)                 (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "prediction (Dense)           (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 4,446,529\n",
      "Trainable params: 4,446,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = TZnet_regression_cosz()\n",
    "model.load_weights('./model/tz_net_regression_64_100_regression_cosz.hdf5')  # TZnet_regression_cosz()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/810 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(810, 51818)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 810/810 [02:26<00:00,  5.53it/s]\n"
     ]
    }
   ],
   "source": [
    "y_true = list()\n",
    "y_pred = list()\n",
    "metadata = None\n",
    "predict_steps, n_test_events = get_n_iterations(fnames_test[:n_files], batch_size=64)\n",
    "print(predict_steps, n_test_events)\n",
    "\n",
    "metadata_gen  = metadata_generator(index_filelist, xy_filelist, metadata_keylist)\n",
    "data_gen = data_generator(fnames_test[:n_files], batch_size=batch_size, \n",
    "                          fdata=get_TZ_only, ftarget=lambda y: y)\n",
    "\n",
    "for i in tqdm(range(predict_steps)):\n",
    "    ZT_batch, y_batch_true = next(data_gen)\n",
    "    metadata_batch = next(metadata_gen)\n",
    "    if metadata is None:\n",
    "        metadata = metadata_batch\n",
    "    else:\n",
    "        metadata = pd.concat((metadata, metadata_batch))\n",
    "    y_batch_pred = model.predict_on_batch(ZT_batch)\n",
    "    y_batch_pred = y_batch_pred.ravel()\n",
    "    y_true.append(y_batch_true)\n",
    "    y_pred.append(y_batch_pred)\n",
    "    \n",
    "y_true = np.hstack(np.asarray(y_true))\n",
    "y_pred = np.hstack(np.asarray(y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3267446726003822"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "mean_squared_error(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.020188022699421548"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_pos = np.argwhere(y_true>0).flatten()\n",
    "y_true_pos = y_true[index_pos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred_pos = y_pred[index_pos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21205295561802565"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_true_pos, y_pred_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46285880430943993"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_neg = np.argwhere(y_true<=0).flatten()\n",
    "y_true_neg = y_true[index_neg]\n",
    "\n",
    "y_pred_neg = y_pred[index_neg]\n",
    "\n",
    "mean_squared_error(y_true_neg, y_pred_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
