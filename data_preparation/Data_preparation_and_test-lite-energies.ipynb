{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import ROOT\n",
    "import numpy as np\n",
    "import root_numpy as rnp\n",
    "from plotly.offline import init_notebook_mode, iplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NFLOORS = 18\n",
    "NSTRING = 115\n",
    "PMTSPERDOM = 31\n",
    "pmtstot = NFLOORS * NSTRING * PMTSPERDOM\n",
    "ndoms = NFLOORS * NSTRING\n",
    "\n",
    "coord_origin = np.asarray((13.887,6.713,405.932))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### execute this cell to load files on server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "detfile = \"utilities/km3net_jul13_90m.detx\"\n",
    "nuefile = \"utilities/km3_v4_nuecc_1.evt.JTE.aa.root\"\n",
    "numufile = \"utilities/km3_v4_numucc_1_B.evt.aa.root\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# run this cell for multiple input files\n",
    "nuefile1 = \"utilities/km3_v4_nuecc_1.evt.JTE.aa.root\"\n",
    "numufile1 = \"utilities/km3_v4_numucc_1_B.evt.aa.root\"\n",
    "nuefile2 = \"utilities/km3_v4_nuecc_2.evt.JTE.aa.root\"\n",
    "numufile2 = \"utilities/km3_v4_numucc_2.evt.JTE.aa.root\"\n",
    "nuefile3 = \"utilities/km3_v4_nuecc_3.evt.JTE.aa.root\"\n",
    "numufile3 = \"utilities/km3_v4_numucc_3.evt.JTE.aa.root\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from load_trees import load_trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### doms and pmts hit for numu and nue files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1 file per type\n",
    "ch_id_numu, dom_id_numu, trig_numu, times_numu = load_trees(numufile)\n",
    "ch_id_nue, dom_id_nue, trig_nue, times_nue = load_trees(nuefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "E_numu = rnp.root2array(numufile, treename='E', branches='Evt.mc_trks.E')\n",
    "type_numu = rnp.root2array(numufile, treename='E', branches = 'Evt.mc_trks.type')\n",
    "E_nue = rnp.root2array(nuefile, treename='E', branches='Evt.mc_trks.E')\n",
    "type_nue = rnp.root2array(nuefile, treename='E', branches = 'Evt.mc_trks.type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "E_numu_ = np.asarray([E_numu[evt][type_numu[evt]==5][0]for evt in range(E_numu.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "E_nue_ = np.asarray([E_nue[evt][type_nue[evt]==3][0]for evt in range(E_nue.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.76293100000000003, 57513900.0)\n"
     ]
    }
   ],
   "source": [
    "(print(np.min(E_numu_), np.max(E_numu_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2.95282, 78860900.0)\n"
     ]
    }
   ],
   "source": [
    "print(np.min(E_nue_), np.max(E_nue_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "700"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E_numu_[E_numu_>10000].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "417"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E_nue_[E_nue_>10000].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 366,  371,  377,  383,  387,  398,  406,  407,  417,  423,  425,\n",
       "         445,  464,  472,  481,  484,  487,  488,  490,  508,  513,  519,\n",
       "         528,  536,  538,  545,  550,  551,  563,  583,  585,  592,  602,\n",
       "         606,  615,  617,  625,  626,  629,  630,  631,  632,  633,  634,\n",
       "         637,  638,  640,  641,  643,  645,  646,  648,  649,  651,  655,\n",
       "         656,  658,  659,  660,  661,  666,  667,  668,  669,  671,  672,\n",
       "         674,  675,  677,  678,  679,  681,  682,  683,  684,  685,  688,\n",
       "         690,  691,  695,  701,  702,  703,  704,  705,  707,  711,  715,\n",
       "         716,  717,  718,  719,  720,  723,  724,  725,  726,  730,  732,\n",
       "         733,  734,  735,  740,  744,  747,  748,  749,  750,  752,  753,\n",
       "         754,  755,  757,  759,  760,  762,  763,  764,  765,  766,  767,\n",
       "         769,  771,  774,  777,  780,  781,  782,  783,  785,  788,  789,\n",
       "         791,  792,  793,  794,  795,  796,  799,  800,  801,  802,  803,\n",
       "         804,  807,  812,  814,  815,  816,  818,  820,  823,  828,  832,\n",
       "         833,  834,  835,  836,  841,  842,  844,  845,  846,  849,  850,\n",
       "         854,  855,  856,  858,  860,  861,  862,  867,  869,  871,  872,\n",
       "         874,  877,  878,  879,  880,  881,  883,  886,  887,  888,  890,\n",
       "         892,  893,  894,  895,  898,  902,  903,  904,  905,  907,  911,\n",
       "         912,  914,  915,  916,  919,  920,  921,  922,  923,  925,  926,\n",
       "         927,  928,  929,  930,  931,  935,  937,  939,  941,  944,  945,\n",
       "         946,  947,  948,  950,  951,  952,  953,  954,  956,  957,  958,\n",
       "         959,  960,  962,  963,  965,  966,  967,  969,  971,  972,  974,\n",
       "         975,  976,  977,  978,  979,  981,  982,  983,  984,  986,  987,\n",
       "         988,  989,  991,  993,  996,  997,  998,  999, 1001, 1002, 1004,\n",
       "        1005, 1006, 1007, 1008, 1009, 1011, 1012, 1013, 1015, 1017, 1018,\n",
       "        1020, 1022, 1023, 1024, 1027, 1028, 1029, 1030, 1032, 1033, 1035,\n",
       "        1036, 1037, 1038, 1039, 1040, 1041, 1042, 1043, 1044, 1045, 1046,\n",
       "        1047, 1048, 1050, 1051, 1052, 1053, 1054, 1057, 1058, 1059, 1060,\n",
       "        1061, 1062, 1064, 1065, 1066, 1068, 1069, 1070, 1071, 1075, 1076,\n",
       "        1078, 1079, 1080, 1081, 1082, 1083, 1085, 1088, 1090, 1092, 1094,\n",
       "        1095, 1096, 1098, 1099, 1100, 1102, 1103, 1104, 1105, 1106, 1107,\n",
       "        1109, 1111, 1112, 1113, 1114, 1116, 1118, 1121, 1122, 1123, 1124,\n",
       "        1125, 1127, 1128, 1129, 1130, 1131, 1133, 1134, 1137, 1140, 1141,\n",
       "        1142, 1143, 1144, 1145, 1146, 1147, 1148, 1149, 1151, 1152, 1153,\n",
       "        1154, 1155, 1156, 1157, 1159, 1160, 1161, 1162, 1163, 1164, 1165,\n",
       "        1166, 1167, 1169, 1170, 1172, 1173, 1174, 1175, 1176, 1177, 1178,\n",
       "        1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1188, 1189, 1190,\n",
       "        1191, 1192, 1194, 1196, 1197, 1198, 1199, 1200, 1201, 1202, 1203,\n",
       "        1204, 1206, 1208, 1209, 1211, 1213, 1214, 1216, 1218, 1219, 1220,\n",
       "        1221, 1222, 1223, 1224, 1225, 1227, 1228, 1229, 1230, 1231, 1232,\n",
       "        1234, 1235, 1236, 1237, 1239, 1241, 1242, 1243, 1244, 1245, 1246,\n",
       "        1248, 1249, 1251, 1254, 1255, 1256, 1258, 1260, 1261, 1262, 1265,\n",
       "        1266, 1267, 1268, 1269, 1270, 1271, 1272, 1273, 1274, 1275, 1276,\n",
       "        1277, 1278, 1279, 1280, 1282, 1283, 1284, 1286, 1287, 1288, 1289,\n",
       "        1290, 1291, 1292, 1294, 1295, 1296, 1300, 1301, 1302, 1303, 1304,\n",
       "        1305, 1306, 1308, 1309, 1311, 1312, 1313, 1314, 1315, 1316, 1317,\n",
       "        1318, 1319, 1320, 1321, 1322, 1323, 1324, 1325, 1326, 1327, 1328,\n",
       "        1329, 1330, 1331, 1332, 1333, 1334, 1335, 1336, 1337, 1338, 1339,\n",
       "        1341, 1342, 1343, 1345, 1346, 1348, 1350, 1351, 1353, 1355, 1357,\n",
       "        1359, 1360, 1361, 1362, 1363, 1364, 1365, 1366, 1368, 1369, 1370,\n",
       "        1371, 1372, 1373, 1374, 1375, 1377, 1378, 1379, 1380, 1381, 1382,\n",
       "        1383, 1384, 1385, 1386, 1388, 1389, 1390, 1391, 1392, 1394, 1395,\n",
       "        1396, 1398, 1399, 1400, 1401, 1403, 1404, 1405, 1406, 1409, 1410,\n",
       "        1411, 1412, 1413, 1414, 1415, 1416, 1417, 1418, 1419, 1420, 1421,\n",
       "        1422, 1423, 1424, 1425, 1426, 1427, 1428, 1429, 1433, 1434, 1435,\n",
       "        1436, 1437, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1447,\n",
       "        1448, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458,\n",
       "        1459, 1460, 1461, 1462, 1463, 1464, 1465, 1467, 1468, 1470, 1471,\n",
       "        1472, 1474, 1475, 1476, 1477, 1478, 1479, 1480, 1481, 1482, 1483,\n",
       "        1484, 1485, 1486, 1487, 1489, 1490, 1491, 1492, 1493, 1494, 1495,\n",
       "        1496, 1497, 1498, 1499, 1500, 1501, 1502, 1503, 1505, 1506, 1507,\n",
       "        1508, 1509, 1510, 1511, 1512, 1513, 1514, 1515, 1516, 1517, 1518,\n",
       "        1519, 1520, 1521, 1523, 1524, 1526, 1527, 1528, 1529, 1530, 1531,\n",
       "        1532, 1533, 1535, 1537, 1538, 1539, 1540]),)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(E_numu_>10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dom_id[evt]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  multiple input files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ch_id_numu1, dom_id_numu1, trig_numu1, times_numu1 = load_trees(numufile1)\n",
    "ch_id_nue1, dom_id_nue1, trig_nue1, times_nue1 = load_trees(nuefile1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ch_id_numu2, dom_id_numu2, trig_numu2, times_numu2 = load_trees(numufile2)\n",
    "ch_id_nue2, dom_id_nue2, trig_nue2, times_nue2 = load_trees(nuefile2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ch_id_numu3, dom_id_numu3, trig_numu3, times_numu3 = load_trees(numufile3)\n",
    "ch_id_nue3, dom_id_nue3, trig_nue3, times_nue3 = load_trees(nuefile3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### create Data structure with the id of the hit DOMs and the discretized times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from timeslices import tslices\n",
    "from timeslices import tslices_multi_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49997887.0, 49993098.0, 50000747.0, 50004225.0, 49993098.0, 50004225.0)\n"
     ]
    }
   ],
   "source": [
    "timeslice = tslices(times_numu, times_nue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'times_numu1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-51890c4bd91b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtimeslice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtslices_multi_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimes_numu1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimes_nue1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimes_numu2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimes_nue2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimes_numu2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimes_nue2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'times_numu1' is not defined"
     ]
    }
   ],
   "source": [
    "timeslice = tslices_multi_files(times_numu1, times_nue1, times_numu2, times_nue2, times_numu2, times_nue2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "timeslice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "timeslice.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from data_preparation import Xy_creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_numu, Y_numu  = Xy_creation(timeslice, dom_id_numu, trig_numu, times_numu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_nue, Y_nue = Xy_creation(timeslice, dom_id_nue, trig_nue, times_nue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### alternative definition of data structure\n",
    "#### DOMs are now organized in strings and floors\n",
    "### let\"s try this with a convolutional neural network!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from data_preparation import Xy_creation_fl_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_numu, Y_numu = Xy_creation_fl_str(timeslice, dom_id_numu, trig_numu, times_numu, 'numu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_nue, Y_nue = Xy_creation_fl_str(timeslice, dom_id_nue, trig_nue, times_nue, 'nue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### try separating low energies from high energies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l_numu = np.where(E_numu_<10000)[0]\n",
    "l_nue = np.where(E_nue_<10000)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_numu_low, Y_numu_low = Xy_creation_fl_str(timeslice, dom_id_numu[l_numu], trig_numu[l_numu], times_numu[l_numu], 'numu')\n",
    "X_nue_low, Y_nue_low = Xy_creation_fl_str(timeslice, dom_id_nue[l_nue], trig_nue[l_nue], times_nue[l_nue], 'nue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h_numu = np.where(E_numu_>10000)[0]\n",
    "h_nue = np.where(E_nue_>10000)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_numu_high, Y_numu_high = Xy_creation_fl_str(timeslice, dom_id_numu[h_numu], trig_numu[h_numu], times_numu[h_numu], 'numu')\n",
    "X_nue_high, Y_nue_high = Xy_creation_fl_str(timeslice, dom_id_nue[h_nue], trig_nue[h_nue], times_nue[h_nue], 'nue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mutiple files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_numu1, Y_numu1 = Xy_creation_fl_str(timeslice, dom_id_numu1, trig_numu1, times_numu1, 'numu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_nue1, Y_nue1 = Xy_creation_fl_str(timeslice, dom_id_nue1, trig_nue1, times_nue1, 'nue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_numu2, Y_numu2 = Xy_creation_fl_str(timeslice, dom_id_numu2, trig_numu2, times_numu2, 'numu')\n",
    "X_nue2, Y_nue2 = Xy_creation_fl_str(timeslice, dom_id_nue2, trig_nue2, times_nue2, 'nue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_numu3, Y_numu3 = Xy_creation_fl_str(timeslice, dom_id_numu3, trig_numu3, times_numu3, 'numu')\n",
    "X_nue3, Y_nue3 = Xy_creation_fl_str(timeslice, dom_id_nue3, trig_nue3, times_nue3, 'nue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_numu.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_nue.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check the shape of the data set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('X_numu: ', (1541, 75, 115, 18), 'X_nue: ', (1183, 75, 115, 18), 'Y_numu: ', (1541,), 'Y_nue: ', (1183,))\n"
     ]
    }
   ],
   "source": [
    "#single file\n",
    "print('X_numu: ', X_numu.shape, 'X_nue: ', X_nue.shape, 'Y_numu: ', Y_numu.shape, 'Y_nue: ', Y_nue.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('X_numu: ', X_numu1.shape, 'X_nue: ', X_nue1.shape, 'Y_numu: ', Y_numu1.shape, 'Y_nue: ', Y_nue1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('X_numu: ', X_numu2.shape, 'X_nue: ', X_nue2.shape, 'Y_numu: ', Y_numu2.shape, 'Y_nue: ', Y_nue2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('X_numu: ', X_numu3.shape, 'X_nue: ', X_nue3.shape, 'Y_numu: ', Y_numu3.shape, 'Y_nue: ', Y_nue3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('X_numu: ', (841, 75, 115, 18), 'X_nue: ', (766, 75, 115, 18), 'Y_numu: ', (841,), 'Y_nue: ', (766,))\n"
     ]
    }
   ],
   "source": [
    "print('X_numu: ', X_numu_low.shape, 'X_nue: ', X_nue_low.shape, 'Y_numu: ', Y_numu_low.shape, 'Y_nue: ', Y_nue_low.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('X_numu: ', (700, 75, 115, 18), 'X_nue: ', (417, 75, 115, 18), 'Y_numu: ', (700,), 'Y_nue: ', (417,))\n"
     ]
    }
   ],
   "source": [
    "print('X_numu: ', X_numu_high.shape, 'X_nue: ', X_nue_high.shape, 'Y_numu: ', Y_numu_high.shape, 'Y_nue: ', Y_nue_high.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### append nue to numu data, without mixing : from now on, data will be X an Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  single file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.vstack((X_numu, X_nue))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y = np.concatenate((Y_numu, Y_nue))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "E_tot = np.concatenate((E_numu_, E_nue_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2724"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E_tot.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2724, 75, 115, 18)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12997.799999999999, 0.0)\n"
     ]
    }
   ],
   "source": [
    "print(E_tot[indx2][0], Y[indx2][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### multiple files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_numu = np.vstack((X_numu1, X_numu2))#, X_numu3))\n",
    "X_nue = np.vstack((X_nue1, X_nue2))#, X_nue3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.vstack((X_numu, X_nue))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_numu = np.concatenate((Y_numu1, Y_numu2))#, Y_numu3))\n",
    "Y_nue = np.concatenate((Y_nue1, Y_nue2))#, Y_nue3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y = np.concatenate((Y_numu, Y_nue))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### separated energies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_low = np.vstack((X_numu_low, X_nue_low))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_low = np.concatenate((Y_numu_low, Y_nue_low))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1607, 75, 115, 18)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_low.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1607,)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_low.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_high = np.vstack((X_numu_high, X_nue_high))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_high = np.concatenate((Y_numu_high, Y_nue_high))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1117, 75, 115, 18)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_high.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1117,)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_high.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "E_numu_low = E_numu_[l_numu]\n",
    "E_nue_low = E_nue[l_nue]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "E_numu_high = E_numu_[h_numu]\n",
    "E_nue_high = E_nue[h_nue]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "E_low = np.concatenate((E_numu_low, E_nue_low))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "E_high = np.concatenate((E_numu_high, E_nue_high))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save to output file X and Y\n",
    "#np.save('X_matrix.npy', X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#used later in cross validation\n",
    "#y_numu_categ = np_utils.to_categorical(Y_numu, 2)\n",
    "#y_nue_categ = np_utils.to_categorical(Y_nue, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#y = np.concatenate((y_numu_categ, y_nue_categ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use `sklearn` to split train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#theano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 0: GeForce GTX 780 Ti (CNMeM is disabled, cuDNN not available)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "#os.environ[\"THEANO_FLAGS\"]= \"mode=FAST_RUN, device=gpu,floatX=float32\"\n",
    "import theano\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#start here if using tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('X_train: ', (2043, 75, 115, 18), 'X_test: ', (681, 75, 115, 18), 'Y_train: ', (2043,), 'Y_test: ', (681,))\n"
     ]
    }
   ],
   "source": [
    "print('X_train: ', X_train.shape, 'X_test: ', X_test.shape, 'Y_train: ', Y_train.shape, 'Y_test: ', Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indices = np.arange(X.shape[0])\n",
    "X_train, X_test, Y_train, Y_test, indx1, indx2 = train_test_split(X, Y, indices, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(X[indx2][0]==X_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indices = np.arange(X_high.shape[0])\n",
    "X_train, X_test, Y_train, Y_test, indx1, indx2 = train_test_split(X_high, Y_high, indices, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "893"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indx1.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "224"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indx2.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  1,   2,   6,   8,  10,  11,  13,  14,  16,  17,  18,  19,  20,\n",
       "         21,  22,  23,  25,  26,  27,  28,  29,  33,  35,  39,  40,  43,\n",
       "         45,  48,  49,  50,  51,  52,  54,  57,  58,  60,  65,  66,  68,\n",
       "         71,  72,  73,  74,  75,  78,  80,  81,  83,  85,  87,  88,  89,\n",
       "         93,  94,  95,  96, 100, 101, 102, 103, 104, 105, 107, 108, 109,\n",
       "        110, 111, 116, 117, 119, 121, 122, 127, 128, 131, 134, 135, 137,\n",
       "        140, 141, 142, 143, 145, 146, 148, 149, 151, 154, 155, 156, 157,\n",
       "        158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 169, 170, 172,\n",
       "        173, 176, 178, 180, 181, 182, 188, 189, 192, 194, 195, 196, 197,\n",
       "        198, 199, 200, 201, 202, 204, 205, 206, 207, 208, 209, 211, 212,\n",
       "        213, 214, 215, 222, 223]),)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(Y_test==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_high"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training with Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_validation_acc = 0.0\n",
    "best_model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.losses import categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fully connected model. To be used with different dataset (from CNN), because data must be reshaped to 2D\n",
    "def dense_model():\n",
    "    ## TRY different activations, e.g. tanh, sigmoid.\n",
    "    model = Sequential()\n",
    "    model.add(Dense(2070, input_shape=((Xtrain.shape[1], Xtrain.shape[2])), activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(2070, activation = 'relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  data format for keras (differen in `th` and `tf`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#tensorflow\n",
    "img_rows = X_train.shape[1]\n",
    "img_cols = X_train.shape[2]\n",
    "img_channel = X_train.shape[3]\n",
    "input_shape = (img_rows, img_cols, img_channel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# theano\n",
    "img_channel = X_train.shape[1]\n",
    "img_rows = X_train.shape[2]\n",
    "img_cols = X_train.shape[3]\n",
    "input_shape = (img_channel, img_rows, img_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2179, 75, 115, 18)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75, 115, 18)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cnn_model():\n",
    "    early_stop = EarlyStopping(monitor='val_acc', patience=4, verbose=1)\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(128, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(Convolution2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    #model.add(Dropout(0.1))\n",
    "    model.add(Convolution2D(32, (3, 3), activation='relu'))\n",
    "    #model.add(Dropout(0.25))\n",
    "    model.add(Convolution2D(32, (3, 3), activation='relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(loss=categorical_crossentropy,\n",
    "                  optimizer=keras.optimizers.Adadelta(),\n",
    "                  metrics=['accuracy'])\n",
    "    model.summary()\n",
    "\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cnn_model_deep():\n",
    "    early_stop = EarlyStopping(monitor='val_acc', patience=4, verbose=1)\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(128, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(Convolution2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), data_format='channels_first'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Convolution2D(32, (3, 3), activation='relu'))\n",
    "    model.add(Convolution2D(32, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), data_format='channels_first'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(loss=categorical_crossentropy,\n",
    "                  optimizer=keras.optimizers.Adadelta(),\n",
    "                  metrics=['accuracy'])\n",
    "    model.summary()\n",
    "\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dense_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-529f787c689f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcreate_nn_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdense_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'dense_model' is not defined"
     ]
    }
   ],
   "source": [
    "create_nn_model = dense_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "create_nn_model = cnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "create_nn_model = cnn_model_deep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "create_nn_model = cnn_model_deep2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "create_nn_model = cnn_model_deep3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "create_nn_model = cnn_1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(750, 75, 115, 18)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Fully connecter netword( w old dataset - ndoms not splitted in strings and floors)\n",
    "\n",
    "for i, (train_index, validation_index) in enumerate(skf.split(X_FC_train, Y_train)):\n",
    "    print(i+1)\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", validation_index)\n",
    "    Xtrain, Xvalidation = X_FC_train[train_index], X_FC_train[validation_index]\n",
    "    ytrain, yvalidation = Y_train[train_index], Y_train[validation_index]\n",
    "    model = create_nn_model()\n",
    "    Ytrain = np_utils.to_categorical(ytrain)\n",
    "    Yvalidation = np_utils.to_categorical(yvalidation)\n",
    "    \n",
    "    history = model.fit(Xtrain, Ytrain, batch_size=115,\n",
    "                        epochs=20, verbose=1,\n",
    "                        validation_data = (Xvalidation, Yvalidation))\n",
    "    validation_acc = history.history['val_acc']\n",
    "    if validation_acc > best_validation_acc:\n",
    "        best_validation_acc = validation_acc\n",
    "        best_model = model\n",
    "Ytrain = np_utils.to_categorical(ytrain)\n",
    "best_model.fit(Xtrain, Ytrain, batch_size=115, epochs=20)  # replicate conf.\n",
    "\n",
    "predictions = best_model.predict(X_FC_test)\n",
    "cls_predictions = np.argmax(predictions, axis=1)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(Y_test, cls_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_13 (Conv2D)           (None, 128, 113, 16)      86528     \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 64, 111, 14)       73792     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 64, 55, 7)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 32, 53, 5)         18464     \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 32, 51, 3)         9248      \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 4896)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2)                 9794      \n",
      "=================================================================\n",
      "Total params: 197,826\n",
      "Trainable params: 197,826\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 599 samples, validate on 151 samples\n",
      "Epoch 1/30\n",
      "599/599 [==============================] - 13s - loss: 0.6929 - acc: 0.5042 - val_loss: 0.6929 - val_acc: 0.5099\n",
      "Epoch 2/30\n",
      "599/599 [==============================] - 13s - loss: 0.6919 - acc: 0.5225 - val_loss: 0.6920 - val_acc: 0.5099\n",
      "Epoch 3/30\n",
      "599/599 [==============================] - 13s - loss: 0.6884 - acc: 0.5509 - val_loss: 0.6966 - val_acc: 0.5033\n",
      "Epoch 4/30\n",
      "599/599 [==============================] - 13s - loss: 0.6879 - acc: 0.5476 - val_loss: 0.6879 - val_acc: 0.5099\n",
      "Epoch 5/30\n",
      "599/599 [==============================] - 13s - loss: 0.6735 - acc: 0.5559 - val_loss: 0.6792 - val_acc: 0.5960\n",
      "Epoch 6/30\n",
      "599/599 [==============================] - 13s - loss: 0.6486 - acc: 0.6260 - val_loss: 0.6520 - val_acc: 0.6093\n",
      "Epoch 7/30\n",
      "599/599 [==============================] - 13s - loss: 0.6164 - acc: 0.6778 - val_loss: 0.5814 - val_acc: 0.7219\n",
      "Epoch 8/30\n",
      "599/599 [==============================] - 13s - loss: 0.5277 - acc: 0.7496 - val_loss: 0.5059 - val_acc: 0.7682\n",
      "Epoch 9/30\n",
      "599/599 [==============================] - 13s - loss: 0.4480 - acc: 0.8047 - val_loss: 0.4340 - val_acc: 0.7947\n",
      "Epoch 10/30\n",
      "599/599 [==============================] - 13s - loss: 0.3937 - acc: 0.8414 - val_loss: 0.4670 - val_acc: 0.7748\n",
      "Epoch 11/30\n",
      "599/599 [==============================] - 13s - loss: 0.3549 - acc: 0.8614 - val_loss: 0.4034 - val_acc: 0.8146\n",
      "Epoch 12/30\n",
      "599/599 [==============================] - 13s - loss: 0.3286 - acc: 0.8765 - val_loss: 0.3689 - val_acc: 0.8344\n",
      "Epoch 13/30\n",
      "599/599 [==============================] - 13s - loss: 0.3035 - acc: 0.8815 - val_loss: 0.3804 - val_acc: 0.8344\n",
      "Epoch 14/30\n",
      "599/599 [==============================] - 13s - loss: 0.3235 - acc: 0.8681 - val_loss: 0.3893 - val_acc: 0.8675\n",
      "Epoch 15/30\n",
      "599/599 [==============================] - 13s - loss: 0.2862 - acc: 0.8831 - val_loss: 0.3290 - val_acc: 0.8742\n",
      "Epoch 16/30\n",
      "599/599 [==============================] - 13s - loss: 0.2529 - acc: 0.9032 - val_loss: 0.3521 - val_acc: 0.8874\n",
      "Epoch 17/30\n",
      "599/599 [==============================] - 13s - loss: 0.2444 - acc: 0.8998 - val_loss: 0.3638 - val_acc: 0.8940\n",
      "Epoch 18/30\n",
      "599/599 [==============================] - 13s - loss: 0.2481 - acc: 0.8982 - val_loss: 0.4182 - val_acc: 0.8543\n",
      "Epoch 19/30\n",
      "599/599 [==============================] - 13s - loss: 0.2268 - acc: 0.9065 - val_loss: 0.4017 - val_acc: 0.8874\n",
      "Epoch 20/30\n",
      "599/599 [==============================] - 13s - loss: 0.2074 - acc: 0.9115 - val_loss: 0.3357 - val_acc: 0.8940\n",
      "Epoch 21/30\n",
      "599/599 [==============================] - 13s - loss: 0.1985 - acc: 0.9299 - val_loss: 0.3729 - val_acc: 0.8675\n",
      "Epoch 22/30\n",
      "599/599 [==============================] - 13s - loss: 0.1942 - acc: 0.9232 - val_loss: 0.3669 - val_acc: 0.9007\n",
      "Epoch 23/30\n",
      "599/599 [==============================] - 13s - loss: 0.1840 - acc: 0.9249 - val_loss: 0.4406 - val_acc: 0.8675\n",
      "Epoch 24/30\n",
      "599/599 [==============================] - 13s - loss: 0.1937 - acc: 0.9282 - val_loss: 0.3794 - val_acc: 0.8808\n",
      "Epoch 25/30\n",
      "599/599 [==============================] - 13s - loss: 0.1644 - acc: 0.9466 - val_loss: 0.3799 - val_acc: 0.9007\n",
      "Epoch 26/30\n",
      "599/599 [==============================] - 13s - loss: 0.1543 - acc: 0.9449 - val_loss: 0.3676 - val_acc: 0.9073\n",
      "Epoch 27/30\n",
      "599/599 [==============================] - 13s - loss: 0.1434 - acc: 0.9533 - val_loss: 0.3841 - val_acc: 0.8808\n",
      "Epoch 28/30\n",
      "599/599 [==============================] - 13s - loss: 0.1410 - acc: 0.9482 - val_loss: 0.3837 - val_acc: 0.9073\n",
      "Epoch 29/30\n",
      "599/599 [==============================] - 13s - loss: 0.1325 - acc: 0.9583 - val_loss: 0.3867 - val_acc: 0.9139\n",
      "Epoch 30/30\n",
      "599/599 [==============================] - 13s - loss: 0.1289 - acc: 0.9549 - val_loss: 0.3940 - val_acc: 0.8874\n",
      "2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_17 (Conv2D)           (None, 128, 113, 16)      86528     \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 64, 111, 14)       73792     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 64, 55, 7)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 32, 53, 5)         18464     \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 32, 51, 3)         9248      \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 4896)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2)                 9794      \n",
      "=================================================================\n",
      "Total params: 197,826\n",
      "Trainable params: 197,826\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 599 samples, validate on 151 samples\n",
      "Epoch 1/30\n",
      "599/599 [==============================] - 14s - loss: 0.6928 - acc: 0.4992 - val_loss: 0.6922 - val_acc: 0.5166\n",
      "Epoch 2/30\n",
      "599/599 [==============================] - 13s - loss: 0.6913 - acc: 0.5526 - val_loss: 0.6918 - val_acc: 0.5033\n",
      "Epoch 3/30\n",
      "599/599 [==============================] - 14s - loss: 0.6900 - acc: 0.5125 - val_loss: 0.6885 - val_acc: 0.5033\n",
      "Epoch 4/30\n",
      "599/599 [==============================] - 13s - loss: 0.6872 - acc: 0.5075 - val_loss: 0.6861 - val_acc: 0.5695\n",
      "Epoch 5/30\n",
      "599/599 [==============================] - 13s - loss: 0.6795 - acc: 0.5776 - val_loss: 0.7112 - val_acc: 0.5033\n",
      "Epoch 6/30\n",
      "599/599 [==============================] - 13s - loss: 0.6665 - acc: 0.5793 - val_loss: 0.6524 - val_acc: 0.6291\n",
      "Epoch 7/30\n",
      "599/599 [==============================] - 13s - loss: 0.6204 - acc: 0.6628 - val_loss: 0.5864 - val_acc: 0.6954\n",
      "Epoch 8/30\n",
      "599/599 [==============================] - 13s - loss: 0.5267 - acc: 0.7596 - val_loss: 0.4743 - val_acc: 0.7682\n",
      "Epoch 9/30\n",
      "599/599 [==============================] - 13s - loss: 0.4852 - acc: 0.7813 - val_loss: 0.4396 - val_acc: 0.8344\n",
      "Epoch 10/30\n",
      "599/599 [==============================] - 13s - loss: 0.4025 - acc: 0.8280 - val_loss: 0.3829 - val_acc: 0.8675\n",
      "Epoch 11/30\n",
      "599/599 [==============================] - 13s - loss: 0.3675 - acc: 0.8347 - val_loss: 0.3116 - val_acc: 0.8940\n",
      "Epoch 12/30\n",
      "599/599 [==============================] - 13s - loss: 0.3453 - acc: 0.8614 - val_loss: 0.2812 - val_acc: 0.9205\n",
      "Epoch 13/30\n",
      "599/599 [==============================] - 13s - loss: 0.3206 - acc: 0.8715 - val_loss: 0.2603 - val_acc: 0.9272\n",
      "Epoch 14/30\n",
      "599/599 [==============================] - 13s - loss: 0.3004 - acc: 0.8881 - val_loss: 0.2637 - val_acc: 0.8940\n",
      "Epoch 15/30\n",
      "599/599 [==============================] - 13s - loss: 0.2974 - acc: 0.8731 - val_loss: 0.2327 - val_acc: 0.9205\n",
      "Epoch 16/30\n",
      "599/599 [==============================] - 13s - loss: 0.2761 - acc: 0.8865 - val_loss: 0.2335 - val_acc: 0.9205\n",
      "Epoch 17/30\n",
      "599/599 [==============================] - 13s - loss: 0.2531 - acc: 0.8998 - val_loss: 0.4696 - val_acc: 0.8344\n",
      "Epoch 18/30\n",
      "599/599 [==============================] - 13s - loss: 0.2563 - acc: 0.8965 - val_loss: 0.2207 - val_acc: 0.9007\n",
      "Epoch 19/30\n",
      "599/599 [==============================] - 13s - loss: 0.2431 - acc: 0.9132 - val_loss: 0.1956 - val_acc: 0.9272\n",
      "Epoch 20/30\n",
      "599/599 [==============================] - 13s - loss: 0.2367 - acc: 0.9048 - val_loss: 0.2330 - val_acc: 0.9073\n",
      "Epoch 21/30\n",
      "599/599 [==============================] - 13s - loss: 0.2141 - acc: 0.9249 - val_loss: 0.1861 - val_acc: 0.9272\n",
      "Epoch 22/30\n",
      "599/599 [==============================] - 13s - loss: 0.2042 - acc: 0.9249 - val_loss: 0.2160 - val_acc: 0.9139\n",
      "Epoch 23/30\n",
      "599/599 [==============================] - 13s - loss: 0.2058 - acc: 0.9199 - val_loss: 0.2400 - val_acc: 0.8940\n",
      "Epoch 24/30\n",
      "599/599 [==============================] - 13s - loss: 0.2023 - acc: 0.9215 - val_loss: 0.2983 - val_acc: 0.8874\n",
      "Epoch 25/30\n",
      "599/599 [==============================] - 13s - loss: 0.1999 - acc: 0.9199 - val_loss: 0.1682 - val_acc: 0.9272\n",
      "Epoch 26/30\n",
      "599/599 [==============================] - 13s - loss: 0.1711 - acc: 0.9416 - val_loss: 0.3008 - val_acc: 0.8808\n",
      "Epoch 27/30\n",
      "599/599 [==============================] - 13s - loss: 0.1718 - acc: 0.9349 - val_loss: 0.1664 - val_acc: 0.9338\n",
      "Epoch 28/30\n",
      "599/599 [==============================] - 13s - loss: 0.1603 - acc: 0.9432 - val_loss: 0.2264 - val_acc: 0.9205\n",
      "Epoch 29/30\n",
      "599/599 [==============================] - 14s - loss: 0.1692 - acc: 0.9399 - val_loss: 0.1792 - val_acc: 0.9338\n",
      "Epoch 30/30\n",
      "599/599 [==============================] - 13s - loss: 0.1540 - acc: 0.9466 - val_loss: 0.1737 - val_acc: 0.9205\n",
      "3\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_21 (Conv2D)           (None, 128, 113, 16)      86528     \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 64, 111, 14)       73792     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 64, 55, 7)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 32, 53, 5)         18464     \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 32, 51, 3)         9248      \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 4896)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2)                 9794      \n",
      "=================================================================\n",
      "Total params: 197,826\n",
      "Trainable params: 197,826\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 600 samples, validate on 150 samples\n",
      "Epoch 1/30\n",
      "600/600 [==============================] - 14s - loss: 0.6929 - acc: 0.5000 - val_loss: 0.6925 - val_acc: 0.4933\n",
      "Epoch 2/30\n",
      "600/600 [==============================] - 13s - loss: 0.6920 - acc: 0.5183 - val_loss: 0.6920 - val_acc: 0.5200\n",
      "Epoch 3/30\n",
      "600/600 [==============================] - 13s - loss: 0.6901 - acc: 0.5383 - val_loss: 0.6911 - val_acc: 0.5067\n",
      "Epoch 4/30\n",
      "600/600 [==============================] - 13s - loss: 0.6862 - acc: 0.5383 - val_loss: 0.6882 - val_acc: 0.5133\n",
      "Epoch 5/30\n",
      "600/600 [==============================] - 13s - loss: 0.6741 - acc: 0.5550 - val_loss: 0.6970 - val_acc: 0.5067\n",
      "Epoch 6/30\n",
      "600/600 [==============================] - 13s - loss: 0.6578 - acc: 0.5933 - val_loss: 0.6791 - val_acc: 0.5067\n",
      "Epoch 7/30\n",
      "600/600 [==============================] - 13s - loss: 0.6127 - acc: 0.6817 - val_loss: 0.5841 - val_acc: 0.7067\n",
      "Epoch 8/30\n",
      "600/600 [==============================] - 13s - loss: 0.5214 - acc: 0.7450 - val_loss: 0.4941 - val_acc: 0.7600\n",
      "Epoch 9/30\n",
      "600/600 [==============================] - 13s - loss: 0.4353 - acc: 0.8050 - val_loss: 0.4593 - val_acc: 0.7733\n",
      "Epoch 10/30\n",
      "600/600 [==============================] - 13s - loss: 0.3775 - acc: 0.8350 - val_loss: 0.3857 - val_acc: 0.8333\n",
      "Epoch 11/30\n",
      "600/600 [==============================] - 13s - loss: 0.3288 - acc: 0.8733 - val_loss: 0.4365 - val_acc: 0.8267\n",
      "Epoch 12/30\n",
      "600/600 [==============================] - 13s - loss: 0.2943 - acc: 0.8750 - val_loss: 0.4079 - val_acc: 0.8400\n",
      "Epoch 13/30\n",
      "600/600 [==============================] - 13s - loss: 0.2930 - acc: 0.8783 - val_loss: 0.3810 - val_acc: 0.8467\n",
      "Epoch 14/30\n",
      "600/600 [==============================] - 13s - loss: 0.2713 - acc: 0.8983 - val_loss: 0.3928 - val_acc: 0.8533\n",
      "Epoch 15/30\n",
      "600/600 [==============================] - 13s - loss: 0.2415 - acc: 0.8950 - val_loss: 0.3901 - val_acc: 0.8467\n",
      "Epoch 16/30\n",
      "600/600 [==============================] - 14s - loss: 0.2268 - acc: 0.9133 - val_loss: 0.5397 - val_acc: 0.8133\n",
      "Epoch 17/30\n",
      "600/600 [==============================] - 13s - loss: 0.2228 - acc: 0.9183 - val_loss: 0.4552 - val_acc: 0.8600\n",
      "Epoch 18/30\n",
      "600/600 [==============================] - 13s - loss: 0.1993 - acc: 0.9150 - val_loss: 0.4171 - val_acc: 0.8800\n",
      "Epoch 19/30\n",
      "600/600 [==============================] - 13s - loss: 0.1879 - acc: 0.9217 - val_loss: 0.4973 - val_acc: 0.8467\n",
      "Epoch 20/30\n",
      "600/600 [==============================] - 13s - loss: 0.1813 - acc: 0.9317 - val_loss: 0.4395 - val_acc: 0.8667\n",
      "Epoch 21/30\n",
      "600/600 [==============================] - 13s - loss: 0.1690 - acc: 0.9350 - val_loss: 0.4349 - val_acc: 0.8533\n",
      "Epoch 22/30\n",
      "600/600 [==============================] - 13s - loss: 0.1545 - acc: 0.9450 - val_loss: 0.4830 - val_acc: 0.8533\n",
      "Epoch 23/30\n",
      "600/600 [==============================] - 13s - loss: 0.1700 - acc: 0.9267 - val_loss: 0.4364 - val_acc: 0.8667\n",
      "Epoch 24/30\n",
      "600/600 [==============================] - 13s - loss: 0.1490 - acc: 0.9500 - val_loss: 0.4552 - val_acc: 0.8667\n",
      "Epoch 25/30\n",
      "600/600 [==============================] - 13s - loss: 0.1321 - acc: 0.9500 - val_loss: 0.5438 - val_acc: 0.8467\n",
      "Epoch 26/30\n",
      "600/600 [==============================] - 13s - loss: 0.1415 - acc: 0.9500 - val_loss: 0.5322 - val_acc: 0.8400\n",
      "Epoch 27/30\n",
      "600/600 [==============================] - 13s - loss: 0.1367 - acc: 0.9433 - val_loss: 0.5006 - val_acc: 0.8667\n",
      "Epoch 28/30\n",
      "600/600 [==============================] - 13s - loss: 0.1085 - acc: 0.9650 - val_loss: 0.5294 - val_acc: 0.8533\n",
      "Epoch 29/30\n",
      "600/600 [==============================] - 13s - loss: 0.0984 - acc: 0.9733 - val_loss: 0.4965 - val_acc: 0.8600\n",
      "Epoch 30/30\n",
      "600/600 [==============================] - 13s - loss: 0.1143 - acc: 0.9617 - val_loss: 0.5261 - val_acc: 0.8733\n",
      "4\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_25 (Conv2D)           (None, 128, 113, 16)      86528     \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 64, 111, 14)       73792     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 64, 55, 7)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 32, 53, 5)         18464     \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 32, 51, 3)         9248      \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 4896)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 2)                 9794      \n",
      "=================================================================\n",
      "Total params: 197,826\n",
      "Trainable params: 197,826\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 601 samples, validate on 149 samples\n",
      "Epoch 1/30\n",
      "601/601 [==============================] - 14s - loss: 0.6927 - acc: 0.5258 - val_loss: 0.6922 - val_acc: 0.4966\n",
      "Epoch 2/30\n",
      "601/601 [==============================] - 13s - loss: 0.6921 - acc: 0.5241 - val_loss: 0.6915 - val_acc: 0.5168\n",
      "Epoch 3/30\n",
      "601/601 [==============================] - 13s - loss: 0.6913 - acc: 0.5408 - val_loss: 0.6906 - val_acc: 0.5973\n",
      "Epoch 4/30\n",
      "601/601 [==============================] - 13s - loss: 0.6866 - acc: 0.5907 - val_loss: 0.6868 - val_acc: 0.6107\n",
      "Epoch 5/30\n",
      "601/601 [==============================] - 13s - loss: 0.6792 - acc: 0.5458 - val_loss: 0.6773 - val_acc: 0.5034\n",
      "Epoch 6/30\n",
      "601/601 [==============================] - 13s - loss: 0.6880 - acc: 0.6007 - val_loss: 0.6682 - val_acc: 0.6510\n",
      "Epoch 7/30\n",
      "601/601 [==============================] - 13s - loss: 0.6561 - acc: 0.6539 - val_loss: 0.6429 - val_acc: 0.6174\n",
      "Epoch 8/30\n",
      "601/601 [==============================] - 13s - loss: 0.6111 - acc: 0.6839 - val_loss: 0.5920 - val_acc: 0.7248\n",
      "Epoch 9/30\n",
      "601/601 [==============================] - 13s - loss: 0.5334 - acc: 0.7754 - val_loss: 0.5682 - val_acc: 0.6980\n",
      "Epoch 10/30\n",
      "601/601 [==============================] - 13s - loss: 0.4771 - acc: 0.7854 - val_loss: 0.6132 - val_acc: 0.6577\n",
      "Epoch 11/30\n",
      "601/601 [==============================] - 13s - loss: 0.4129 - acc: 0.8270 - val_loss: 0.5810 - val_acc: 0.7651\n",
      "Epoch 12/30\n",
      "601/601 [==============================] - 13s - loss: 0.3691 - acc: 0.8502 - val_loss: 0.4892 - val_acc: 0.7651\n",
      "Epoch 13/30\n",
      "601/601 [==============================] - 13s - loss: 0.3359 - acc: 0.8636 - val_loss: 0.4872 - val_acc: 0.8121\n",
      "Epoch 14/30\n",
      "601/601 [==============================] - 13s - loss: 0.3098 - acc: 0.8719 - val_loss: 0.5002 - val_acc: 0.8255\n",
      "Epoch 15/30\n",
      "601/601 [==============================] - 13s - loss: 0.2979 - acc: 0.8735 - val_loss: 0.5089 - val_acc: 0.8389\n",
      "Epoch 16/30\n",
      "601/601 [==============================] - 13s - loss: 0.2798 - acc: 0.8769 - val_loss: 0.5231 - val_acc: 0.8456\n",
      "Epoch 17/30\n",
      "601/601 [==============================] - 13s - loss: 0.2636 - acc: 0.8835 - val_loss: 0.5458 - val_acc: 0.8456\n",
      "Epoch 18/30\n",
      "601/601 [==============================] - 13s - loss: 0.2485 - acc: 0.8968 - val_loss: 0.6017 - val_acc: 0.8523\n",
      "Epoch 19/30\n",
      "601/601 [==============================] - 13s - loss: 0.2346 - acc: 0.9118 - val_loss: 0.5987 - val_acc: 0.8523\n",
      "Epoch 20/30\n",
      "601/601 [==============================] - 13s - loss: 0.2226 - acc: 0.9201 - val_loss: 0.5936 - val_acc: 0.8523\n",
      "Epoch 21/30\n",
      "601/601 [==============================] - 13s - loss: 0.2287 - acc: 0.9068 - val_loss: 0.5952 - val_acc: 0.8456\n",
      "Epoch 22/30\n",
      "601/601 [==============================] - 13s - loss: 0.2052 - acc: 0.9235 - val_loss: 0.5902 - val_acc: 0.8255\n",
      "Epoch 23/30\n",
      "601/601 [==============================] - 13s - loss: 0.2070 - acc: 0.9235 - val_loss: 0.5911 - val_acc: 0.8591\n",
      "Epoch 24/30\n",
      "601/601 [==============================] - 13s - loss: 0.1930 - acc: 0.9318 - val_loss: 0.6174 - val_acc: 0.8591\n",
      "Epoch 25/30\n",
      "601/601 [==============================] - 13s - loss: 0.1800 - acc: 0.9318 - val_loss: 0.5947 - val_acc: 0.8523\n",
      "Epoch 26/30\n",
      "601/601 [==============================] - 13s - loss: 0.1743 - acc: 0.9384 - val_loss: 0.6062 - val_acc: 0.8658\n",
      "Epoch 27/30\n",
      "601/601 [==============================] - 14s - loss: 0.1761 - acc: 0.9351 - val_loss: 0.5908 - val_acc: 0.8591\n",
      "Epoch 28/30\n",
      "601/601 [==============================] - 13s - loss: 0.1689 - acc: 0.9384 - val_loss: 0.5873 - val_acc: 0.8523\n",
      "Epoch 29/30\n",
      "601/601 [==============================] - 13s - loss: 0.1596 - acc: 0.9351 - val_loss: 0.6573 - val_acc: 0.8456\n",
      "Epoch 30/30\n",
      "601/601 [==============================] - 13s - loss: 0.1629 - acc: 0.9384 - val_loss: 0.5921 - val_acc: 0.8456\n",
      "5\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_29 (Conv2D)           (None, 128, 113, 16)      86528     \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 64, 111, 14)       73792     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 64, 55, 7)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 32, 53, 5)         18464     \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 32, 51, 3)         9248      \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 4896)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 2)                 9794      \n",
      "=================================================================\n",
      "Total params: 197,826\n",
      "Trainable params: 197,826\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 601 samples, validate on 149 samples\n",
      "Epoch 1/30\n",
      "601/601 [==============================] - 14s - loss: 0.6936 - acc: 0.5042 - val_loss: 0.6925 - val_acc: 0.5235\n",
      "Epoch 2/30\n",
      "601/601 [==============================] - 13s - loss: 0.6920 - acc: 0.5208 - val_loss: 0.6911 - val_acc: 0.5034\n",
      "Epoch 3/30\n",
      "601/601 [==============================] - 13s - loss: 0.6901 - acc: 0.5108 - val_loss: 0.6886 - val_acc: 0.5034\n",
      "Epoch 4/30\n",
      "601/601 [==============================] - 13s - loss: 0.6927 - acc: 0.5258 - val_loss: 0.6882 - val_acc: 0.5503\n",
      "Epoch 5/30\n",
      "601/601 [==============================] - 13s - loss: 0.6818 - acc: 0.5657 - val_loss: 0.6802 - val_acc: 0.5302\n",
      "Epoch 6/30\n",
      "601/601 [==============================] - 13s - loss: 0.6730 - acc: 0.5607 - val_loss: 0.6715 - val_acc: 0.5369\n",
      "Epoch 7/30\n",
      "601/601 [==============================] - 13s - loss: 0.6619 - acc: 0.5990 - val_loss: 0.6620 - val_acc: 0.5973\n",
      "Epoch 8/30\n",
      "601/601 [==============================] - 13s - loss: 0.6334 - acc: 0.6539 - val_loss: 0.6277 - val_acc: 0.6577\n",
      "Epoch 9/30\n",
      "601/601 [==============================] - 13s - loss: 0.5688 - acc: 0.7304 - val_loss: 0.5403 - val_acc: 0.7248\n",
      "Epoch 10/30\n",
      "601/601 [==============================] - 13s - loss: 0.4948 - acc: 0.7521 - val_loss: 0.4708 - val_acc: 0.7987\n",
      "Epoch 11/30\n",
      "601/601 [==============================] - 13s - loss: 0.4124 - acc: 0.8220 - val_loss: 0.4144 - val_acc: 0.8255\n",
      "Epoch 12/30\n",
      "601/601 [==============================] - 13s - loss: 0.4292 - acc: 0.7987 - val_loss: 0.3858 - val_acc: 0.8255\n",
      "Epoch 13/30\n",
      "601/601 [==============================] - 13s - loss: 0.3427 - acc: 0.8719 - val_loss: 0.3922 - val_acc: 0.8188\n",
      "Epoch 14/30\n",
      "601/601 [==============================] - 13s - loss: 0.3275 - acc: 0.8652 - val_loss: 0.3425 - val_acc: 0.8389\n",
      "Epoch 15/30\n",
      "601/601 [==============================] - 13s - loss: 0.3009 - acc: 0.8835 - val_loss: 0.3219 - val_acc: 0.8658\n",
      "Epoch 16/30\n",
      "601/601 [==============================] - 13s - loss: 0.2839 - acc: 0.8852 - val_loss: 0.3113 - val_acc: 0.8725\n",
      "Epoch 17/30\n",
      "601/601 [==============================] - 13s - loss: 0.2799 - acc: 0.8835 - val_loss: 0.3230 - val_acc: 0.8658\n",
      "Epoch 18/30\n",
      "601/601 [==============================] - 13s - loss: 0.2520 - acc: 0.8952 - val_loss: 0.3380 - val_acc: 0.8456\n",
      "Epoch 19/30\n",
      "601/601 [==============================] - 13s - loss: 0.2421 - acc: 0.9085 - val_loss: 0.3765 - val_acc: 0.8322\n",
      "Epoch 20/30\n",
      "601/601 [==============================] - 14s - loss: 0.2353 - acc: 0.9068 - val_loss: 0.3269 - val_acc: 0.8725\n",
      "Epoch 21/30\n",
      "601/601 [==============================] - 13s - loss: 0.2174 - acc: 0.9185 - val_loss: 0.2890 - val_acc: 0.8523\n",
      "Epoch 22/30\n",
      "601/601 [==============================] - 13s - loss: 0.2109 - acc: 0.9201 - val_loss: 0.3887 - val_acc: 0.8456\n",
      "Epoch 23/30\n",
      "601/601 [==============================] - 13s - loss: 0.2039 - acc: 0.9251 - val_loss: 0.2844 - val_acc: 0.8725\n",
      "Epoch 24/30\n",
      "601/601 [==============================] - 13s - loss: 0.1880 - acc: 0.9368 - val_loss: 0.2782 - val_acc: 0.8859\n",
      "Epoch 25/30\n",
      "601/601 [==============================] - 13s - loss: 0.1812 - acc: 0.9384 - val_loss: 0.2860 - val_acc: 0.8792\n",
      "Epoch 26/30\n",
      "601/601 [==============================] - 13s - loss: 0.1707 - acc: 0.9484 - val_loss: 0.3178 - val_acc: 0.8792\n",
      "Epoch 27/30\n",
      "601/601 [==============================] - 13s - loss: 0.1687 - acc: 0.9451 - val_loss: 0.3056 - val_acc: 0.8658\n",
      "Epoch 28/30\n",
      "601/601 [==============================] - 13s - loss: 0.1622 - acc: 0.9468 - val_loss: 0.3375 - val_acc: 0.8725\n",
      "Epoch 29/30\n",
      "601/601 [==============================] - 13s - loss: 0.1565 - acc: 0.9451 - val_loss: 0.3036 - val_acc: 0.8926\n",
      "Epoch 30/30\n",
      "601/601 [==============================] - 13s - loss: 0.1544 - acc: 0.9468 - val_loss: 0.3851 - val_acc: 0.8591\n",
      "Epoch 1/30\n",
      "601/601 [==============================] - 12s - loss: 0.1535 - acc: 0.9418    \n",
      "Epoch 2/30\n",
      "601/601 [==============================] - 12s - loss: 0.1387 - acc: 0.9534    \n",
      "Epoch 3/30\n",
      "601/601 [==============================] - 12s - loss: 0.1478 - acc: 0.9551    \n",
      "Epoch 4/30\n",
      "601/601 [==============================] - 12s - loss: 0.1319 - acc: 0.9601    \n",
      "Epoch 5/30\n",
      "601/601 [==============================] - 12s - loss: 0.1244 - acc: 0.9601    \n",
      "Epoch 6/30\n",
      "601/601 [==============================] - 11s - loss: 0.1256 - acc: 0.9634    \n",
      "Epoch 7/30\n",
      "601/601 [==============================] - 12s - loss: 0.1180 - acc: 0.9567    \n",
      "Epoch 8/30\n",
      "601/601 [==============================] - 12s - loss: 0.1094 - acc: 0.9617    \n",
      "Epoch 9/30\n",
      "601/601 [==============================] - 12s - loss: 0.1010 - acc: 0.9634    \n",
      "Epoch 10/30\n",
      "601/601 [==============================] - 12s - loss: 0.1035 - acc: 0.9667    \n",
      "Epoch 11/30\n",
      "601/601 [==============================] - 11s - loss: 0.0915 - acc: 0.9717    \n",
      "Epoch 12/30\n",
      "601/601 [==============================] - 12s - loss: 0.4279 - acc: 0.9085    \n",
      "Epoch 13/30\n",
      "601/601 [==============================] - 12s - loss: 0.0874 - acc: 0.9700    \n",
      "Epoch 14/30\n",
      "601/601 [==============================] - 12s - loss: 0.0860 - acc: 0.9700    \n",
      "Epoch 15/30\n",
      "601/601 [==============================] - 12s - loss: 0.0841 - acc: 0.9734    \n",
      "Epoch 16/30\n",
      "601/601 [==============================] - 11s - loss: 0.0841 - acc: 0.9734    \n",
      "Epoch 17/30\n",
      "601/601 [==============================] - 12s - loss: 0.0800 - acc: 0.9767    \n",
      "Epoch 18/30\n",
      "601/601 [==============================] - 12s - loss: 0.0769 - acc: 0.9784    \n",
      "Epoch 19/30\n",
      "601/601 [==============================] - 12s - loss: 0.0752 - acc: 0.9800    \n",
      "Epoch 20/30\n",
      "601/601 [==============================] - 12s - loss: 0.0734 - acc: 0.9767    \n",
      "Epoch 21/30\n",
      "601/601 [==============================] - 12s - loss: 0.0721 - acc: 0.9767    \n",
      "Epoch 22/30\n",
      "601/601 [==============================] - 12s - loss: 0.0701 - acc: 0.9784    \n",
      "Epoch 23/30\n",
      "601/601 [==============================] - 12s - loss: 0.0675 - acc: 0.9800    \n",
      "Epoch 24/30\n",
      "601/601 [==============================] - 12s - loss: 0.0648 - acc: 0.9817    \n",
      "Epoch 25/30\n",
      "601/601 [==============================] - 12s - loss: 0.0637 - acc: 0.9784    \n",
      "Epoch 26/30\n",
      "601/601 [==============================] - 12s - loss: 0.0695 - acc: 0.9767    \n",
      "Epoch 27/30\n",
      "601/601 [==============================] - 12s - loss: 0.0595 - acc: 0.9817    \n",
      "Epoch 28/30\n",
      "601/601 [==============================] - 12s - loss: 0.0565 - acc: 0.9867    \n",
      "Epoch 29/30\n",
      "601/601 [==============================] - 12s - loss: 0.0548 - acc: 0.9867    \n",
      "Epoch 30/30\n",
      "601/601 [==============================] - 12s - loss: 0.0528 - acc: 0.9867    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.92000000000000004"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cnn_model - new dataset + tensorflow (with data_format\" channel_first \") low energies\n",
    "# dropout removed\n",
    "num_classes = 2\n",
    "for i, (train_index, validation_index) in enumerate(skf.split(X_train, Y_train)):\n",
    "    print(i+1)\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", validation_index)\n",
    "    Xtrain, Xvalidation = X_train[train_index], X_train[validation_index]\n",
    "    ytrain, yvalidation = Y_train[train_index], Y_train[validation_index]\n",
    "    model = create_nn_model()\n",
    "    Ytrain = np_utils.to_categorical(ytrain)\n",
    "    Yvalidation = np_utils.to_categorical(yvalidation)\n",
    "    \n",
    "    history = model.fit(Xtrain, Ytrain, batch_size=64,\n",
    "                        epochs=30, verbose=1,\n",
    "                        validation_data = (Xvalidation, Yvalidation))\n",
    "    validation_acc = history.history['val_acc']\n",
    "    if validation_acc > best_validation_acc:\n",
    "        best_validation_acc = validation_acc\n",
    "        best_model = model\n",
    "Ytrain = np_utils.to_categorical(ytrain)\n",
    "best_model.fit(Xtrain, Ytrain, batch_size=64, epochs=30)  # replicate conf.\n",
    "\n",
    "predictions = best_model.predict(X_test)\n",
    "cls_predictions = np.argmax(predictions, axis=1)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(Y_test, cls_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 0.92000000000000004"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_41 (Conv2D)           (None, 128, 113, 16)      86528     \n",
      "_________________________________________________________________\n",
      "conv2d_42 (Conv2D)           (None, 64, 111, 14)       73792     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 64, 55, 7)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_43 (Conv2D)           (None, 32, 53, 5)         18464     \n",
      "_________________________________________________________________\n",
      "conv2d_44 (Conv2D)           (None, 32, 51, 3)         9248      \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 4896)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 2)                 9794      \n",
      "=================================================================\n",
      "Total params: 197,826\n",
      "Trainable params: 197,826\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 714 samples, validate on 179 samples\n",
      "Epoch 1/30\n",
      "714/714 [==============================] - 16s - loss: 0.6625 - acc: 0.6162 - val_loss: 0.6449 - val_acc: 0.6313\n",
      "Epoch 2/30\n",
      "714/714 [==============================] - 16s - loss: 0.6203 - acc: 0.6457 - val_loss: 0.5508 - val_acc: 0.6369\n",
      "Epoch 3/30\n",
      "714/714 [==============================] - 16s - loss: 0.5507 - acc: 0.7465 - val_loss: 0.5200 - val_acc: 0.6425\n",
      "Epoch 4/30\n",
      "714/714 [==============================] - 16s - loss: 0.4305 - acc: 0.8165 - val_loss: 0.2970 - val_acc: 0.9330\n",
      "Epoch 5/30\n",
      "714/714 [==============================] - 16s - loss: 0.3985 - acc: 0.8585 - val_loss: 0.2868 - val_acc: 0.9050\n",
      "Epoch 6/30\n",
      "714/714 [==============================] - 16s - loss: 0.3363 - acc: 0.8838 - val_loss: 0.2523 - val_acc: 0.8994\n",
      "Epoch 7/30\n",
      "714/714 [==============================] - 16s - loss: 0.2859 - acc: 0.8866 - val_loss: 0.2630 - val_acc: 0.8883\n",
      "Epoch 8/30\n",
      "714/714 [==============================] - 16s - loss: 0.2513 - acc: 0.9090 - val_loss: 0.2303 - val_acc: 0.9050\n",
      "Epoch 9/30\n",
      "714/714 [==============================] - 16s - loss: 0.2606 - acc: 0.9034 - val_loss: 0.1952 - val_acc: 0.9050\n",
      "Epoch 10/30\n",
      "714/714 [==============================] - 16s - loss: 0.2096 - acc: 0.9244 - val_loss: 0.2207 - val_acc: 0.9050\n",
      "Epoch 11/30\n",
      "714/714 [==============================] - 16s - loss: 0.2033 - acc: 0.9146 - val_loss: 0.4388 - val_acc: 0.8156\n",
      "Epoch 12/30\n",
      "714/714 [==============================] - 16s - loss: 0.2032 - acc: 0.9202 - val_loss: 0.2116 - val_acc: 0.9050\n",
      "Epoch 13/30\n",
      "714/714 [==============================] - 16s - loss: 0.1636 - acc: 0.9398 - val_loss: 0.2021 - val_acc: 0.9162\n",
      "Epoch 14/30\n",
      "714/714 [==============================] - 16s - loss: 0.1526 - acc: 0.9412 - val_loss: 0.1943 - val_acc: 0.9274\n",
      "Epoch 15/30\n",
      "714/714 [==============================] - 16s - loss: 0.1431 - acc: 0.9454 - val_loss: 0.1964 - val_acc: 0.9330\n",
      "Epoch 16/30\n",
      "714/714 [==============================] - 16s - loss: 0.1390 - acc: 0.9426 - val_loss: 0.2020 - val_acc: 0.9162\n",
      "Epoch 17/30\n",
      "714/714 [==============================] - 16s - loss: 0.1372 - acc: 0.9440 - val_loss: 0.2084 - val_acc: 0.9218\n",
      "Epoch 18/30\n",
      "714/714 [==============================] - 16s - loss: 0.1244 - acc: 0.9538 - val_loss: 0.2099 - val_acc: 0.9162\n",
      "Epoch 19/30\n",
      "714/714 [==============================] - 16s - loss: 0.1284 - acc: 0.9538 - val_loss: 0.2094 - val_acc: 0.9218\n",
      "Epoch 20/30\n",
      "714/714 [==============================] - 16s - loss: 0.1170 - acc: 0.9580 - val_loss: 0.2172 - val_acc: 0.9162\n",
      "Epoch 21/30\n",
      "714/714 [==============================] - 16s - loss: 0.1087 - acc: 0.9552 - val_loss: 0.2237 - val_acc: 0.9218\n",
      "Epoch 22/30\n",
      "714/714 [==============================] - 16s - loss: 0.1141 - acc: 0.9622 - val_loss: 0.2239 - val_acc: 0.9330\n",
      "Epoch 23/30\n",
      "714/714 [==============================] - 16s - loss: 0.1041 - acc: 0.9636 - val_loss: 0.2291 - val_acc: 0.9218\n",
      "Epoch 24/30\n",
      "714/714 [==============================] - 16s - loss: 0.0978 - acc: 0.9636 - val_loss: 0.2308 - val_acc: 0.9274\n",
      "Epoch 25/30\n",
      "714/714 [==============================] - 16s - loss: 0.0956 - acc: 0.9650 - val_loss: 0.2365 - val_acc: 0.9330\n",
      "Epoch 26/30\n",
      "714/714 [==============================] - 16s - loss: 0.1029 - acc: 0.9622 - val_loss: 0.2407 - val_acc: 0.9441\n",
      "Epoch 27/30\n",
      "714/714 [==============================] - 16s - loss: 0.0903 - acc: 0.9636 - val_loss: 0.2414 - val_acc: 0.9218\n",
      "Epoch 28/30\n",
      "714/714 [==============================] - 16s - loss: 0.0848 - acc: 0.9678 - val_loss: 0.2434 - val_acc: 0.9385\n",
      "Epoch 29/30\n",
      "714/714 [==============================] - 16s - loss: 0.0816 - acc: 0.9706 - val_loss: 0.2438 - val_acc: 0.9274\n",
      "Epoch 30/30\n",
      "714/714 [==============================] - 16s - loss: 0.0783 - acc: 0.9706 - val_loss: 0.2635 - val_acc: 0.9330\n",
      "2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_45 (Conv2D)           (None, 128, 113, 16)      86528     \n",
      "_________________________________________________________________\n",
      "conv2d_46 (Conv2D)           (None, 64, 111, 14)       73792     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 64, 55, 7)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_47 (Conv2D)           (None, 32, 53, 5)         18464     \n",
      "_________________________________________________________________\n",
      "conv2d_48 (Conv2D)           (None, 32, 51, 3)         9248      \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 4896)              0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 2)                 9794      \n",
      "=================================================================\n",
      "Total params: 197,826\n",
      "Trainable params: 197,826\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 714 samples, validate on 179 samples\n",
      "Epoch 1/30\n",
      "714/714 [==============================] - 16s - loss: 0.6689 - acc: 0.6317 - val_loss: 0.6835 - val_acc: 0.6313\n",
      "Epoch 2/30\n",
      "714/714 [==============================] - 16s - loss: 0.6239 - acc: 0.6331 - val_loss: 0.6727 - val_acc: 0.6313\n",
      "Epoch 3/30\n",
      "714/714 [==============================] - 16s - loss: 0.5757 - acc: 0.6373 - val_loss: 0.6267 - val_acc: 0.7709\n",
      "Epoch 4/30\n",
      "714/714 [==============================] - 16s - loss: 0.4570 - acc: 0.7815 - val_loss: 1.2523 - val_acc: 0.6480\n",
      "Epoch 5/30\n",
      "714/714 [==============================] - 16s - loss: 0.5266 - acc: 0.8459 - val_loss: 0.3996 - val_acc: 0.7430\n",
      "Epoch 6/30\n",
      "714/714 [==============================] - 16s - loss: 0.3346 - acc: 0.8768 - val_loss: 0.2969 - val_acc: 0.8939\n",
      "Epoch 7/30\n",
      "714/714 [==============================] - 16s - loss: 0.3054 - acc: 0.8992 - val_loss: 0.2814 - val_acc: 0.8994\n",
      "Epoch 8/30\n",
      "714/714 [==============================] - 16s - loss: 0.2740 - acc: 0.9006 - val_loss: 0.3519 - val_acc: 0.8771\n",
      "Epoch 9/30\n",
      "714/714 [==============================] - 16s - loss: 0.2455 - acc: 0.9048 - val_loss: 0.3396 - val_acc: 0.8994\n",
      "Epoch 10/30\n",
      "714/714 [==============================] - 16s - loss: 0.2496 - acc: 0.8852 - val_loss: 0.3802 - val_acc: 0.8883\n",
      "Epoch 11/30\n",
      "714/714 [==============================] - 16s - loss: 0.2097 - acc: 0.9104 - val_loss: 0.4526 - val_acc: 0.7542\n",
      "Epoch 12/30\n",
      "714/714 [==============================] - 16s - loss: 0.2185 - acc: 0.9034 - val_loss: 0.2725 - val_acc: 0.9162\n",
      "Epoch 13/30\n",
      "714/714 [==============================] - 16s - loss: 0.2023 - acc: 0.9202 - val_loss: 0.2136 - val_acc: 0.8994\n",
      "Epoch 14/30\n",
      "714/714 [==============================] - 16s - loss: 0.1697 - acc: 0.9356 - val_loss: 0.2464 - val_acc: 0.8994\n",
      "Epoch 15/30\n",
      "714/714 [==============================] - 16s - loss: 0.1605 - acc: 0.9342 - val_loss: 0.2403 - val_acc: 0.9050\n",
      "Epoch 16/30\n",
      "714/714 [==============================] - 16s - loss: 0.1536 - acc: 0.9468 - val_loss: 0.2958 - val_acc: 0.8994\n",
      "Epoch 17/30\n",
      "714/714 [==============================] - 16s - loss: 0.1464 - acc: 0.9426 - val_loss: 0.2397 - val_acc: 0.9106\n",
      "Epoch 18/30\n",
      "714/714 [==============================] - 16s - loss: 0.1402 - acc: 0.9454 - val_loss: 0.3275 - val_acc: 0.8939\n",
      "Epoch 19/30\n",
      "714/714 [==============================] - 16s - loss: 0.1480 - acc: 0.9412 - val_loss: 0.2776 - val_acc: 0.8994\n",
      "Epoch 20/30\n",
      "714/714 [==============================] - 16s - loss: 0.1368 - acc: 0.9468 - val_loss: 0.2692 - val_acc: 0.9106\n",
      "Epoch 21/30\n",
      "714/714 [==============================] - 16s - loss: 0.1231 - acc: 0.9566 - val_loss: 0.2604 - val_acc: 0.9218\n",
      "Epoch 22/30\n",
      "714/714 [==============================] - 16s - loss: 0.1142 - acc: 0.9538 - val_loss: 0.2642 - val_acc: 0.9162\n",
      "Epoch 23/30\n",
      "714/714 [==============================] - 16s - loss: 0.1152 - acc: 0.9538 - val_loss: 0.2798 - val_acc: 0.9106\n",
      "Epoch 24/30\n",
      "714/714 [==============================] - 16s - loss: 0.1143 - acc: 0.9524 - val_loss: 0.2916 - val_acc: 0.9106\n",
      "Epoch 25/30\n",
      "714/714 [==============================] - 16s - loss: 0.1020 - acc: 0.9608 - val_loss: 0.2660 - val_acc: 0.9106\n",
      "Epoch 26/30\n",
      "714/714 [==============================] - 16s - loss: 0.0942 - acc: 0.9636 - val_loss: 0.2618 - val_acc: 0.9218\n",
      "Epoch 27/30\n",
      "714/714 [==============================] - 16s - loss: 0.0879 - acc: 0.9650 - val_loss: 0.3132 - val_acc: 0.9050\n",
      "Epoch 28/30\n",
      "714/714 [==============================] - 16s - loss: 0.0881 - acc: 0.9650 - val_loss: 0.3722 - val_acc: 0.8436\n",
      "Epoch 29/30\n",
      "714/714 [==============================] - 16s - loss: 0.0950 - acc: 0.9538 - val_loss: 0.3203 - val_acc: 0.8994\n",
      "Epoch 30/30\n",
      "714/714 [==============================] - 16s - loss: 0.0756 - acc: 0.9720 - val_loss: 0.4471 - val_acc: 0.8939\n",
      "3\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_49 (Conv2D)           (None, 128, 113, 16)      86528     \n",
      "_________________________________________________________________\n",
      "conv2d_50 (Conv2D)           (None, 64, 111, 14)       73792     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 64, 55, 7)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_51 (Conv2D)           (None, 32, 53, 5)         18464     \n",
      "_________________________________________________________________\n",
      "conv2d_52 (Conv2D)           (None, 32, 51, 3)         9248      \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 4896)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 2)                 9794      \n",
      "=================================================================\n",
      "Total params: 197,826\n",
      "Trainable params: 197,826\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 714 samples, validate on 179 samples\n",
      "Epoch 1/30\n",
      "714/714 [==============================] - 16s - loss: 0.6754 - acc: 0.6204 - val_loss: 0.6679 - val_acc: 0.6313\n",
      "Epoch 2/30\n",
      "714/714 [==============================] - 16s - loss: 0.6285 - acc: 0.6331 - val_loss: 0.8816 - val_acc: 0.6313\n",
      "Epoch 3/30\n",
      "714/714 [==============================] - 16s - loss: 0.5919 - acc: 0.6331 - val_loss: 0.7308 - val_acc: 0.6313\n",
      "Epoch 4/30\n",
      "714/714 [==============================] - 16s - loss: 0.4730 - acc: 0.7367 - val_loss: 0.6633 - val_acc: 0.6536\n",
      "Epoch 5/30\n",
      "714/714 [==============================] - 16s - loss: 0.4022 - acc: 0.8529 - val_loss: 0.5165 - val_acc: 0.8883\n",
      "Epoch 6/30\n",
      "714/714 [==============================] - 16s - loss: 0.3294 - acc: 0.8782 - val_loss: 0.3948 - val_acc: 0.8883\n",
      "Epoch 7/30\n",
      "714/714 [==============================] - 16s - loss: 0.2862 - acc: 0.9006 - val_loss: 0.3211 - val_acc: 0.8436\n",
      "Epoch 8/30\n",
      "714/714 [==============================] - 16s - loss: 0.3305 - acc: 0.8782 - val_loss: 0.4777 - val_acc: 0.8883\n",
      "Epoch 9/30\n",
      "714/714 [==============================] - 16s - loss: 0.2415 - acc: 0.9174 - val_loss: 0.3341 - val_acc: 0.8827\n",
      "Epoch 10/30\n",
      "714/714 [==============================] - 16s - loss: 0.2163 - acc: 0.9076 - val_loss: 0.4265 - val_acc: 0.8827\n",
      "Epoch 11/30\n",
      "714/714 [==============================] - 16s - loss: 0.2065 - acc: 0.9202 - val_loss: 0.2540 - val_acc: 0.8994\n",
      "Epoch 12/30\n",
      "714/714 [==============================] - 16s - loss: 0.1917 - acc: 0.9188 - val_loss: 0.7650 - val_acc: 0.7207\n",
      "Epoch 13/30\n",
      "714/714 [==============================] - 16s - loss: 0.2000 - acc: 0.9160 - val_loss: 0.2278 - val_acc: 0.9106\n",
      "Epoch 14/30\n",
      "714/714 [==============================] - 16s - loss: 0.1745 - acc: 0.9356 - val_loss: 0.2081 - val_acc: 0.9162\n",
      "Epoch 15/30\n",
      "714/714 [==============================] - 16s - loss: 0.1583 - acc: 0.9426 - val_loss: 0.2592 - val_acc: 0.9106\n",
      "Epoch 16/30\n",
      "714/714 [==============================] - 16s - loss: 0.1517 - acc: 0.9412 - val_loss: 0.2120 - val_acc: 0.9106\n",
      "Epoch 17/30\n",
      "714/714 [==============================] - 16s - loss: 0.1376 - acc: 0.9496 - val_loss: 0.2170 - val_acc: 0.9162\n",
      "Epoch 18/30\n",
      "714/714 [==============================] - 16s - loss: 0.1444 - acc: 0.9412 - val_loss: 0.2085 - val_acc: 0.9162\n",
      "Epoch 19/30\n",
      "714/714 [==============================] - 16s - loss: 0.1258 - acc: 0.9496 - val_loss: 0.2175 - val_acc: 0.9106\n",
      "Epoch 20/30\n",
      "714/714 [==============================] - 16s - loss: 0.1228 - acc: 0.9552 - val_loss: 0.2170 - val_acc: 0.9218\n",
      "Epoch 21/30\n",
      "714/714 [==============================] - 16s - loss: 0.1166 - acc: 0.9538 - val_loss: 0.2185 - val_acc: 0.9218\n",
      "Epoch 22/30\n",
      "714/714 [==============================] - 16s - loss: 0.1138 - acc: 0.9524 - val_loss: 0.2323 - val_acc: 0.9274\n",
      "Epoch 23/30\n",
      "714/714 [==============================] - 16s - loss: 0.1039 - acc: 0.9650 - val_loss: 0.2139 - val_acc: 0.9274\n",
      "Epoch 24/30\n",
      "714/714 [==============================] - 16s - loss: 0.1007 - acc: 0.9678 - val_loss: 0.2160 - val_acc: 0.9274\n",
      "Epoch 25/30\n",
      "714/714 [==============================] - 16s - loss: 0.0977 - acc: 0.9664 - val_loss: 0.2488 - val_acc: 0.9330\n",
      "Epoch 26/30\n",
      "714/714 [==============================] - 16s - loss: 0.1007 - acc: 0.9650 - val_loss: 0.2266 - val_acc: 0.9218\n",
      "Epoch 27/30\n",
      "714/714 [==============================] - 16s - loss: 0.0881 - acc: 0.9720 - val_loss: 0.2298 - val_acc: 0.9162\n",
      "Epoch 28/30\n",
      "714/714 [==============================] - 16s - loss: 0.0892 - acc: 0.9706 - val_loss: 0.3040 - val_acc: 0.9106\n",
      "Epoch 29/30\n",
      "714/714 [==============================] - 16s - loss: 0.0830 - acc: 0.9720 - val_loss: 0.2378 - val_acc: 0.9274\n",
      "Epoch 30/30\n",
      "714/714 [==============================] - 16s - loss: 0.0799 - acc: 0.9748 - val_loss: 0.2328 - val_acc: 0.9274\n",
      "4\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_53 (Conv2D)           (None, 128, 113, 16)      86528     \n",
      "_________________________________________________________________\n",
      "conv2d_54 (Conv2D)           (None, 64, 111, 14)       73792     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 64, 55, 7)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_55 (Conv2D)           (None, 32, 53, 5)         18464     \n",
      "_________________________________________________________________\n",
      "conv2d_56 (Conv2D)           (None, 32, 51, 3)         9248      \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 4896)              0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 2)                 9794      \n",
      "=================================================================\n",
      "Total params: 197,826\n",
      "Trainable params: 197,826\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 715 samples, validate on 178 samples\n",
      "Epoch 1/30\n",
      "715/715 [==============================] - 16s - loss: 0.6678 - acc: 0.6028 - val_loss: 0.6864 - val_acc: 0.6348\n",
      "Epoch 2/30\n",
      "715/715 [==============================] - 16s - loss: 0.6239 - acc: 0.6322 - val_loss: 0.5948 - val_acc: 0.6348\n",
      "Epoch 3/30\n",
      "715/715 [==============================] - 16s - loss: 0.5302 - acc: 0.6587 - val_loss: 0.5158 - val_acc: 0.8427\n",
      "Epoch 4/30\n",
      "715/715 [==============================] - 16s - loss: 0.3728 - acc: 0.8531 - val_loss: 0.4675 - val_acc: 0.8708\n",
      "Epoch 5/30\n",
      "715/715 [==============================] - 16s - loss: 0.4504 - acc: 0.8350 - val_loss: 0.4447 - val_acc: 0.8315\n",
      "Epoch 6/30\n",
      "715/715 [==============================] - 16s - loss: 0.2826 - acc: 0.8825 - val_loss: 0.4678 - val_acc: 0.8708\n",
      "Epoch 7/30\n",
      "715/715 [==============================] - 16s - loss: 0.2777 - acc: 0.8867 - val_loss: 0.4271 - val_acc: 0.9101\n",
      "Epoch 8/30\n",
      "715/715 [==============================] - 16s - loss: 0.2306 - acc: 0.9049 - val_loss: 0.4244 - val_acc: 0.9045\n",
      "Epoch 9/30\n",
      "715/715 [==============================] - 16s - loss: 0.2108 - acc: 0.9231 - val_loss: 0.4371 - val_acc: 0.9157\n",
      "Epoch 10/30\n",
      "715/715 [==============================] - 16s - loss: 0.1841 - acc: 0.9203 - val_loss: 0.4453 - val_acc: 0.8989\n",
      "Epoch 11/30\n",
      "715/715 [==============================] - 16s - loss: 0.1844 - acc: 0.9161 - val_loss: 0.4449 - val_acc: 0.8989\n",
      "Epoch 12/30\n",
      "715/715 [==============================] - 16s - loss: 0.1716 - acc: 0.9315 - val_loss: 0.4265 - val_acc: 0.9157\n",
      "Epoch 13/30\n",
      "715/715 [==============================] - 16s - loss: 0.1735 - acc: 0.9301 - val_loss: 0.4117 - val_acc: 0.9213\n",
      "Epoch 14/30\n",
      "715/715 [==============================] - 16s - loss: 0.1535 - acc: 0.9343 - val_loss: 0.4198 - val_acc: 0.9213\n",
      "Epoch 15/30\n",
      "715/715 [==============================] - 16s - loss: 0.1475 - acc: 0.9385 - val_loss: 0.4517 - val_acc: 0.9045\n",
      "Epoch 16/30\n",
      "715/715 [==============================] - 16s - loss: 0.1403 - acc: 0.9441 - val_loss: 0.3976 - val_acc: 0.9213\n",
      "Epoch 17/30\n",
      "715/715 [==============================] - 16s - loss: 0.1313 - acc: 0.9413 - val_loss: 0.4253 - val_acc: 0.9270\n",
      "Epoch 18/30\n",
      "715/715 [==============================] - 16s - loss: 0.1277 - acc: 0.9427 - val_loss: 0.4233 - val_acc: 0.9270\n",
      "Epoch 19/30\n",
      "715/715 [==============================] - 16s - loss: 0.1323 - acc: 0.9483 - val_loss: 0.4277 - val_acc: 0.9270\n",
      "Epoch 20/30\n",
      "715/715 [==============================] - 16s - loss: 0.1152 - acc: 0.9538 - val_loss: 0.4348 - val_acc: 0.9270\n",
      "Epoch 21/30\n",
      "715/715 [==============================] - 16s - loss: 0.1105 - acc: 0.9594 - val_loss: 0.4674 - val_acc: 0.9213\n",
      "Epoch 22/30\n",
      "715/715 [==============================] - 16s - loss: 0.1065 - acc: 0.9608 - val_loss: 0.4218 - val_acc: 0.9326\n",
      "Epoch 23/30\n",
      "715/715 [==============================] - 16s - loss: 0.1039 - acc: 0.9580 - val_loss: 0.4772 - val_acc: 0.9045\n",
      "Epoch 24/30\n",
      "715/715 [==============================] - 16s - loss: 0.0983 - acc: 0.9580 - val_loss: 0.4281 - val_acc: 0.9326\n",
      "Epoch 25/30\n",
      "715/715 [==============================] - 16s - loss: 0.0980 - acc: 0.9622 - val_loss: 0.4891 - val_acc: 0.9045\n",
      "Epoch 26/30\n",
      "715/715 [==============================] - 16s - loss: 0.0921 - acc: 0.9608 - val_loss: 0.3945 - val_acc: 0.9270\n",
      "Epoch 27/30\n",
      "715/715 [==============================] - 16s - loss: 0.0878 - acc: 0.9636 - val_loss: 0.4747 - val_acc: 0.9101\n",
      "Epoch 28/30\n",
      "715/715 [==============================] - 16s - loss: 0.0837 - acc: 0.9664 - val_loss: 0.3770 - val_acc: 0.9326\n",
      "Epoch 29/30\n",
      "715/715 [==============================] - 16s - loss: 0.0787 - acc: 0.9664 - val_loss: 0.4272 - val_acc: 0.9270\n",
      "Epoch 30/30\n",
      "715/715 [==============================] - 16s - loss: 0.0738 - acc: 0.9706 - val_loss: 0.5135 - val_acc: 0.9101\n",
      "5\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_57 (Conv2D)           (None, 128, 113, 16)      86528     \n",
      "_________________________________________________________________\n",
      "conv2d_58 (Conv2D)           (None, 64, 111, 14)       73792     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 64, 55, 7)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_59 (Conv2D)           (None, 32, 53, 5)         18464     \n",
      "_________________________________________________________________\n",
      "conv2d_60 (Conv2D)           (None, 32, 51, 3)         9248      \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 4896)              0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 2)                 9794      \n",
      "=================================================================\n",
      "Total params: 197,826\n",
      "Trainable params: 197,826\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 715 samples, validate on 178 samples\n",
      "Epoch 1/30\n",
      "715/715 [==============================] - 16s - loss: 0.6615 - acc: 0.6252 - val_loss: 0.6477 - val_acc: 0.6348\n",
      "Epoch 2/30\n",
      "715/715 [==============================] - 16s - loss: 0.6286 - acc: 0.6322 - val_loss: 0.6511 - val_acc: 0.6348\n",
      "Epoch 3/30\n",
      "715/715 [==============================] - 16s - loss: 0.5606 - acc: 0.6713 - val_loss: 0.4686 - val_acc: 0.6966\n",
      "Epoch 4/30\n",
      "715/715 [==============================] - 16s - loss: 0.4573 - acc: 0.7944 - val_loss: 0.3979 - val_acc: 0.9101\n",
      "Epoch 5/30\n",
      "715/715 [==============================] - 16s - loss: 0.3286 - acc: 0.8657 - val_loss: 0.4460 - val_acc: 0.7753\n",
      "Epoch 6/30\n",
      "715/715 [==============================] - 16s - loss: 0.2806 - acc: 0.8769 - val_loss: 0.3767 - val_acc: 0.9157\n",
      "Epoch 7/30\n",
      "715/715 [==============================] - 16s - loss: 0.2278 - acc: 0.9133 - val_loss: 0.3640 - val_acc: 0.9045\n",
      "Epoch 8/30\n",
      "715/715 [==============================] - 16s - loss: 0.2478 - acc: 0.9077 - val_loss: 0.3453 - val_acc: 0.9101\n",
      "Epoch 9/30\n",
      "715/715 [==============================] - 16s - loss: 0.2066 - acc: 0.9231 - val_loss: 0.3415 - val_acc: 0.9101\n",
      "Epoch 10/30\n",
      "715/715 [==============================] - 16s - loss: 0.1849 - acc: 0.9259 - val_loss: 0.3359 - val_acc: 0.9101\n",
      "Epoch 11/30\n",
      "715/715 [==============================] - 16s - loss: 0.1814 - acc: 0.9273 - val_loss: 0.3362 - val_acc: 0.9045\n",
      "Epoch 12/30\n",
      "715/715 [==============================] - 16s - loss: 0.1470 - acc: 0.9441 - val_loss: 0.3201 - val_acc: 0.8989\n",
      "Epoch 13/30\n",
      "715/715 [==============================] - 16s - loss: 0.1531 - acc: 0.9413 - val_loss: 0.3279 - val_acc: 0.9213\n",
      "Epoch 14/30\n",
      "715/715 [==============================] - 16s - loss: 0.1346 - acc: 0.9441 - val_loss: 0.3312 - val_acc: 0.9213\n",
      "Epoch 15/30\n",
      "715/715 [==============================] - 16s - loss: 0.1324 - acc: 0.9441 - val_loss: 0.3308 - val_acc: 0.9213\n",
      "Epoch 16/30\n",
      "715/715 [==============================] - 16s - loss: 0.1451 - acc: 0.9385 - val_loss: 0.3630 - val_acc: 0.9213\n",
      "Epoch 17/30\n",
      "715/715 [==============================] - 16s - loss: 0.1227 - acc: 0.9510 - val_loss: 0.3510 - val_acc: 0.8989\n",
      "Epoch 18/30\n",
      "715/715 [==============================] - 16s - loss: 0.1142 - acc: 0.9552 - val_loss: 0.3619 - val_acc: 0.9270\n",
      "Epoch 19/30\n",
      "715/715 [==============================] - 16s - loss: 0.1087 - acc: 0.9538 - val_loss: 0.3594 - val_acc: 0.9101\n",
      "Epoch 20/30\n",
      "715/715 [==============================] - 16s - loss: 0.1067 - acc: 0.9524 - val_loss: 0.3606 - val_acc: 0.9101\n",
      "Epoch 21/30\n",
      "715/715 [==============================] - 16s - loss: 0.1100 - acc: 0.9552 - val_loss: 0.3622 - val_acc: 0.9101\n",
      "Epoch 22/30\n",
      "715/715 [==============================] - 16s - loss: 0.0983 - acc: 0.9552 - val_loss: 0.3623 - val_acc: 0.9101\n",
      "Epoch 23/30\n",
      "715/715 [==============================] - 16s - loss: 0.0951 - acc: 0.9608 - val_loss: 0.3706 - val_acc: 0.9045\n",
      "Epoch 24/30\n",
      "715/715 [==============================] - 16s - loss: 0.0883 - acc: 0.9650 - val_loss: 0.3765 - val_acc: 0.9157\n",
      "Epoch 25/30\n",
      "715/715 [==============================] - 16s - loss: 0.0976 - acc: 0.9580 - val_loss: 0.3786 - val_acc: 0.9157\n",
      "Epoch 26/30\n",
      "715/715 [==============================] - 16s - loss: 0.0837 - acc: 0.9636 - val_loss: 0.5448 - val_acc: 0.8820\n",
      "Epoch 27/30\n",
      "715/715 [==============================] - 16s - loss: 0.0871 - acc: 0.9594 - val_loss: 0.3944 - val_acc: 0.9101\n",
      "Epoch 28/30\n",
      "715/715 [==============================] - 16s - loss: 0.0758 - acc: 0.9678 - val_loss: 0.4005 - val_acc: 0.9101\n",
      "Epoch 29/30\n",
      "715/715 [==============================] - 16s - loss: 0.0757 - acc: 0.9706 - val_loss: 0.4179 - val_acc: 0.9157\n",
      "Epoch 30/30\n",
      "715/715 [==============================] - 16s - loss: 0.0712 - acc: 0.9706 - val_loss: 0.4230 - val_acc: 0.9157\n",
      "Epoch 1/30\n",
      "715/715 [==============================] - 14s - loss: 0.0692 - acc: 0.9720    \n",
      "Epoch 2/30\n",
      "715/715 [==============================] - 14s - loss: 0.0626 - acc: 0.9748    \n",
      "Epoch 3/30\n",
      "715/715 [==============================] - 14s - loss: 0.0654 - acc: 0.9804    \n",
      "Epoch 4/30\n",
      "715/715 [==============================] - 14s - loss: 0.0667 - acc: 0.9692    \n",
      "Epoch 5/30\n",
      "715/715 [==============================] - 14s - loss: 0.0593 - acc: 0.9734    \n",
      "Epoch 6/30\n",
      "715/715 [==============================] - 14s - loss: 0.0564 - acc: 0.9790    \n",
      "Epoch 7/30\n",
      "715/715 [==============================] - 14s - loss: 0.0529 - acc: 0.9818    \n",
      "Epoch 8/30\n",
      "715/715 [==============================] - 14s - loss: 0.0489 - acc: 0.9832    \n",
      "Epoch 9/30\n",
      "715/715 [==============================] - 14s - loss: 0.0552 - acc: 0.9762    \n",
      "Epoch 10/30\n",
      "715/715 [==============================] - 14s - loss: 0.0442 - acc: 0.9832    \n",
      "Epoch 11/30\n",
      "715/715 [==============================] - 14s - loss: 0.0438 - acc: 0.9818    \n",
      "Epoch 12/30\n",
      "715/715 [==============================] - 14s - loss: 0.0394 - acc: 0.9874    \n",
      "Epoch 13/30\n",
      "715/715 [==============================] - 14s - loss: 0.0403 - acc: 0.9860    \n",
      "Epoch 14/30\n",
      "715/715 [==============================] - 14s - loss: 0.0546 - acc: 0.9776    \n",
      "Epoch 15/30\n",
      "715/715 [==============================] - 14s - loss: 0.0363 - acc: 0.9888    \n",
      "Epoch 16/30\n",
      "715/715 [==============================] - 14s - loss: 0.0347 - acc: 0.9916    \n",
      "Epoch 17/30\n",
      "715/715 [==============================] - 14s - loss: 0.0332 - acc: 0.9930    \n",
      "Epoch 18/30\n",
      "715/715 [==============================] - 14s - loss: 0.0320 - acc: 0.9944    \n",
      "Epoch 19/30\n",
      "715/715 [==============================] - 14s - loss: 0.0318 - acc: 0.9916    \n",
      "Epoch 20/30\n",
      "715/715 [==============================] - 14s - loss: 0.0301 - acc: 0.9916    \n",
      "Epoch 21/30\n",
      "715/715 [==============================] - 14s - loss: 0.0296 - acc: 0.9944    \n",
      "Epoch 22/30\n",
      "715/715 [==============================] - 14s - loss: 0.0287 - acc: 0.9944    \n",
      "Epoch 23/30\n",
      "715/715 [==============================] - 14s - loss: 0.0292 - acc: 0.9888    \n",
      "Epoch 24/30\n",
      "715/715 [==============================] - 14s - loss: 0.0259 - acc: 0.9930    \n",
      "Epoch 25/30\n",
      "715/715 [==============================] - 14s - loss: 0.0237 - acc: 0.9958    \n",
      "Epoch 26/30\n",
      "715/715 [==============================] - 14s - loss: 0.0222 - acc: 0.9958    \n",
      "Epoch 27/30\n",
      "715/715 [==============================] - 14s - loss: 0.0225 - acc: 0.9944    \n",
      "Epoch 28/30\n",
      "715/715 [==============================] - 14s - loss: 0.0212 - acc: 0.9958    \n",
      "Epoch 29/30\n",
      "715/715 [==============================] - 14s - loss: 0.0199 - acc: 0.9944    \n",
      "Epoch 30/30\n",
      "715/715 [==============================] - 14s - loss: 0.0183 - acc: 0.9958    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.90625"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cnn_model - new dataset + tensorflow (with data_format\" channel_first \") hiigh energies\n",
    "# dropout removed\n",
    "best_validation_acc = 0.0\n",
    "best_model = None\n",
    "\n",
    "num_classes = 2\n",
    "for i, (train_index, validation_index) in enumerate(skf.split(X_train, Y_train)):\n",
    "    print(i+1)\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", validation_index)\n",
    "    Xtrain, Xvalidation = X_train[train_index], X_train[validation_index]\n",
    "    ytrain, yvalidation = Y_train[train_index], Y_train[validation_index]\n",
    "    model = create_nn_model()\n",
    "    Ytrain = np_utils.to_categorical(ytrain)\n",
    "    Yvalidation = np_utils.to_categorical(yvalidation)\n",
    "    \n",
    "    history = model.fit(Xtrain, Ytrain, batch_size=64,\n",
    "                        epochs=30, verbose=1,\n",
    "                        validation_data = (Xvalidation, Yvalidation))\n",
    "    validation_acc = history.history['val_acc']\n",
    "    if validation_acc > best_validation_acc:\n",
    "        best_validation_acc = validation_acc\n",
    "        best_model = model\n",
    "Ytrain = np_utils.to_categorical(ytrain)\n",
    "best_model.fit(Xtrain, Ytrain, batch_size=64, epochs=30)  # replicate conf.\n",
    "\n",
    "predictions = best_model.predict(X_test)\n",
    "cls_predictions = np.argmax(predictions, axis=1)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(Y_test, cls_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "E_test_h = E_high[indx2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "E_t_h_min = np.min(E_test_h[0])\n",
    "E_t_h_max = np.max(E_test_h[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "203"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E_high[indx2][np.floor(Y_test)==cls_predictions].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E_high[indx2][np.floor(Y_test)!=cls_predictions].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  9.59698000e+05,   7.24280000e+05,   8.35125000e+03,\n",
       "         2.24419000e+03,   3.95065000e+02,   6.02405000e+01,\n",
       "         1.00514000e+01,   5.90483000e+00,   1.67079000e+04,\n",
       "         2.96511000e+03,   1.71819000e+03,   2.77071000e+03,\n",
       "         4.41594000e+03,   1.47335000e+03,   1.15395000e+03,\n",
       "         3.56528000e+02,   4.06618000e+02,   2.19632000e+02,\n",
       "         3.16779000e+02,   4.15252000e+01,   1.04532000e+02,\n",
       "         4.14364000e+02,   1.86372000e+00,   2.90795000e-01,\n",
       "         5.50684000e-01,   4.65552000e-02,   1.22373000e+00,\n",
       "         4.49609000e-01,   1.48968000e+00,   4.03814000e+04,\n",
       "         1.44639000e+05,   2.89514000e+03,   4.81284000e+02,\n",
       "         6.43982000e+02,   5.61965000e+02,   6.85230000e+02,\n",
       "         3.50410000e+02,   1.41388000e+01,   2.00065000e+01,\n",
       "         2.45178000e+02,   1.73668000e+02,   4.18585000e+01,\n",
       "         1.47774000e+02,   7.24280000e+05,   7.78952000e+03,\n",
       "         2.05613000e+03,   3.27080000e+02,   4.73365000e+01,\n",
       "         7.01976000e+00,   3.73900000e+00,   1.56948000e+04,\n",
       "         2.72844000e+03,   1.56680000e+03,   2.54721000e+03,\n",
       "         4.08685000e+03,   1.33927000e+03,   1.04394000e+03,\n",
       "         3.11773000e+02,   3.57261000e+02,   1.88512000e+02,\n",
       "         2.76087000e+02,   3.14786000e+01,   8.61271000e+01,\n",
       "         3.64306000e+02,   1.78207000e-01,   8.27973000e-02,\n",
       "         5.50684000e-01,   4.65552000e-02,   8.15538000e-01,\n",
       "         4.49609000e-01,   1.48968000e+00,   3.79168000e+04,\n",
       "         1.38059000e+05,   2.89514000e+03,   4.81284000e+02,\n",
       "         6.43982000e+02,   5.61965000e+02,   6.85230000e+02,\n",
       "         3.50410000e+02,   1.41388000e+01,   2.00065000e+01,\n",
       "         2.45178000e+02,   1.73668000e+02,   4.18585000e+01,\n",
       "         1.47774000e+02])"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E_test_h[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-192-fe6353b63243>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mE_w_h_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mE_high\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindx2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mcls_predictions\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mE_t_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mE_t_max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mE_b__h_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mE_high\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindx2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0mcls_predictions\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mE_t_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mE_t_max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/numpy/lib/function_base.pyc\u001b[0m in \u001b[0;36mhistogram\u001b[0;34m(a, bins, range, normed, weights, density)\u001b[0m\n\u001b[1;32m    746\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m             \u001b[0;31m# Only include values in the right range\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 748\u001b[0;31m             \u001b[0mkeep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtmp_a\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mmn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    749\u001b[0m             \u001b[0mkeep\u001b[0m \u001b[0;34m&=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtmp_a\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mmx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogical_and\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "E_w_h_cls = np.histogram(E_high[indx2][np.floor(Y_test)==cls_predictions], bins=1000, range = (E_t_min, E_t_max))\n",
    "\n",
    "E_b__h_cls = np.histogram(E_high[indx2][np.floor(Y_test)!=cls_predictions], bins=1000, range = (E_t_min, E_t_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_13 (Conv2D)           (None, 128, 113, 16)      86528     \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 64, 111, 14)       73792     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 64, 55, 7)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 32, 53, 5)         18464     \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 32, 51, 3)         9248      \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 4896)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2)                 9794      \n",
      "=================================================================\n",
      "Total params: 197,826\n",
      "Trainable params: 197,826\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1742 samples, validate on 437 samples\n",
      "Epoch 1/20\n",
      "1742/1742 [==============================] - 39s - loss: 0.6818 - acc: 0.5608 - val_loss: 0.6654 - val_acc: 0.5652\n",
      "Epoch 2/20\n",
      "1742/1742 [==============================] - 39s - loss: 0.6048 - acc: 0.6366 - val_loss: 0.5966 - val_acc: 0.6018\n",
      "Epoch 3/20\n",
      "1742/1742 [==============================] - 39s - loss: 0.4221 - acc: 0.8266 - val_loss: 0.4683 - val_acc: 0.7803\n",
      "Epoch 4/20\n",
      "1742/1742 [==============================] - 39s - loss: 0.3902 - acc: 0.8530 - val_loss: 0.3114 - val_acc: 0.8810\n",
      "Epoch 5/20\n",
      "1742/1742 [==============================] - 39s - loss: 0.3262 - acc: 0.8737 - val_loss: 0.2954 - val_acc: 0.9016\n",
      "Epoch 6/20\n",
      "1742/1742 [==============================] - 39s - loss: 0.2675 - acc: 0.9041 - val_loss: 0.2868 - val_acc: 0.8993\n",
      "Epoch 7/20\n",
      "1742/1742 [==============================] - 39s - loss: 0.2520 - acc: 0.9104 - val_loss: 0.3128 - val_acc: 0.8924\n",
      "Epoch 8/20\n",
      "1742/1742 [==============================] - 39s - loss: 0.2305 - acc: 0.9156 - val_loss: 0.2697 - val_acc: 0.9062\n",
      "Epoch 9/20\n",
      "1742/1742 [==============================] - 39s - loss: 0.2105 - acc: 0.9191 - val_loss: 0.2668 - val_acc: 0.9153\n",
      "Epoch 10/20\n",
      "1742/1742 [==============================] - 39s - loss: 0.2016 - acc: 0.9219 - val_loss: 0.2599 - val_acc: 0.9153\n",
      "Epoch 11/20\n",
      "1742/1742 [==============================] - 39s - loss: 0.1888 - acc: 0.9282 - val_loss: 0.2652 - val_acc: 0.8993\n",
      "Epoch 12/20\n",
      "1742/1742 [==============================] - 39s - loss: 0.1797 - acc: 0.9294 - val_loss: 1.0478 - val_acc: 0.6316\n",
      "Epoch 13/20\n",
      "1742/1742 [==============================] - 39s - loss: 0.1983 - acc: 0.9282 - val_loss: 0.2520 - val_acc: 0.9085\n",
      "Epoch 14/20\n",
      "1742/1742 [==============================] - 39s - loss: 0.1644 - acc: 0.9369 - val_loss: 0.2790 - val_acc: 0.9062\n",
      "Epoch 15/20\n",
      "1742/1742 [==============================] - 39s - loss: 0.1581 - acc: 0.9392 - val_loss: 0.2409 - val_acc: 0.9108\n",
      "Epoch 16/20\n",
      "1742/1742 [==============================] - 39s - loss: 0.1478 - acc: 0.9426 - val_loss: 0.2380 - val_acc: 0.9153\n",
      "Epoch 17/20\n",
      "1742/1742 [==============================] - 39s - loss: 0.1517 - acc: 0.9437 - val_loss: 0.2351 - val_acc: 0.9199\n",
      "Epoch 18/20\n",
      "1742/1742 [==============================] - 39s - loss: 0.1368 - acc: 0.9437 - val_loss: 0.2244 - val_acc: 0.9108\n",
      "Epoch 19/20\n",
      "1742/1742 [==============================] - 39s - loss: 0.1319 - acc: 0.9472 - val_loss: 0.2207 - val_acc: 0.9176\n",
      "Epoch 20/20\n",
      "1742/1742 [==============================] - 39s - loss: 0.1304 - acc: 0.9529 - val_loss: 0.2179 - val_acc: 0.9199\n",
      "2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_17 (Conv2D)           (None, 128, 113, 16)      86528     \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 64, 111, 14)       73792     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 64, 55, 7)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 32, 53, 5)         18464     \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 32, 51, 3)         9248      \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 4896)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2)                 9794      \n",
      "=================================================================\n",
      "Total params: 197,826\n",
      "Trainable params: 197,826\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1743 samples, validate on 436 samples\n",
      "Epoch 1/20\n",
      "1743/1743 [==============================] - 39s - loss: 0.6838 - acc: 0.5605 - val_loss: 0.6687 - val_acc: 0.5642\n",
      "Epoch 2/20\n",
      "1743/1743 [==============================] - 39s - loss: 0.6169 - acc: 0.6277 - val_loss: 0.5318 - val_acc: 0.8188\n",
      "Epoch 3/20\n",
      "1743/1743 [==============================] - 39s - loss: 0.4325 - acc: 0.8204 - val_loss: 0.4767 - val_acc: 0.8417\n",
      "Epoch 4/20\n",
      "1743/1743 [==============================] - 39s - loss: 0.3304 - acc: 0.8789 - val_loss: 0.3094 - val_acc: 0.8670\n",
      "Epoch 5/20\n",
      "1743/1743 [==============================] - 39s - loss: 0.2823 - acc: 0.9019 - val_loss: 0.5047 - val_acc: 0.8028\n",
      "Epoch 6/20\n",
      "1743/1743 [==============================] - 39s - loss: 0.2682 - acc: 0.9053 - val_loss: 0.3201 - val_acc: 0.8807\n",
      "Epoch 7/20\n",
      "1743/1743 [==============================] - 39s - loss: 0.2398 - acc: 0.9151 - val_loss: 0.3190 - val_acc: 0.8922\n",
      "Epoch 8/20\n",
      "1743/1743 [==============================] - 39s - loss: 0.2202 - acc: 0.9208 - val_loss: 0.3500 - val_acc: 0.8807\n",
      "Epoch 9/20\n",
      "1743/1743 [==============================] - 39s - loss: 0.2120 - acc: 0.9214 - val_loss: 0.3634 - val_acc: 0.8716\n",
      "Epoch 10/20\n",
      "1743/1743 [==============================] - 39s - loss: 0.1990 - acc: 0.9323 - val_loss: 0.3432 - val_acc: 0.8899\n",
      "Epoch 11/20\n",
      "1743/1743 [==============================] - 39s - loss: 0.1893 - acc: 0.9363 - val_loss: 0.3611 - val_acc: 0.8807\n",
      "Epoch 12/20\n",
      "1743/1743 [==============================] - 39s - loss: 0.1855 - acc: 0.9357 - val_loss: 0.3040 - val_acc: 0.8945\n",
      "Epoch 13/20\n",
      "1743/1743 [==============================] - 39s - loss: 0.1781 - acc: 0.9375 - val_loss: 0.3256 - val_acc: 0.8945\n",
      "Epoch 14/20\n",
      "1743/1743 [==============================] - 39s - loss: 0.1714 - acc: 0.9375 - val_loss: 0.3008 - val_acc: 0.9083\n",
      "Epoch 15/20\n",
      "1743/1743 [==============================] - 39s - loss: 0.1605 - acc: 0.9415 - val_loss: 0.3076 - val_acc: 0.8830\n",
      "Epoch 16/20\n",
      "1743/1743 [==============================] - 39s - loss: 0.1574 - acc: 0.9455 - val_loss: 0.3029 - val_acc: 0.9037\n",
      "Epoch 17/20\n",
      "1743/1743 [==============================] - 40s - loss: 0.1452 - acc: 0.9461 - val_loss: 0.2865 - val_acc: 0.9014\n",
      "Epoch 18/20\n",
      "1743/1743 [==============================] - 39s - loss: 0.1371 - acc: 0.9518 - val_loss: 0.2896 - val_acc: 0.9060\n",
      "Epoch 19/20\n",
      "1743/1743 [==============================] - 39s - loss: 0.1247 - acc: 0.9552 - val_loss: 0.2969 - val_acc: 0.9014\n",
      "Epoch 20/20\n",
      "1743/1743 [==============================] - 39s - loss: 0.1243 - acc: 0.9541 - val_loss: 0.2960 - val_acc: 0.9037\n",
      "3\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_21 (Conv2D)           (None, 128, 113, 16)      86528     \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 64, 111, 14)       73792     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 64, 55, 7)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 32, 53, 5)         18464     \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 32, 51, 3)         9248      \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 4896)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2)                 9794      \n",
      "=================================================================\n",
      "Total params: 197,826\n",
      "Trainable params: 197,826\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1743 samples, validate on 436 samples\n",
      "Epoch 1/20\n",
      "1743/1743 [==============================] - 40s - loss: 0.6815 - acc: 0.5674 - val_loss: 0.6725 - val_acc: 0.5642\n",
      "Epoch 2/20\n",
      "1743/1743 [==============================] - 39s - loss: 0.6448 - acc: 0.6254 - val_loss: 0.5969 - val_acc: 0.5803\n",
      "Epoch 3/20\n",
      "1743/1743 [==============================] - 39s - loss: 0.5048 - acc: 0.7923 - val_loss: 0.4499 - val_acc: 0.8050\n",
      "Epoch 4/20\n",
      "1743/1743 [==============================] - 39s - loss: 0.3546 - acc: 0.8554 - val_loss: 0.3632 - val_acc: 0.8716\n",
      "Epoch 5/20\n",
      "1743/1743 [==============================] - 39s - loss: 0.4241 - acc: 0.8772 - val_loss: 0.3566 - val_acc: 0.8830\n",
      "Epoch 6/20\n",
      "1743/1743 [==============================] - 39s - loss: 0.2658 - acc: 0.8967 - val_loss: 0.3436 - val_acc: 0.8830\n",
      "Epoch 7/20\n",
      "1743/1743 [==============================] - 39s - loss: 0.2486 - acc: 0.9036 - val_loss: 0.3357 - val_acc: 0.8945\n",
      "Epoch 8/20\n",
      "1743/1743 [==============================] - 39s - loss: 0.2344 - acc: 0.9076 - val_loss: 0.3344 - val_acc: 0.9037\n",
      "Epoch 9/20\n",
      "1743/1743 [==============================] - 39s - loss: 0.2339 - acc: 0.9094 - val_loss: 0.3701 - val_acc: 0.8739\n",
      "Epoch 10/20\n",
      "1743/1743 [==============================] - 39s - loss: 0.2197 - acc: 0.9105 - val_loss: 0.3404 - val_acc: 0.8945\n",
      "Epoch 11/20\n",
      "1743/1743 [==============================] - 39s - loss: 0.2083 - acc: 0.9168 - val_loss: 0.3190 - val_acc: 0.9037\n",
      "Epoch 12/20\n",
      "1743/1743 [==============================] - 39s - loss: 0.2040 - acc: 0.9191 - val_loss: 0.3444 - val_acc: 0.8922\n",
      "Epoch 13/20\n",
      "1743/1743 [==============================] - 39s - loss: 0.1960 - acc: 0.9243 - val_loss: 0.3287 - val_acc: 0.9014\n",
      "Epoch 14/20\n",
      "1743/1743 [==============================] - 39s - loss: 0.1882 - acc: 0.9225 - val_loss: 0.3243 - val_acc: 0.9128\n",
      "Epoch 15/20\n",
      "1743/1743 [==============================] - 39s - loss: 0.1825 - acc: 0.9300 - val_loss: 0.3059 - val_acc: 0.9106\n",
      "Epoch 16/20\n",
      "1743/1743 [==============================] - 39s - loss: 0.1745 - acc: 0.9300 - val_loss: 0.2997 - val_acc: 0.9128\n",
      "Epoch 17/20\n",
      "1743/1743 [==============================] - 39s - loss: 0.1679 - acc: 0.9369 - val_loss: 0.2976 - val_acc: 0.9128\n",
      "Epoch 18/20\n",
      "1743/1743 [==============================] - 39s - loss: 0.1608 - acc: 0.9357 - val_loss: 0.3093 - val_acc: 0.9083\n",
      "Epoch 19/20\n",
      "1743/1743 [==============================] - 39s - loss: 0.1607 - acc: 0.9329 - val_loss: 0.3137 - val_acc: 0.8991\n",
      "Epoch 20/20\n",
      "1743/1743 [==============================] - 39s - loss: 0.1607 - acc: 0.9340 - val_loss: 0.2747 - val_acc: 0.9174\n",
      "4\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_25 (Conv2D)           (None, 128, 113, 16)      86528     \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 64, 111, 14)       73792     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 64, 55, 7)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 32, 53, 5)         18464     \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 32, 51, 3)         9248      \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 4896)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 2)                 9794      \n",
      "=================================================================\n",
      "Total params: 197,826\n",
      "Trainable params: 197,826\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1744 samples, validate on 435 samples\n",
      "Epoch 1/20\n",
      "1744/1744 [==============================] - 40s - loss: 0.6817 - acc: 0.5608 - val_loss: 0.6660 - val_acc: 0.5655\n",
      "Epoch 2/20\n",
      "1744/1744 [==============================] - 39s - loss: 0.6214 - acc: 0.6003 - val_loss: 0.5294 - val_acc: 0.8230\n",
      "Epoch 3/20\n",
      "1744/1744 [==============================] - 39s - loss: 0.4377 - acc: 0.8119 - val_loss: 0.3288 - val_acc: 0.8713\n",
      "Epoch 4/20\n",
      "1744/1744 [==============================] - 39s - loss: 0.3356 - acc: 0.8670 - val_loss: 0.3073 - val_acc: 0.8575\n",
      "Epoch 5/20\n",
      "1744/1744 [==============================] - 39s - loss: 0.2861 - acc: 0.8945 - val_loss: 0.2717 - val_acc: 0.8828\n",
      "Epoch 6/20\n",
      "1744/1744 [==============================] - 39s - loss: 0.2476 - acc: 0.9042 - val_loss: 0.2269 - val_acc: 0.9011\n",
      "Epoch 7/20\n",
      "1744/1744 [==============================] - 39s - loss: 0.2289 - acc: 0.9146 - val_loss: 0.2253 - val_acc: 0.9149\n",
      "Epoch 8/20\n",
      "1744/1744 [==============================] - 39s - loss: 0.2097 - acc: 0.9180 - val_loss: 0.2148 - val_acc: 0.9034\n",
      "Epoch 9/20\n",
      "1744/1744 [==============================] - 39s - loss: 0.1953 - acc: 0.9197 - val_loss: 0.2357 - val_acc: 0.9241\n",
      "Epoch 10/20\n",
      "1744/1744 [==============================] - 39s - loss: 0.1814 - acc: 0.9237 - val_loss: 0.2360 - val_acc: 0.8966\n",
      "Epoch 11/20\n",
      "1744/1744 [==============================] - 39s - loss: 0.1721 - acc: 0.9289 - val_loss: 0.1874 - val_acc: 0.9218\n",
      "Epoch 12/20\n",
      "1744/1744 [==============================] - 39s - loss: 0.1604 - acc: 0.9364 - val_loss: 0.2450 - val_acc: 0.9264\n",
      "Epoch 13/20\n",
      "1744/1744 [==============================] - 39s - loss: 0.1600 - acc: 0.9404 - val_loss: 0.1965 - val_acc: 0.9172\n",
      "Epoch 14/20\n",
      "1744/1744 [==============================] - 39s - loss: 0.1470 - acc: 0.9432 - val_loss: 0.1747 - val_acc: 0.9310\n",
      "Epoch 15/20\n",
      "1744/1744 [==============================] - 39s - loss: 0.1425 - acc: 0.9455 - val_loss: 0.1717 - val_acc: 0.9356\n",
      "Epoch 16/20\n",
      "1744/1744 [==============================] - 39s - loss: 0.1368 - acc: 0.9478 - val_loss: 0.1867 - val_acc: 0.9149\n",
      "Epoch 17/20\n",
      "1744/1744 [==============================] - 39s - loss: 0.1289 - acc: 0.9507 - val_loss: 0.1810 - val_acc: 0.9172\n",
      "Epoch 18/20\n",
      "1744/1744 [==============================] - 39s - loss: 0.1266 - acc: 0.9541 - val_loss: 0.2502 - val_acc: 0.8966\n",
      "Epoch 19/20\n",
      "1744/1744 [==============================] - 39s - loss: 0.1181 - acc: 0.9564 - val_loss: 0.6807 - val_acc: 0.7195\n",
      "Epoch 20/20\n",
      "1744/1744 [==============================] - 39s - loss: 0.1317 - acc: 0.9495 - val_loss: 0.1667 - val_acc: 0.9379\n",
      "5\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_29 (Conv2D)           (None, 128, 113, 16)      86528     \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 64, 111, 14)       73792     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 64, 55, 7)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 32, 53, 5)         18464     \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 32, 51, 3)         9248      \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 4896)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 2)                 9794      \n",
      "=================================================================\n",
      "Total params: 197,826\n",
      "Trainable params: 197,826\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1744 samples, validate on 435 samples\n",
      "Epoch 1/20\n",
      "1744/1744 [==============================] - 39s - loss: 0.6830 - acc: 0.5579 - val_loss: 0.6638 - val_acc: 0.5655\n",
      "Epoch 2/20\n",
      "1744/1744 [==============================] - 39s - loss: 0.6205 - acc: 0.5757 - val_loss: 0.5663 - val_acc: 0.5793\n",
      "Epoch 3/20\n",
      "1744/1744 [==============================] - 39s - loss: 0.4913 - acc: 0.7890 - val_loss: 0.3880 - val_acc: 0.8276\n",
      "Epoch 4/20\n",
      "1744/1744 [==============================] - 39s - loss: 0.3556 - acc: 0.8578 - val_loss: 0.3241 - val_acc: 0.8759\n",
      "Epoch 5/20\n",
      "1744/1744 [==============================] - 40s - loss: 0.2887 - acc: 0.8819 - val_loss: 0.3051 - val_acc: 0.8989\n",
      "Epoch 6/20\n",
      "1744/1744 [==============================] - 39s - loss: 0.2560 - acc: 0.9008 - val_loss: 0.2998 - val_acc: 0.9057\n",
      "Epoch 7/20\n",
      "1744/1744 [==============================] - 39s - loss: 0.2336 - acc: 0.9088 - val_loss: 0.3021 - val_acc: 0.9103\n",
      "Epoch 8/20\n",
      "1744/1744 [==============================] - 39s - loss: 0.2197 - acc: 0.9088 - val_loss: 0.2842 - val_acc: 0.9126\n",
      "Epoch 9/20\n",
      "1744/1744 [==============================] - 39s - loss: 0.2100 - acc: 0.9186 - val_loss: 0.2928 - val_acc: 0.9264\n",
      "Epoch 10/20\n",
      "1744/1744 [==============================] - 39s - loss: 0.1962 - acc: 0.9226 - val_loss: 0.2896 - val_acc: 0.9241\n",
      "Epoch 11/20\n",
      "1744/1744 [==============================] - 39s - loss: 0.1816 - acc: 0.9289 - val_loss: 0.2815 - val_acc: 0.9172\n",
      "Epoch 12/20\n",
      "1744/1744 [==============================] - 39s - loss: 0.1709 - acc: 0.9346 - val_loss: 0.3711 - val_acc: 0.8966\n",
      "Epoch 13/20\n",
      "1744/1744 [==============================] - 39s - loss: 0.1696 - acc: 0.9335 - val_loss: 0.3512 - val_acc: 0.9080\n",
      "Epoch 14/20\n",
      "1744/1744 [==============================] - 39s - loss: 0.1622 - acc: 0.9341 - val_loss: 0.3625 - val_acc: 0.9011\n",
      "Epoch 15/20\n",
      "1744/1744 [==============================] - 39s - loss: 0.1514 - acc: 0.9386 - val_loss: 0.2922 - val_acc: 0.9264\n",
      "Epoch 16/20\n",
      "1744/1744 [==============================] - 39s - loss: 0.1465 - acc: 0.9455 - val_loss: 0.2888 - val_acc: 0.9241\n",
      "Epoch 17/20\n",
      "1744/1744 [==============================] - 39s - loss: 0.1433 - acc: 0.9467 - val_loss: 0.2927 - val_acc: 0.9333\n",
      "Epoch 18/20\n",
      "1744/1744 [==============================] - 39s - loss: 0.1390 - acc: 0.9461 - val_loss: 0.2839 - val_acc: 0.9287\n",
      "Epoch 19/20\n",
      "1744/1744 [==============================] - 39s - loss: 0.1313 - acc: 0.9507 - val_loss: 0.3437 - val_acc: 0.9057\n",
      "Epoch 20/20\n",
      "1744/1744 [==============================] - 39s - loss: 0.1321 - acc: 0.9513 - val_loss: 0.2852 - val_acc: 0.9287\n",
      "Epoch 1/30\n",
      "1744/1744 [==============================] - 34s - loss: 0.1247 - acc: 0.9518    \n",
      "Epoch 2/30\n",
      "1744/1744 [==============================] - 34s - loss: 0.1222 - acc: 0.9558    \n",
      "Epoch 3/30\n",
      "1744/1744 [==============================] - 34s - loss: 0.1190 - acc: 0.9604    \n",
      "Epoch 4/30\n",
      "1744/1744 [==============================] - 34s - loss: 0.1164 - acc: 0.9570    \n",
      "Epoch 5/30\n",
      "1744/1744 [==============================] - 34s - loss: 0.1087 - acc: 0.9633    \n",
      "Epoch 6/30\n",
      "1744/1744 [==============================] - 34s - loss: 0.1067 - acc: 0.9593    \n",
      "Epoch 7/30\n",
      "1744/1744 [==============================] - 34s - loss: 0.1061 - acc: 0.9610    \n",
      "Epoch 8/30\n",
      "1744/1744 [==============================] - 34s - loss: 0.1030 - acc: 0.9667    \n",
      "Epoch 9/30\n",
      "1744/1744 [==============================] - 34s - loss: 0.0957 - acc: 0.9662    \n",
      "Epoch 10/30\n",
      "1744/1744 [==============================] - 34s - loss: 0.0994 - acc: 0.9627    \n",
      "Epoch 11/30\n",
      "1744/1744 [==============================] - 34s - loss: 0.0882 - acc: 0.9713    \n",
      "Epoch 12/30\n",
      "1744/1744 [==============================] - 34s - loss: 0.0836 - acc: 0.9731    \n",
      "Epoch 13/30\n",
      "1744/1744 [==============================] - 34s - loss: 0.0829 - acc: 0.9731    \n",
      "Epoch 14/30\n",
      "1744/1744 [==============================] - 34s - loss: 0.0807 - acc: 0.9736    \n",
      "Epoch 15/30\n",
      "1744/1744 [==============================] - 34s - loss: 0.0849 - acc: 0.9685    \n",
      "Epoch 16/30\n",
      "1744/1744 [==============================] - 34s - loss: 0.0792 - acc: 0.9725    \n",
      "Epoch 17/30\n",
      "1744/1744 [==============================] - 34s - loss: 0.0722 - acc: 0.9771    \n",
      "Epoch 18/30\n",
      "1744/1744 [==============================] - 34s - loss: 0.0667 - acc: 0.9799    \n",
      "Epoch 19/30\n",
      "1744/1744 [==============================] - 34s - loss: 0.0769 - acc: 0.9759    \n",
      "Epoch 20/30\n",
      "1744/1744 [==============================] - 34s - loss: 0.0629 - acc: 0.9771    \n",
      "Epoch 21/30\n",
      "1744/1744 [==============================] - 34s - loss: 0.0613 - acc: 0.9799    \n",
      "Epoch 22/30\n",
      "1744/1744 [==============================] - 34s - loss: 0.0638 - acc: 0.9776    \n",
      "Epoch 23/30\n",
      "1744/1744 [==============================] - 34s - loss: 0.0543 - acc: 0.9845    \n",
      "Epoch 24/30\n",
      "1744/1744 [==============================] - 34s - loss: 0.0538 - acc: 0.9828    \n",
      "Epoch 25/30\n",
      "1744/1744 [==============================] - 34s - loss: 0.0531 - acc: 0.9839    \n",
      "Epoch 26/30\n",
      "1744/1744 [==============================] - 34s - loss: 0.0513 - acc: 0.9862    \n",
      "Epoch 27/30\n",
      "1744/1744 [==============================] - 34s - loss: 0.0491 - acc: 0.9851    \n",
      "Epoch 28/30\n",
      "1744/1744 [==============================] - 34s - loss: 0.0469 - acc: 0.9868    \n",
      "Epoch 29/30\n",
      "1744/1744 [==============================] - 34s - loss: 0.0446 - acc: 0.9891    \n",
      "Epoch 30/30\n",
      "1744/1744 [==============================] - 34s - loss: 0.0402 - acc: 0.9903    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.90091743119266054"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cnn_model - new dataset + tensorflow (with data_format\" channel_first \") E_tot\n",
    "# dropout removed\n",
    "best_validation_acc = 0.0\n",
    "best_model = None\n",
    "\n",
    "num_classes = 2\n",
    "for i, (train_index, validation_index) in enumerate(skf.split(X_train, Y_train)):\n",
    "    print(i+1)\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", validation_index)\n",
    "    Xtrain, Xvalidation = X_train[train_index], X_train[validation_index]\n",
    "    ytrain, yvalidation = Y_train[train_index], Y_train[validation_index]\n",
    "    model = create_nn_model()\n",
    "    Ytrain = np_utils.to_categorical(ytrain)\n",
    "    Yvalidation = np_utils.to_categorical(yvalidation)\n",
    "    \n",
    "    history = model.fit(Xtrain, Ytrain, batch_size=64,\n",
    "                        epochs=20, verbose=1,\n",
    "                        validation_data = (Xvalidation, Yvalidation))\n",
    "    validation_acc = history.history['val_acc']\n",
    "    if validation_acc > best_validation_acc:\n",
    "        best_validation_acc = validation_acc\n",
    "        best_model = model\n",
    "\n",
    "Ytrain = np_utils.to_categorical(ytrain)\n",
    "best_model.fit(Xtrain, Ytrain, batch_size=64, epochs=30)  # replicate conf.\n",
    "\n",
    "predictions = best_model.predict(X_test)\n",
    "cls_predictions = np.argmax(predictions, axis=1)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(Y_test, cls_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12997.0, 0.0, 0)\n",
      "(525.0, 0.0, 0)\n",
      "(20696.0, 1.0, 1)\n",
      "(2187.0, 0.0, 0)\n",
      "(1933.0, 1.0, 1)\n",
      "(6796620.0, 1.0, 1)\n",
      "(2900.0, 1.0, 1)\n",
      "(139570.0, 1.0, 0)\n",
      "(79570.0, 1.0, 1)\n",
      "(6092.0, 0.0, 0)\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(np.floor(E_tot[indx2][i]), Y_test[i], cls_predictions[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 212.0, 1.0, 0)\n",
      "(12, 0.0, 0.0, 1)\n",
      "(13, 150.0, 0.0, 1)\n",
      "(15, 102.0, 0.0, 1)\n",
      "(20, 158.0, 0.0, 1)\n",
      "(30, 192.0, 0.0, 1)\n",
      "(47, 261.0, 0.0, 1)\n",
      "(59, 150.0, 1.0, 0)\n",
      "(60, 193.0, 0.0, 1)\n",
      "(61, 1007.0, 1.0, 0)\n",
      "(66, 228.0, 0.0, 1)\n",
      "(81, 486.0, 1.0, 0)\n",
      "(96, 536.0, 1.0, 0)\n",
      "(102, 71.0, 1.0, 0)\n",
      "(108, 410.0, 1.0, 0)\n",
      "(116, 686.0, 1.0, 0)\n",
      "(133, 525.0, 1.0, 0)\n",
      "(137, 1179.0, 1.0, 0)\n",
      "(141, 622.0, 1.0, 0)\n",
      "(151, 2039.0, 1.0, 0)\n",
      "(186, 258.0, 1.0, 0)\n",
      "(190, 1811.0, 0.0, 1)\n",
      "(197, 213.0, 1.0, 0)\n",
      "(208, 1934.0, 1.0, 0)\n",
      "(220, 669.0, 1.0, 0)\n",
      "(221, 658.0, 0.0, 1)\n",
      "(226, 831.0, 1.0, 0)\n",
      "(227, 214.0, 0.0, 1)\n",
      "(232, 695.0, 1.0, 0)\n",
      "(243, 678.0, 1.0, 0)\n",
      "(272, 1701.0, 0.0, 1)\n",
      "(295, 2615.0, 1.0, 0)\n",
      "(296, 229.0, 1.0, 0)\n",
      "(297, 822.0, 0.0, 1)\n",
      "(298, 2728.0, 0.0, 1)\n",
      "(306, 189.0, 1.0, 0)\n",
      "(312, 343.0, 0.0, 1)\n",
      "(316, 3048.0, 1.0, 0)\n",
      "(319, 2166.0, 1.0, 0)\n",
      "(338, 2115.0, 1.0, 0)\n",
      "(359, 891.0, 0.0, 1)\n",
      "(395, 3859.0, 0.0, 1)\n",
      "(399, 8055.0, 0.0, 1)\n",
      "(400, 8893.0, 1.0, 0)\n",
      "(401, 1306.0, 1.0, 0)\n",
      "(408, 7250.0, 0.0, 1)\n",
      "(412, 3829.0, 1.0, 0)\n",
      "(415, 2643.0, 0.0, 1)\n",
      "(416, 5982.0, 0.0, 1)\n",
      "(434, 1057.0, 0.0, 1)\n",
      "(444, 4550.0, 1.0, 0)\n",
      "(509, 4651.0, 0.0, 1)\n",
      "(527, 9910.0, 1.0, 0)\n",
      "(538, 10715.0, 0.0, 1)\n"
     ]
    }
   ],
   "source": [
    "for i in range(E_tot[indx2].size):\n",
    "    if np.floor(Y_test[i])!=cls_predictions[i]:\n",
    "        print (i, np.floor(E_tot[i]),np.floor( Y_test[i]), cls_predictions[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "E_bin = np.arange(E_t_min, E_t_max, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "E_w_cls = np.histogram(E_tot[indx2][np.floor(Y_test)==cls_predictions], bins=1000, range = (E_t_min, E_t_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "E_b_cls = np.histogram(E_tot[indx2][np.floor(Y_test)!=cls_predictions], bins=1000, range = (E_t_min, E_t_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cls_eff = np.true_divide(E_b_cls[0], E_w_cls[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "491"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E_tot[indx2][np.floor(Y_test)==cls_predictions].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E_tot[indx2][np.floor(Y_test)!=cls_predictions].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f44501743d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# the histogram of the data\n",
    "#n, bins = plt.hist(cls_eff, 1000, normed=1, facecolor='g', alpha=0.75)\n",
    "#plt.hist(E_b_cls[0], bins=E_w_cls[1], range = (E_t_min, E_t_max), alpha = 0.5 )\n",
    "plt.hist(E_b_cls[0], color=\"blue\", range=(0,10))#, bins=E_w_cls[1], range = (E_t_min, E_t_max), alpha = 0.5, color=\"blue\" )\n",
    "plt.hist(E_w_cls[0], alpha=0.5, color=\"red\", range = (0,10))#, range = (E_t_min, E_t_max))\n",
    "\n",
    "#plt.xlabel('Smarts')\n",
    "#plt.ylabel('Probability')\n",
    "#plt.title('Histogram of well classified events')\n",
    "#plt.text(60, .025, r'$\\mu=100,\\ \\sigma=15$')\n",
    "#plt.axis([40, 160, 0, 0.03])\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([45,  2,  0,  0,  1,  0,  0,  2,  0,  0,  1,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]),\n",
       " array([  3.20481000e+00,   7.88641016e+04,   1.57724998e+05, ...,\n",
       "          7.87031782e+07,   7.87820391e+07,   7.88609000e+07]))"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E_b_cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([397,  27,  14,   9,   4,   4,   2,   4,   1,   2,   0,   2,   0,\n",
       "          1,   1,   1,   0,   2,   0,   2,   0,   0,   1,   0,   0,   0,\n",
       "          0,   0,   2,   1,   0,   0,   0,   0,   0,   0,   0,   1,   0,\n",
       "          0,   0,   1,   0,   0,   0,   0,   0,   0,   1,   0,   0,   0,\n",
       "          0,   0,   0,   0,   1,   0,   0,   0,   1,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   1,   0,   0,   1,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   1,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   1,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   1,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1]),\n",
       " array([  3.20481000e+00,   7.88641016e+04,   1.57724998e+05, ...,\n",
       "          7.87031782e+07,   7.87820391e+07,   7.88609000e+07]))"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E_w_cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(E_b_cls[1]==E_w_cls[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([397,  27,  14,   9,   4,   4,   2,   4,   1,   2,   0,   2,   0,\n",
       "         1,   1,   1,   0,   2,   0,   2,   0,   0,   1,   0,   0,   0,\n",
       "         0,   0,   2,   1,   0,   0,   0,   0,   0,   0,   0,   1,   0,\n",
       "         0,   0,   1,   0,   0,   0,   0,   0,   0,   1,   0,   0,   0,\n",
       "         0,   0,   0,   0,   1,   0,   0,   0,   1,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   1,   0,   0,   1,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   1,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   1,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   1,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E_w_cls[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.hist?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.],\n",
       "       [ 0.,  0.],\n",
       "       [ 0.,  1.],\n",
       "       ..., \n",
       "       [ 0.,  0.],\n",
       "       [ 0.,  0.],\n",
       "       [ 0.,  1.]], dtype=float32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.floor(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0,\n",
       "       1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0,\n",
       "       0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0,\n",
       "       0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1,\n",
       "       0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0,\n",
       "       1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1,\n",
       "       0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1,\n",
       "       1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0,\n",
       "       0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "       0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1,\n",
       "       1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "       0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0,\n",
       "       1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1,\n",
       "       0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  1.,  0.,  1.,  1.,  1.,  1.,  1.,  0.,  1.,  0.,  0.,\n",
       "        0.,  0.,  0.,  1.,  1.,  1.,  0.,  0.,  0.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,\n",
       "        1.,  0.,  1.,  1.,  1.,  1.,  0.,  1.,  0.,  1.,  0.,  0.,  0.,\n",
       "        0.,  1.,  0.,  1.,  1.,  1.,  0.,  1.,  0.,  1.,  1.,  0.,  0.,\n",
       "        0.,  0.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  1.,  1.,\n",
       "        1.,  1.,  0.,  1.,  0.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  0.,  0.,  0.,  1.,  1.,\n",
       "        0.,  0.,  1.,  0.,  1.,  1.,  1.,  1.,  1.,  0.,  1.,  0.,  0.,\n",
       "        1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,  0.,\n",
       "        1.,  0.,  0.,  0.,  1.,  0.,  1.,  0.,  1.,  1.,  0.,  1.,  0.,\n",
       "        1.,  0.,  0.,  1.,  0.,  0.,  1.,  1.,  1.,  0.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  0.,  1.,  1.,  1.,  0.,  1.,  1.,  0.,  1.,\n",
       "        1.,  1.,  0.,  1.,  1.,  0.,  1.,  1.,  0.,  0.,  0.,  1.,  1.,\n",
       "        1.,  1.,  1.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  1.,  1.,\n",
       "        1.,  1.,  0.,  1.,  1.,  0.,  1.,  1.,  1.,  1.,  1.,  0.,  1.,\n",
       "        0.,  1.,  0.,  1.,  0.,  1.,  0.,  1.,  1.,  0.,  0.,  1.,  0.,\n",
       "        0.,  0.,  0.,  0.,  1.,  1.,  0.,  1.,  0.,  1.,  1.,  0.,  1.,\n",
       "        0.,  0.,  0.,  0.,  1.,  0.,  1.,  1.,  0.,  1.,  0.,  1.,  1.,\n",
       "        0.,  1.,  1.,  1.,  1.,  0.,  1.,  0.,  0.,  1.,  0.,  1.,  0.,\n",
       "        0.,  1.,  1.,  1.,  1.,  0.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,\n",
       "        0.,  1.,  0.,  0.,  0.,  1.,  0.,  0.,  1.,  1.,  1.,  0.,  0.,\n",
       "        0.,  1.,  0.,  1.,  0.,  1.,  0.,  1.,  1.,  1.,  1.,  0.,  1.,\n",
       "        0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  1.,  1.,  0.,  1.,\n",
       "        0.,  1.,  0.,  0.,  0.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,  0.,\n",
       "        1.,  1.,  1.,  1.,  0.,  1.,  1.,  0.,  1.,  1.,  1.,  1.,  1.,\n",
       "        0.,  0.,  0.,  0.,  1.,  1.,  0.,  0.,  0.,  0.,  1.,  0.,  1.,\n",
       "        1.,  1.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  1.,  1.,  0.,\n",
       "        0.,  1.,  0.,  1.,  0.,  0.,  0.,  1.,  1.,  1.,  1.,  0.,  0.,\n",
       "        1.,  1.,  1.,  1.,  1.,  0.,  1.,  0.,  1.,  0.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  0.,  1.,  0.,  0.,  1.,  0.,  1.,  0.,  0.,  0.,\n",
       "        0.,  1.,  0.,  0.,  0.,  1.,  1.,  0.,  1.,  0.,  0.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  0.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  0.,  1.,  1.,  0.,  1.,  0.,  1.,  0.,  1.,  0.,\n",
       "        1.,  0.,  0.,  1.,  1.,  1.,  0.,  1.,  1.,  0.,  1.,  1.,  1.,\n",
       "        0.,  0.,  1.,  0.,  1.,  1.,  0.,  0.,  0.,  1.,  0.,  1.,  1.,\n",
       "        1.,  1.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  1.,  1.,  1.,  0.,\n",
       "        0.,  0.,  0.,  1.,  1.,  1.,  0.,  1.,  1.,  0.,  1.,  0.,  1.,\n",
       "        0.,  0.,  0.,  1.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,\n",
       "        0.,  1.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  1.,  1.])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy_score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(np.floor(Y_test)!=cls_predictions)[0].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "545"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_predictions.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_predictions[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9118329466357309"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(431-38)/431."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         ..., \n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       "\n",
       "        [[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         ..., \n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       "\n",
       "        [[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         ..., \n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       "\n",
       "        ..., \n",
       "        [[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         ..., \n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       "\n",
       "        [[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         ..., \n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       "\n",
       "        [[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         ..., \n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.]]],\n",
       "\n",
       "\n",
       "       [[[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         ..., \n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       "\n",
       "        [[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         ..., \n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       "\n",
       "        [[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         ..., \n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       "\n",
       "        ..., \n",
       "        [[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         ..., \n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       "\n",
       "        [[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         ..., \n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       "\n",
       "        [[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         ..., \n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.]]],\n",
       "\n",
       "\n",
       "       [[[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         ..., \n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       "\n",
       "        [[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         ..., \n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       "\n",
       "        [[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         ..., \n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       "\n",
       "        ..., \n",
       "        [[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         ..., \n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       "\n",
       "        [[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         ..., \n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       "\n",
       "        [[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         ..., \n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.]]],\n",
       "\n",
       "\n",
       "       ..., \n",
       "       [[[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         ..., \n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       "\n",
       "        [[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         ..., \n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       "\n",
       "        [[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         ..., \n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       "\n",
       "        ..., \n",
       "        [[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         ..., \n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       "\n",
       "        [[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         ..., \n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       "\n",
       "        [[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         ..., \n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.]]],\n",
       "\n",
       "\n",
       "       [[[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         ..., \n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       "\n",
       "        [[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         ..., \n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       "\n",
       "        [[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         ..., \n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       "\n",
       "        ..., \n",
       "        [[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         ..., \n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       "\n",
       "        [[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         ..., \n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       "\n",
       "        [[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         ..., \n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.]]],\n",
       "\n",
       "\n",
       "       [[[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         ..., \n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       "\n",
       "        [[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         ..., \n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       "\n",
       "        [[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         ..., \n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       "\n",
       "        ..., \n",
       "        [[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         ..., \n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       "\n",
       "        [[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         ..., \n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       "\n",
       "        [[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         ..., \n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.]]]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "E_test = E_tot[indx2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "E_t_min = np.min(E_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "E_t_max = np.max(E_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bins = np.arange(E_t_min, E_t_max, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.ara"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.91183294663573089"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try to plot data set (X_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sum_times(evt):\n",
    "    summed_X = np.sum(X[evt], axis=0)\n",
    "    #print(summed_X.shape, Y[evt])\n",
    "    return summed_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_ch_sum = np.asarray([sum_times(evt) for evt in range(X.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_ch_sum.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.where(Y==0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "import matplotlib as mpl\n",
    "%matplotlib inline\n",
    "\n",
    "# Displaying the first training data\n",
    "fig = pyplot.figure(figsize=(20,10))\n",
    "ax = fig.add_subplot(121)\n",
    "ax2 = fig.add_subplot(122)\n",
    "#for numu, put evt number < 1541\n",
    "#img2 = ax2.imshow(sum_times(1500), cmap=mpl.cm.Blues)\n",
    "img2 = ax2.imshow(X_ch_sum[1500], cmap=mpl.cm.Blues)\n",
    "#for nue, put 1541< evt number < 2723 \n",
    "imgplot = ax.imshow(X_ch_sum[2720], cmap=mpl.cm.Blues)\n",
    "\n",
    "imgplot.set_interpolation('nearest')\n",
    "img2.set_interpolation('nearest')\n",
    "#ax.xaxis.set_ticks_position('top')\n",
    "ax.yaxis.set_ticks_position('left')\n",
    "ax.set_title(\"nue\")\n",
    "ax2.set_title(\"numu\")\n",
    "ax.grid()\n",
    "\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sum_times(1500)[sum_times(1500)!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sum_times(2720)[sum_times(2720)!=0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
